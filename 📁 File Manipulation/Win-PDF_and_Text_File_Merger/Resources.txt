----- M2-Lectura.pdf -----
Módulo 2. Servicios centrales de
Amazon W eb Services (A WS)
Introducción
En este módulo vamos a introducirnos en los servicios que son el centro de las soluciones que
vamos a construir con AWS, los llamados servicios core. Ahondaremos, en primer lugar , en la
capacidad de cómputo (EC2 o Elast ic Compute Cloud), explicaremos qué nos brinda, cuáles son
sus diferentes opciones y cómo elegir lo mejor para cubrir diferentes necesidades.
Continuaremos con los servicios de almacenamiento, analizaremos cuáles son sus ventajas, usos
comunes y qué diferencia nos ofrecen para poder determinar el mejor producto disponible.
Finalmente, comp renderemos todas las herramientas, para escoger con conocimiento la mejor
opción que nos puede ofrecer Amazon sobre la base de nuestros objetivos o los de nuestra
empresa o clientes.
Video de inmersión
Unidad 1. Servicios de Cómputo 
Tema 1. Introducción a los servicios centrales de Amazon W eb Services
Figura 1: Los servicios centrales de Amazon W eb Services
Fuente: Sielva, 2017, https://bit.ly/3yLUs1u.
Amazon Web Services ofrece a sus clientes un amplio conjunto de servicios agrupados según la
naturaleza o solución que aporta cada uno de ellos. Estos servicios contribuyen con las empresas
a reducir  los costos de IT (tecnologías de la información) y escalar . Entre los recursos más
importantes, encontramos los siguientes:
1. Servicio de cómputo:  es la capacidad de cómputo o de brindar la infraestructura necesaria
para que los productos funcionen de manera eficiente y rápida. Se trata de bloques de servidores
agrupados en data centers  disponibles para utilizar en cualquier tipo de producto o servicio digital,
según las necesidades. El servicio principal es EC2 (Elastic Compute Cloud) , el cual permite
escalar fácilmente máquinas virtuales para la potencia de cómputo principal. 
2. Servic io de almacenamiento:  es la capacidad de guarda de los datos sin límites de
almacenamiento. Solo posee un límite: el tamaño del fichero que cargar en S3, el cual no puede
superar los 5 terabytes, pero puede  haber ilimitados ficheros de ese tamaño almacenados. Son
configurables para obtener el mejor rendimiento según el tipo de dato que se va a guardar . Según
el uso que se haga de los datos, se ofrecen varios tipos de alma cenamientos, aunque los
principales son: S3 (Simple Storage Services) y EBS (Elastic Block Store).
3. Servicio de base de datos:  estos servicios permiten utilizar diferentes motores de base de
datos y diferentes tecnologías, con opciones y configuraciones acordes a cada necesidad. Cada
uno de estos servicios brinda opcion es de motores y formas de optimización. Entre los centrales
se pueden mencionar: RDS, un servicio de base de datos relacional que permite alojar muchos
tipos de bases de datos en la nube; DynamoDB , una opción de base de datos NoSQL  (not only
structured query language ) en la nube y de escalabilidad bajo demanda; ElastiCache , crea
cachés en memoria y admite estándares abiertos en el almacenamiento en caché.
4. Servicio de redes: uno de los focos principales dentro de la infraestructura que brinda Amazon
es la red de alta velocidad, segura y con opciones de configuración que se adaptan a las
necesidades dentro de las organizaciones. También es la que requiere más experiencia y mayor
atención al configurarla, dado que es la base de la seguridad de toda la infraestructura. El
principal servicio que se puede mencionar es VPC (Virtual Private Cloud) : proporciona los
componentes de red necesarios para una infraestructura que incluye subconjuntos, puertas de
enlace, tablas de enrutamiento y mecanismos de seguridad.
5. Administración de AWS: Amazon ofrece herramientas para el monitoreo de los servicios que
se consu men, así como alertas de cuando se están excediendo límites o se tienen problemas de
performance o velocid ad. Esta información permite analizar con detalle las decisio nes que se
deben tomar en búsqueda de la mejora continua del producto o servicio. Como principales, se
pueden mencionar , por ejemplo: CloudW atch, que permite la supervisión de servicios clave y
utiliza métricas y alertas para un enfoque de monitoreo familiar; y CloudT rail, un servicio que
posibilita el seguimiento de —potencialmente— todas las llamadas API a AWS, lo cual permite un
análisis detallado de todos los eventos sin importar la fuente: consola web, CLI (command-line
interface ), SDK ( software development kit ), etcétera.
6. Seguri dad de AWS: la seguridad es otro de los focos principales en toda la estructura cloud de
Amazon. Brinda servicios para permitir configurar y manejar la segu ridad requerida para las
plataformas, así como la seguridad interna de accesos y roles. Dentro de los servicios núcleo, se
destaca IAM (Identity and Access Management o Gestión de Identidad y Acceso), que es el
servicio responsable de rastrear identidades y acceso en un sistema. El acceso se administra
mediante políticas de IAM que imponen límites a los agentes dentro de AWS. Hay tres
componentes fundamentales para una política de IAM:
El principal: define para quién son los permisos.
La acción o acciones:  define qué se está realizando.
Los recursos:  especifican a qué propiedades se tiene acceso.
Aplicar el modelo de zero trust (visto en la unidad anterior) en IAM significa adoptar el principio de
privilegio mínimo.  Esto implica que cada agente solo debe posee r los permisos mínimos
necesarios para cumplir su función.
7. Integración de aplicaciones de AWS: Amazon también ofrece los servicios para la
comunicación entre diferentes aplicaciones y la velocidad que se necesita para que el
funcionamiento sea transparente para el usuario final. Entre los más importantes, se destacan:
SNS, un servicio de notificación simp le que permite generar notificaciones por correo electrónico y
texto basadas en eventos de AWS; y SQS , el servicio de cola simple perm ite desacoplar
componentes y poner en cola mens ajes entre estos. Este servicio ayud a al uso de microservicios
para las necesidades de procesamiento.
Tema 2. Servicios de cómputo
La capacidad de cómputo  hace referencia a la capacidad de brindar la infraestructura necesaria
para que los productos funcionen de manera eficiente y rápida. Dentro de este grupo, Amazon
EC2 es probablemente, uno de los servicios más famosos e importantes. Se trata de capacidad
de cómputo ( hardware ) en modo servicio y con la característica principal de la elasticidad. 
Antes de continuar , invitamos a ver el siguiente video:
Video 1. Introducción a Amazon EC2
Fuente: Amaz on Web Services (28 de agosto de 2015). Introduction to Amazon EC2 - Elastic Cloud Server & Hosting with AWS [archive de
video]. YouTube. https://n9.cl/5asp3.
Conceptos básicos
Instancias y AMI
Una instancia es un servidor virtual en la nube de AWS. Con Amazon EC2, se puede  instalar y
configurar el sistema operativo y las aplicaciones que se ejecutan en la instancia. De esta manera
se brinda  “una combinación equilibrada de recursos informáticos, de memoria y de red. Además,
pueden usarse para distintas cargas de trabajo, para los servidores web, los repositorios de
código [entre otras funciones]” (Amazon W eb Services, s.f., https://amzn.to/3yHHUb4).
Una imagen de máquina de Amazon  (AMI) es una plantilla que contiene una configuración
de software (por ejemplo, un sistema opera tivo, un servidor de aplicaciones y
aplicaciones). Desde una AMI, se lanza una instancia, que es una copia de la AMI que se
ejecuta como un servidor virtual en la nube. Desde una misma AMI, se pueden lanzar
varias instancias, como se muestra en la figura siguiente. (Amazon Web Services, 2020, p.
200).
Figura 2: V arias instancias de una AMI
Fuente: Amazon W eb Services, 2020, p. 201. 
[Un usuario] puede lanzar distintos tipos de instancias desde una única AMI . . . Cada tipo
de instancia ofrece diferentes capacidades de memoria y computación [que el
desarrollador deberá seleccionar]… según la cantidad de memoria y de potencia . . . que
precise para la aplicación o el software que tiene previsto ejecutar en la instancia . . .
       
[Lanzada la] instancia, su aspecto es el de un host tradicional y [se] puede interactuar con
ella como [se] haría con un equipo. (Amazon W eb Services, 2020, p. 201) 
Uso de las AMI
Amazon Web Services (AWS) publica muchas imágenes de máquina de Amazon (AMI)
que contienen configuraciones de software habituales para uso público. Además, los
miembros de la comunidad de desarrolladores de AWS han publicado AMI personalizadas
. . . con [las que se puede] iniciar nuevas instancias . . . [de manera rápida y fácil]. Por
ejemplo, si la aplicación es un sitio web o un servicio web, la AMI podría incluir un servidor
web, el contenido estático asocia do y el código para las páginas dinámicas. Como
resultado, despué s de lanzar una instancia desde esta AMI, el servidor web se inicia y la
aplicación está lista para aceptar solicitudes. (Amazon W eb Services, 2020, p. 203)
Figura 3: Amazon EC2
Fuente: [imagen sin título sobre Amazon EC2], s.f., https://bit.ly/3AEsxkz. 
Una de las principales características del servicio EC2 es la configuración de 
la capacidad de cómputo, el sistema de almacenamiento y el sistema operativo.
[Esta] capacidad (procesador , memo ria y almacenamiento) es elástica, es decir , consume
los recursos según sus necesidades (y no más).
[Además, este servicio] permite el escalado automático (autoscaling ), es decir , permi te
incrementar el número de instancias EC2 y el tipo de [estas] según  la demanda del
servicio. Esta funcionalidad está pensada principalmente para atender picos puntuales de
demanda y optimizar así el coste del servicio, puesto que se paga únicamente por lo que
se utiliza.
[Finalmente], la administración se puede realizar utilizando la interfa z de AWS o una
interfaz de consola tal y como si de un servidor estándar se tratara.
       
Las ventajas que aporta el servicio EC2 [al usuario final] son:
Poder contratar el servicio con una capacidad mínima para realizar las pruebas y
posteriormente incrementar la capacidad, adaptando el coste al uso real.
En caso de una alta demanda, poder utilizar el autoescalado, incre mentando el
número de instancias cuando el uso así lo demande y reduciéndolo en caso
contrario.
No neces itar realizar ninguna compra de hardware y tampoc o tener que decidir la
capacidad necesaria en tiempo de diseño de la solución.
AWS ofrece distintos modelos de contratación de las instancias EC2:
1. Bajo demanda : se consume por lo que se usa y no hay ningún tipo de compromiso
de permanencia. Sería el mejor modo de contratación en la fase inicial o piloto [de un
trabajo] o proyecto personal o de clientes.
2. Instancias de subasta : se puja por la capacidad libre de AWS EC2. Se pueden
obtener descuentos de hasta el 90 % en el pago . . .
3. Instancias reserv adas : se obtiene hasta un 75 % de descuento, adquiriendo
compromisos de permanencia de 1 o 3 años . . .
4. Hosts dedicados : se pued en contra tar servidores físicos de EC2. Se trata de un tipo
de uso muy específico. (Sielva, 2017, https://bit.ly/3yRK0VS) 
Tipos de instancias y su uso con EC2
Existen diferentes tipos de instancias, que se seleccionarán en funció n de los requisitos de la
aplicación o del software que se tenga previsto ejecutar en dicha instancia. Amazon EC2 se
encarga de proporcionar a cada instancia una cantidad uniforme y predecible de capacidad de
CPU, según su necesidad de rendimiento. Mencionemos los tipos de instancias:
Instancias de uso general : “Las instancias de uso general proporcionan un conjunto
equilibrado de recursos informático s, de memoria y de red, y se pueden usar para una
amplia gama de cargas de trabajo” (Amazon W eb Services, 2020, p. 214). 
Instancias optimizadas para comp utación : “Las instancias optimizadas son ideales para
las aplicaciones relacionadas con computación que disponen de procesadores de alto
rendimiento” (Amazon W eb Services, 2020, p. 264).
Instancias optimizadas para mem oria: “Las instancias optimizadas para memoria están
diseñadas para ofrecer un rendimien to rápido para cargas de trabajo que procesan grandes
conjuntos de datos en memoria” (Amazon W eb Services, 2020, p. 273). 
Instancias optimizadas para almacenamiento: 
Las instancias optimizadas para almacenamiento se diseñan para cargas de trabajo que
requieren un alto acceso de lectura y escritura secuencial a grandes conjuntos de datos en
almacenamiento local. Se optimizan para ofrecer decenas de miles de operaciones de E/S
aleatorias de baja latencia por segundo (IOPS) para las aplicaciones. (Amazon Web
Services, 2020, p. 285)
Instancias de informática acelerada : “ofrecen  acceso a aceleradores de computación
basado en hardware , como unidades de procesamiento gráfico (GPU) o matrices de puertas
programables en campo (FPGA)” (Amazon W eb Services, 2020, p. 293).
Ciclo de vida de una instancia
“Una instancia Amazon EC2 pasa por diferentes estados desde el momento en que se lanza
hasta su finalización” (Amazon Web Services, 2020, p. 487). El usuario puede parar o terminar
una instancia en ejecución en cualquier momento.
Figura 4: T ransiciones entre los distintos estados de una instancia
Fuente: Amazon W eb Services, 2020, p. 488.
Al lanzar una instancia, esta entra en estado pending . [Según el tipo de instancia que se
haya especificado, se] determinará el hardware del equipo host para la instancia…  Una
vez que la instanc ia está lista para utilizarse, entra en estado running . [Esto significa que el
usuario] puede conectarse a la instancia en ejecución y usarla como si fuera un equipo.
(Amazon W eb Services, 2020, p. 489)
“Si la instancia no logra hacer una comprobación de estado o no ejecu ta las aplicaciones como
debería . . . [se] puede detener e iniciar la instancia para tratar de solucionar el problema”
(Amazon Web Services, 2020, p. 503). Esto hace que entre en estado  stopping , lo que significa
que se prepara para detenerse o hibernar .
“Mientras la estancia está en estado stopped , puede modificar ciertos atributos de ella, incluido el
tipo de instancia” (Amazon Web Services, 2020, p. 490). Además, cuando una instancia hiberna,
le indicamos al sistema operativo que se realiza la hibernación (susp ensión a disco) para que
guarde el contenido de la memoria de la instancia (RAM) en su volume n raíz de otro servicio de
Amazon, que es EBS, para reiniciarla en otro momento.
En ambos casos (stopped o hibernación), si se inicia de nuevo la instancia, se transfiere a un
nuevo host. Esto provocará que volvamos al estado running . 
Si el usuario decide que ya no necesita una instancia, puede terminarla. “En cuanto el estado de
una insta ncia cambie a shutting-down  o a terminated , dejará de incurrir en costos por ella”
(Amazon Web Services, 2020, p. 491). Una vez terminada una instancia, permanecerá visible
durante un breve período de tiempo  y, a continuación, la entrada se eliminará automáticamente.
Dado que se elimina todo tipo de dato vinculado, no es posible conectarse a una instancia
terminada ni recuperarla. Para evita r que la instancia termine de forma accidental, se recomienda
deshabilitar la opción de terminación. 
En cuanto al reinicio de una instancia, el documento expresa: 
El reinicio  de una instancia es equivalente al reinicio del sistema operativo. La instancia
sigue estando en el mismo equipo host y conserva su nombre de DNS público, dirección
IP privad a y todos los datos en sus volúmenes de almacén de instanc ias. (Amazon Web
Services, 2020, p. 490)
Si el dispositivo raíz de la instancia es un volumen de Amazon EBS, la instancia se detiene
y puede volver a iniciarla en cualquier momento. Si el dispositivo raíz de la instancia es un
volumen de almacén de instancias, la instancia se termina y no puede volver a utilizarse.
(Amazon W eb Services, 2020, p. 491)
Para conocer más acerca del
funcionamiento de las
instancias, invitamos a visitar
el siguiente enlace: 
Amazon W eb Services  (s.f.).
Ciclo de vida de la instancia .
Amazon W eb Services.
https://n9.cl/jif92 . 
Breve historia de conceptos: balanceador
El término balanceador , antes del desa rrollo del concepto de nube como lo conocemos
actualmente, se utilizaba para referirse a un dispositivo de hardware (que podrían ser 2 o más
servidores on premise) conectado a otro dispositivo de hardware . Una de sus funciones era
balancear la carga de peticiones a un sitio, de modo que este no recibier a todas las peticiones por
sí solo y se volviera incapaz de responder a nuevas peticiones. El balanceador , entonces, repartía
las peticiones entre otros servidores que tenían la misma información que el servidor .
Figura 5: Balanceador de carga
Fuente: TP-Link Technologies, s.f., https://bit.ly/37zPCrV . 
Entonces, esta tecnología del año 2000 buscaba lograr un equilibri o de la carga. Entre las
soluciones de hardware , podemos considerar los rúters y switches , los cuales incluyen un
software de balanceo preparado para ello. Pero también hay soluciones de software que se
instalan en el back end  de los servidores.
Luego de más de 10 años de avances tecnológicos y bajo el mismo nombre de load balancer ,
Amazon ofrece dentro de su servicio EC2 la opción de pago para utilizar los balanceadores de
carga integrados dentro de Amazon.
Este servicio es configurable mediante un software por parte del cliente, quien solo debe
configurar las instancias (sinónimo de servidores) que se incluirán en el balanceador para que la
carga se reparta. El cliente también puede seleccionar aspectos más profundos, como el
algoritmo que se utilizará o funciones como el autoescalado de servidores (instancias), para que
se agreguen y, en ese mismo proceso, se creen nuevos servidores para suplir demandas, y
también para que crezcan y vuelvan a un estado previo, entre otras opciones.
El principal cambio aquí es que, en los años anteriores a la existencia de la nube, el balanceador
de carga era una combinación de hardware y software que debía ser comprada y que no tenía
ninguna propiedad de elasticidad, es decir , por cada servidor nuevo  había que conectarlo y
desconectarlo manualmente, y lo mismo sucedía con su configuración. Nada de esto ha quedado
en la nube, que se encarga automáticamente de abastecer al cliente en sus demandas.
Si bien balancead or como concepto quedó obsoleto con la implemen tación de las tecnologías
cloud, el significante no cambió. V eamos en profundidad el servicio.
Amazon ELB (Elastic Load Balancing)
Figura 6: Amazon ELB 
Fuente: Barr , 2014, https://n9.cl/oevue. 
Este servicio de AWS permite interponer un balanceador por delante de varias instancias
EC2 para poder distribuir la carga, ya sea por demanda (porque hay un pico elevado de
peticiones), como por tipo de servicio (enviar las peticiones de video a un servidor
especializado en streaming y las peticiones de datos a un servidor de datos). También
permite implementar una tolerancia a fallos propia y ofrece alta disponibilidad y escalado
nativo automático. (Sielva, 2017, https://bit.ly/3yRK0VS) 
En un patrón básico, los servidores web se ubican detrás de un balanceador de carga o
equilibrador de carga elástica , que distribuye el tráfico entre ellos.
De esta forma, si uno de los servidores deja de estar disponible, el equilib rador de carga
lo reconoce y deja de distribuir tráfico  a la instancia no saludable. Esto garantiza que,
en caso de que haya un problema en uno de los AZ donde reside un componente, su
aplicación aún esté disponible. (González, 2018, https://bit.ly/3CFXiaw) 
“Elastic Load Balancing ofrece tres tipos de equilibradores de carga: clásico, de carga de
aplicaciones y de red. Estas cuentan con alta disponibilidad, escalamiento automático y seguridad
robusta. Todo lo que necesita para que las aplicaciones sean tolerantes a fallas” (González, 2018,
https://bit.ly/3CFXiaw).
En el siguiente módulo, abordaremos estos temas en mayor profundidad.
Actividad de repaso
De acuerdo con lo aprendido en el módulo, el balanceador , como
tecnología, ¿se mantiene igual desde su creación hasta la creación de la
nube de Amazon W eb Services?
El concepto de load balancer solo mantiene su nombre, ya que ha cambiado por
completo. Han pasado 20 años desde la utilización de los balanceadores de carga,
y, en tiempos de Amazon W eb Services, son implementaciones de hardware y
software totalmente controladas por Amazon W eb Services. El usuario no puede ni
tiene interacción con el hardware ni con el software que gestiona el balanceo. Lo
único que puede hacer el usuario es realizar la configuración pertinente a: qué tipo
de balanceador utilizar (de aplicación, de red); los servidores (instancias) que
recibirán el tráfico.
Sí, la tecnología es la misma. Amazon utiliza switches, rúters y un software
especializado para balancear la carga entre servidores y evitar sobrecargas en ellos.
No, lo único que se conserva es el nombre de la técnica, es decir , el balanceo de
carga. La implementación de balanceadores de carga en la actualidad es una
combinación de hardware de Microsoft con software de Amazon y la utilización del
servicio ELB (Elastic Load Balancer) con sus distintos tipos de balanceador .
Justificación
Lambda: la experiencia serverless en Amazon
Figura 7: Amazon Lambda
Fuente: Rootstack, 2023, https://n9.cl/kmb3as. 
Para que comprendamos el propó sito del Servicio Lambda, veremos un video que explica
brevemente por qué es una excelen te opción al momento de pensar en servicios serverless, es
decir , sin necesidad de crear instancias o servidores.
Video 2. Funciones Lambda
Fuente: Carvajal, R. (20 de mayo de 2020). Funciones Lambda (AWS): ¿Qué son y cómo funciona esta tecnología? [archivo de video].
YouTube. https://n9.cl/5y0gc.
Una vez que hemos comprendido el propósito de utilizar servicios serverless, los invitamos a
comprender e implementar una solución sencilla en Lambda: 
Video 3: Cómo crear funciones o microservicios en AWS Lambda
Fuente: Arquitectura AWS (31 de julio de 2017). Cómo crear funciones o microservicios en AWS Lambda [archivo de video]. YouTube.
https://n9.cl/rz8750.
Este servicio nos permite poder ejecutar código (pequeñas aplicaciones) sin ser necesario
un servidor (serverless ). Posiblemente sea uno de los servicios más innovadores de AWS,
puesto que permite poder tener determinados servicios web atendie ndo peticiones de
otras aplicaciones sin necesidad de desplegarlos en servidores de aplicaciones. (Sielva,
2017, https://bit.ly/3yRK0VS)
Al código que se ejecuta en AWS Lambda se lo denomina función de Lambda. Después de
crear una función de Lambda, esta, siempre, estará lista para ejecuta rse en cuanto se
active, de manera similar al funcion amiento de una fórmula en una hoja de cálculo. Cada
función incluye código y cierta inform ación de configuración asociada, incluidos el nombre
de la función y los requisitos en materia de recursos. Las funciones de Lambda “no tienen
estado” y no tienen ninguna afinidad  con la infraestructura subyacente, por lo que Lambda
puede lanzar rápidamente tantas copias de la función como resulten necesarias para
ajustar la escala al índice de eventos entrantes. (Amazon Web Services, s. f. b,
https://amzn.to/3A wSQcc) 
Se puede hacer hincapié en el concepto no tienen estado , al que también se llama stateless . Esto
quiere decir que las funciones de Lambda no están ni prendidas, ni apagadas, sino estáticamente
abiertas a ser llamadas para ser ejecutadas por un evento externo o interno, dependiendo de
cómo se las configure. Esto solo será cobrado por Amazon si la función entra en ejecución, es
decir , si es utilizad a; no se cobrará por crearla y guardarla. La cantidad de milisegundos mínimos
por los cuales Amazon cobrará la ejecución es de 100. Esto es un estándar y significa que, si el
código tarda 30 milisegundos en ejecutarse, se cobrarán 100 milisegundos, redondeando lo
restante a favor del servicio de Amazon.
Algunas características de Lambda:
En este servicio, al igual que en la gran mayoría de los de AWS,
Solo se paga por la ejecución, es decir , cada vez que se atienden peticiones.
Es muy útil para evitar los tiempos de parada controlada. En una actualización del
sistema, siempre existe un tiempo mínimo de parada, y utilizando este servicio la
mayoría de las veces es posible reiniciar los servidores, y los servi cios Lambda
seguirán funcionando.
Tiene una utilidad clara para atender multitud de peticiones simultáneas, para
meterlas en una cola y redirigirlas hacia instancias EC2.
El servicio incluye alta disponibilidad de manera nativa. (Sielva, 2017,
https://bit.ly/3yRK0VS)
Unidad 2. Servicios de almacenamiento
Tema 1. Introducción a los servicios de almacenamiento
El almac enamiento en la nube es un modelo de informática en la nube que almacena
datos en internet a través de un proveedor de cloud que administra y opera el
almacenamiento como un servicio. Se ofrece bajo demanda con capacidad y costo
oportunos, y elimina la necesida d de tener que comprar y administrar su propia
infraestructura de almacenamiento de datos. Esto le otorga agilidad , escala global y
durabilidad con acceso a los datos en cualquier momento y lugar . (Ama zon Web Services,
s. f. c, https://amzn.to/3iDK8mn) 
¿Cómo funciona el almacenamiento en la nube?
El almacenamiento en la nube se compra a un proveedor externo que posee y opera
capacidad de almacenamiento de datos y la distribuye a través de internet con un modelo
de pago por uso. Estos proveedores de almacenamiento en la nube administran la
capacidad, la seguridad y la durabilidad para lograr que sus aplicaciones de todo el mundo
tengan acceso a los datos.
       
Las aplicaciones obtienen acceso al almacenamiento en la nube mediante protocolos de
almacenamiento tradicionales o directamente mediante una API. Muchos proveedores
ofrecen servicios complementarios diseñados para ayudar a recopilar , administrar ,
proteger y analizar datos a gran escala. (Amazon Web Services, s.f.,
https://amzn.to/3iDK8mn) 
Beneficios del almacenamiento en la nube
El almacenamiento  de datos en la nube permite a los departamentos de TI transformar tres
aspectos:
1. Costo total de la propiedad . Con el almacena miento en la nube, no es necesario
comprar hardware , almacenar para aprovisionar o invertir capital en situaciones que
pueden darse “algún día”. Puede agregar o eliminar capacidad bajo demanda,
modificar las características de desempeño y retención con rapidez y pagar
solamente por el almacenamiento que utilice. Incluso puede trasladar los datos a los
que se accede con menos frecuencia a capas de menor costo de acuerdo con las
reglas auditables, para aprovechar la economía de escala.
2. Tiempo de implementación  . . . Permite al departamento de TI proporcionar con
rapidez la cantidad de almacena miento necesaria en el momento necesario,
permitiéndoles concentrarse en resolver problemas de aplicación compl ejos en lugar
de tener que administrar sistemas de almacenamiento.
3. Gestión de la información . Centralizar el almacenamiento en la nube aporta un
gran beneficio para nuevos casos de uso. Al utilizar políticas de administración del
ciclo de vida del almacenamiento en la nube, puede realizar potentes tareas de
administración de la información, incluida la separación por niveles autom atizada o el
bloqueo de datos para cumplir con los requisitos de conformidad. (Amazon Web
Services, s.f., https://amzn.to/3iDK8mn) 
Requisitos del almacenamiento en la nube
Garantizar que los datos críticos de un cliente o una empresa se mantengan seguros, a
salvo y disponibles es algo fundam ental. A la hora de considerar el almacenamiento de
datos en la nube, existen varios requisitos fundamentales.
Durabilidad . Los datos deberían almacenarse de forma redundante, a poder ser en
varias instalacione s y en varios dispositivos de cada instalación. Los desastres
naturales, los errores humanos o los fallos mecánicos no deberían provocar una
pérdida de los datos.
Disponibilidad . Todos los datos deberían estar disponibles cuando es necesario. El
almacenamiento en la nube aporta el equilibrio ideal entre tiempos de recuperación y
costo.
Seguridad . Lo ideal es cifrar todos los datos , tanto si están en reposo como en
tránsito. Los permisos y los controles de acceso deberían funcionar del mismo modo
en la nube que en el almacenamiento on-premise . 
. . . 
Existen tres tipos de almacenamien to en la nube: de objetos, de archivos y de bloque.
Según el uso que se haga de ellos, AWS ofrece varios tipos de almacenamientos, cada
uno con sus propios beneficios y casos de uso: 
1. Almacenamiento de objetos : con frecuencia, las aplicaciones desarrolladas en la
nube aprovechan la gran escalabilidad y las características de metadatos del
almacenamiento de objetos. Las soluciones de almacenamiento de objetos como
Amazon Simple Storage Servic e (S3) son ideales para crear aplicacio nes
modernas desde cero que requieren escala y flexibilidad, y que también puede
utilizar para importar almacenes de datos existentes para su análisis, backup o
archivado. [S3 es almacenamiento de clave/valor basado en objetos para muchos
propósitos en AWS.]
2. Almacenamiento de archivos : algunas aplicaciones necesitan obtener acceso a
archivos comparti dos y requieren un sistema de archivos. A menudo,  este tipo de
almacenamiento cuenta con un servidor de almacenamiento conecta do a la red
(NAS). Las soluciones de almacena miento de archivos como Amazon Elastic File
System (EFS)  son ideales para casos de uso como depósitos de contenido de gran
tamaño, entornos  de desarrollo, almacenes multimedia o directorios de inicio del
usuario.
3. Almacenamiento en bloque : en otras  aplicaciones empresariales, como bases de
datos o sistemas de planificación de recursos empresariales (ERP), a menudo [se]
requiere almacenamiento dedicado y de baja latencia para cada host. Esto es similar
al almacenamiento conectado directamente (DAS) o una red de área de
almacenamiento (SAN). Las solucio nes de almacenamiento en la nube, basadas en
bloques, como Amazon Elastic Block Store (EBS) , se aprovisionan  con cada
servidor virtual y ofrecen la latencia ultrabaja necesaria para cargas de trabajo de
alto rendimiento. (Oré V ilchez, 2022, https://n9.cl/vccfj)
Tema 2. Elastic Block Store (EBS)
Amazon Elastic Block Store (EBS) es un servicio de almacenamiento de bloque de alto
rendimiento diseñado para usar EC2, tanto en cargas de trabajo intensivas de rendimiento
como de transacciones, a cualquier escala, como en bases de datos relacionales y no
relacionales, aplicaciones empresariales, aplicaciones en contenedores, motores de
análisis de big data , sistemas de archivos y flujos de trabajo de medios.
[Existen] cuatro tipos de volumen diferentes que equilibran el precio  y el rendimiento
óptimos. Estos volúmenes se pueden cambiar y ajustar sin interrumpir  el funcionamiento
de las aplicaciones  fundamentales, de modo que disponga de un almacenamiento rentable
cuando se necesite. (Amazon W eb Services, s.f., https://amzn.to/3gepnfF)
Los volúm enes de Amazon EBS se colocan en una zona de disponibilidad específica,
donde se replica n automáticamen te para protegerlos de errores de componentes
individuales. Todos los tipos de volúmenes de EBS ofrecen capacid ades instantáneas
duraderas y están diseñados para proporcionar una alta disponibilidad. (Amazon Web
Services, s. f. e, https://amzn.to/3xFGKvE) 
Tipos de volúmenes
Amazon EBS proporciona una variedad de opciones que… permiten optimizar el
rendimiento del almacenamiento y los costos de su carga de trabajo. Estas opciones se
dividen en dos categorías principales: almacenamiento respaldado por SSD para cargas
de trabaj o transaccionales… y almacenamiento respaldado por HDD para cargas de
trabajo intensivas. (Amazon W eb Services, s.f., https://amzn.to/3xFGKvE) 
1. Almacenamiento respaldado por SSD (solid state disk): van desde 1 GB
(gigabyte) a 16 TB (terabyte). Es un volumen de mayor rendimiento diseñado para
cargas de trabajo transaccionales sensibles a la latencia, como bases de datos
relacionales y NoSQL  con uso intensivo de operaciones de E/S, volúmenes de
arranque, aplicaciones interactivas de baja latencia, desarrollo y pruebas. Son de uso
general y equilibran el precio y el rendimiento (Amazon W eb Services, s.f.).
2. Almacenamiento respaldado por HDD (hard disk drive ): desde 500 GB a 16 TB.
Son volúmenes de bajo costo, diseñados para cargas de trabajo de procesamiento
intensivo según se acceda a ellas con mayor o menor frecuencia, como big data,
almacenes de datos, procesamiento de registros, etcétera (Amazon Web Services,
s.f.).
Servicios que se incluyen:
Seguridad: 
Amazon EBS ofrece un cifrado integral…, por lo que no resulta necesario crear ni
administrar una infraestructura segura de administración de claves. El cifrado de EBS
habilita la seguridad de los datos en reposo mediante el cifrado de instantáneas,
volúmenes de arranque y volúmen es de datos por medio de claves administradas por
Amazon o con claves [creadas por el usuario]. (Amazon Web Services, s.f.,
https://amzn.to/3xFGKvE)
Elasticidad: 
[Es] una característica que . . . permite adaptar fácilmente los volúmenes a… las
necesidades de las aplicaciones . . . permiten aumentar la capacidad, ajustar el
rendimiento y modificar el tipo de cualquier volumen de generación nueva o existente de
manera dinámica  y sin interrupciones ni impactos en el rendimien to. (Amazon Web
Services, s.f., https://amzn.to/3xFGKvE) 
API Gateway de Amazon W eb Services
En primer lugar , debemos desarrolla r el concepto de API. Una API (application program  interface )
es “es un conjunto de herramientas , definiciones y protocolos que se utiliza para desarrollar [e
integrar] el software de las aplicaciones” (Red Hat, s.f., https://red.ht/2X9AMX9). 
Amazon ofrece a los usuarios API Gateway , una interfaz que se encuentra entre la aplicación y los
microservicios. Los desarrolladores la usan para crear , publicar , manten er, monitorear y asegurar
los servicios, sin interactuar directamente con ellos. Es la API la que hace de puente o puerta de
enlace entre el cliente y el conjunto de servicios back end. 
API Gateway no solo simplifica la forma en que construyen y admin istran las API, sino que
también aumenta la seguridad, ya que no queda expuesto el punto final y esto minimiza
considerablemente el vector de ataque. El back end siempre se encuentra oculto para los
desarrolladores y ellos solo trabajan con la interfaz.
Tema 3. Amazon S3 (Simple Storage Service)
Conceptos previos        
Antes de desarroll ar las características y especificaciones del servicio S3, es importante entender
algunos conceptos previos que nos ayudarán con el entendimiento. Para comenzar , veremos un
video.
 Video 4: Amazon S3, excelente servicio de almacenamiento en la nube
Fuente: Lópe z, D. (2 de diciembre de 2016). Amazon S3, excelente servicio de almacenamiento en la nube [archivo de video]. YouTube.
https://n9.cl/v06wl. 
Figura 8: Amazon S3
Fuente: [imagen sin título sobre Amazon S3], 2022, https://bit.ly/3mbnSCL.
“Es el servicio principal de AWS para el almacenamiento y recuperación de archivos mediante una
API. Utilizando esta API, los programadores pueden desarrollar aplicaciones para almacenar y
recuperar archivos de manera ágil y segura” (Sielva, 2017, https://bit.ly/3yLUs1u). 
“Amazon se encarga de almacenar [los] archivos de manera redundante” (Sielva, 2017,
https://bit.ly/3yLUs1u). Esto significa que utiliza varios discos proporcionando tolerancia a fallos,
mayor capacidad y mayor fiabilidad en el almacenamiento.
“Una de las principales ventajas de este servicio es su muy bajo costo” (gracias a que es
totalmente escalable y a que admite un nivel de acceso a datos específico con un costo
correspondiente a cada uno) “y por supuesto su integración con el resto de servicios de AWS”
(Sielva, 2017, https://bit.ly/3yLUs1u). 
Los clientes de todos los tamaños y sectores pueden utilizar Amazon S3 para almacenar y
proteger cualquier  cantidad de datos para diversos casos de uso, tales como lagos de
datos, sitios web, aplicaciones móviles, copia de seguridad y restauración, archivado,
aplicaciones empresariales, dispositivos IoT y análisis de big data. Amazon S3 proporciona
funciones de gestión para que pueda optimizar , organizar y configurar el acceso a sus
datos para satisfacer sus requisitos empresariales, organizativos y de conformidad
específicos. (Amazon W eb Services, s.f., https://n9.cl/jnob6)
Los datos de S3 se almacenan como objetos (de hasta 5 terabytes ) dentro de recurs os llamados
buckets . Se puede acced er a los objetos a través de los puntos de acceso de S3 a través del
nombre de host del bucket o se les puede anexar , hasta 10 pares de clave-valor (etiquetas) a
cada uno, que se pueden crear , actualizar y eliminar a lo largo de todo el ciclo de vida de ellos. A
su vez, los buckets se pueden organizar con nombres compartidos denominados prefijos
(Amazon W eb Services, s.f.).
Para hacer un seguimiento de los nombres de los buckets de S3, prefijos y etiquetas de objetos,
AWS cuenta con S3 Inventory , donde se enumera y almacena esta información, así como sus
metadatos y estado de cifrado correspondientes (Amazon W eb Services, s.f.). 
Amazon S3 también admite características que ayudan a:
controlar las versiones de los datos;
impedir el borrado accidental;
replicar los datos en otras regiones de AWS para lograr una latencia reducida;
tener conformidad, seguridad, recuperación de desastres y muchos otros casos de uso. 
“Con el control de versiones de S3 puede preservar , recuperar y restau rar todas las versiones de
un objeto almacenado en Amazon S3, lo que le permite recuperarse fácilmente de acciones de
usuarios involun tarias y de errores de aplicaciones” (Amazo n Web Services, s.f.,
https://n9.cl/5pue). 
Tema 4. Amazon Glacier
Video 5. Servicio Glacier
Fuente: Amazon Web Services Latin America (20 de abril de 2019). Glacier Deep Archive – Spanish [archivo de video]. YouTube.
https://n9.cl/cg3sq.
Figura 9: Amazon Glacier
Fuente: [imagen sin título de Amazon Glacier], 2017, https://bit.ly/3jRfqp5.
Amazon S3 Glacier es un servicio de almacenamiento que funciona como una extensión de S3
para archivos que van a tener una tasa reducida de acceso. “Es un servicio de costo
extremadamente bajo, que ofrece almacenamiento seguro, duradero y flexible para archivos y
copias de seguridad de datos” (Amazon Web Services, s. f., https://amzn.to/3xKNd8l) cuando la
información que se requiere guardar no va a ser consultada con demasiada asiduidad, como
podría ser un sistema de copia de seguridad.
Amazon S3 Glacier permite a los clientes ahorrarse las cargas administ rativas de operar y
escalar el almacenamiento en AWS, para que no tengan que preocuparse por la
planificación de la capacidad, el aprovisionamiento de hardware , la replic ación de datos, la
detección y reparación de errores de hardware o las extensas migraciones de hardware .
(Amazon W eb Services, s.f., https://amzn.to/3xKNd8l) 
Los clientes pueden almacenar datos por tan solo 1 USD por terabyte al mes, lo que
representa un ahorro significativo en comparación con las soluciones locales. Amazon S3
Glacier proporcion a tres opciones de acceso a los archivos, que van desde unos pocos
minutos a varias horas, y S3 Glacier Deep Archive ofrece dos opciones de acceso, que
van desde 12 a 48 horas, lo que las convierte en opciones adecua das para diversas
necesidades de recuperación a la vez que mantienen los costos bajos. (Amazon Web
Services, s.f., https://amzn.to/3fWXh8o) 
Su diferencia más grande con los servicios de Amazon S3 normales es cómo se accede a la
información y el tiempo que lleva, suponiendo ahorros muy grandes en comparación con datos
almacenados.
En Amazon S3 Glacier , los datos se almacenan en “archivos”. Estos se pueden guardar de forma
individual (fotos, documentos, videos, etc.) o se pueden comprimir y cargarse como un solo
archivo (TAR, ZIP, etc.) con un tamaño máximo de 40 terabytes y de forma ilimitada. Cuando se
crea un archivo, se le asigna un ID (identification ) único y su conte nido es inmutable, es decir , no
se puede actualizar una vez creado. Esto garantiza que datos como los registros de conformidad
y normativos no se puedan modificar una vez archivados.
“Amazon S3 Glacier utiliza ‘almace nes’ como contenedores para almacenar archivos” (Amazon
Web Services, s. f., https://amzn.to/3jSJf97), que son manipulados por el usuario, quien también
puede establecer políticas de acceso para cada almacén que permitan  o denieguen actividades
específicas a usuarios determinados. Cada cuenta de AWS puede disponer de hasta 1000
almacenes.
En cuanto a la seguridad de los datos:
en Amazon S3 Glacier están protegidos por defecto; solo los propietarios de los almacenes
disponen de acceso a los recursos de Amazon S3 Glacier que crearon . . . Gracias a las
características de protección de datos de Amazon S3 Glacier , puede proteger los datos de
errores tanto físicos como lógicos. De esta forma, se evita la pérdida de datos provocada
por acciones involuntarias del usuario, errores de la aplicación y errores de la
infraestructura. (Amazon W eb Services, s. f. j, https://amzn.to/3jSJf97) 
Actividad de repaso
¿Es ilimitado el tamaño de los archivos que se pueden cargar al
almacenamiento Amazon S3?
Sí, es ilimitado. Dada la flexibilidad y escalabilidad de la nube de Amazon,
literalmente se creará la cantidad necesaria de servidores de Amazon para
almacenar la cantidad de archivos que los clientes necesiten. El tamaño del archivo
no tiene importancia, ni la cantidad que se almacene de ellos.
Sí, es ilimitado, pero con una condición: los archivos mayores a 5 GB deben ser
cargados de manera fraccionada. Para esto, el usuario cargará el archivo sin
interacción alguna y el servicio S3 se encargará de dividir el archivo en las partes
necesarias para cargarlo en S3 de manera paralela, luego se unirá todo dentro del
servicio S3 el archivo final.
No, no es ilimitado. El límite de tamaño para cada fichero, en Amazon S3, es de 5
TB, y también existe una limitación lógica en las posibilidades reales de Amazon de
ofrecer almacenamiento ilimitado. Esto técnicamente no es posible, ya que está
sujeto a condiciones de un entorno realista y no sería posible un escenario donde
todos los clientes de Amazon quisieran interactuar con el Servicio S3
simultáneamente
Tema 5. Amazon Elastic File System (EFS)
Figura 10: Amazon Elastic File System
Fuente: [imagen sin título sobre Amazon Elastic File System], 2018, https://bit.ly/3jHL6gM.
Video 6. Introducción a Amazon Elastic File System: Procesamiento en Paralelo
Fuente: Amaz on Web Services (2 de junio de 2020). ¿Cómo puedo realizar una copia de datos en Amazon EFS maximizando el rendimiento
en paralelo? [archivo de video]. YouTube. https://n9.cl/f8pjp.
Amazon EFS (Elastic File System) es un servicio de almacenamiento de archivos  basa do en la
nube para aplicaciones y cargas de trabajo que se ejecutan en la nube pública de Amazon Web
Services. AWS implementa y administra automáticamente la infraestructura de EFS, que se
distribuye en una cantidad ilimitada de servidores para evitar “cuellos de botella” en el
rendimiento. 
Está diseñado para ajustar su escala hasta petabytes, según se requiera, sin interrumpir el
funcionamiento de las aplicaciones, mediante el aumento y la reducción automática de su
capacidad a medida que agrega o elimina archivos. De esta manera, se elimina la
necesidad de aprovisionar y administrar la capacidad para adaptarse al crecimiento.
(Amazon W eb Services, s.f., https://amzn.to/3iCpQJU) 
Dado que los patrones de carga de trabajo pueden variar según los clientes, EFS ofrece dos
clases de almacen amiento: estándar y acceso poco frecuente. Es bastante usual que los clientes
encuentren que el 80 % de sus archivos es de acceso poco frecuente y que solo el 20 % se utiliza
de forma activa. “Amazon EFS sumi nistra de forma transparente los archivos de ambas clases de
almacenamiento en un espacio de nombres de sistema de archivos común” (Amazon Web
Services, s.f., https://amzn.to/3iCpQJU). 
Las principales características de este servicio son:
Usa el protocolo NFS: EFS “proporciona un almacenamie nto de sistema de archivos [NFS]
compartido para cargas de trabajo de Linux” (Amazon Web Services, s.f.,
https://amzn.to/3iCpQJU). 
Es escalable : “A medi da que un sistema de archivos crece y puede ampliarse a niveles de
mayor rendimiento durante período s breves para admitir las necesidades de rendimiento
impredecibles de las cargas de trabajo de archivos” (Amazon Web Services, s.f.,
https://amzn.to/3iCpQJU). 
Aumenta y reduce la capacidad de almacenamiento automáticamente : “El usuario no
tiene que preocuparse por la administración de servidores o almacenamiento de archivos, la
actualización de hardware, la configuración de software o la realización de copias de
seguridad” (Amazon W eb Services, s.f., https://amzn.to/3lYIcH1).
Tiene alta disponibilidad y durabilidad : “Todos los archivos y directorios están
almacenados de forma redundante en varias zonas de disponibilidad en una misma región”
(Amazon W eb Services, s.f., https://amzn.to/3lYIcH1). 
Algunos de los usos más comunes de AWS EFS pueden ser para el almacenamiento de
archivos de aplicaciones empresariales, para cargas de trabajo y aplicaciones, incluyendo
big data, o tamb ién para flujos de trabajo de procesamiento, gestión de contenido o
websites. (Nubersia, s.f., https://bit.ly/3xHZg6m) 
Rendimiento y cargas de trabajo
Figura 1 1: Rendimiento y cargas de trabajo
Fuente: Nubersia, s.f., https://bit.ly/3xHZg6m
El rendim iento del sistema va en función del tamaño del sistema de archivos, aunque
soporta picos altos de lectura/escritu ra. Cualquier sistema de archivos EFS creados podrá
soportar picos de 100 MB de lectura/escritura por segundo.
Para los sistemas de archivos super iores a 1 TB, Amazon Web Services te adjudicará 100
MB de más por cada TB para los picos de más carga de trabajo, por lo que, si dispones de
un sistema de archivos de 3 TB de almacenamiento, el sistema soport ará picos de hasta
300 MB de carga por segundo. (Nubersia, s. f., https://bit.ly/3xHZg6m)
¡Vamos a practicar!
Si querés conocer más sobre cómo utilizar la plataforma de Amazon y poner a prueba tus
conocimientos, te dejamos la siguiente actividad.
Video de habilidades
¿Se pueden utilizar los servicios de Amazon sin utilizar , por lo menos, un
servicio Core (Servicio Principal)?
Verdadero
Falso
Justificación
¿Amazon S3 es un servicio exclusivo de Backups de Almacenamiento en la
nube?
Verdadero
Falso
Justificación
Una vez que seleccionamos un tipo de instancia, y creamos un servidor , no
podremos cambiarlo jamás.
Verdadero
Falso
Justificación
Los cambios de Instancia, ya sea a una instancia con mejores cualidades,
o de calidad inferior , requiere que el usuario realice un contacto con el
Soporte de Amazon.
Verdadero
Falso
Justificación
¿Por qué debe ponerse en modo “Stop” la instancia previamente para
realizar un cambio de la misma?
Porque es un requerimiento legal de Amazon W eb Services.
Porque es necesario que el hardware se apague para que el personal de Amazon lo
modifique físicamente.
Porque si la instancia (servidor) se está ejecutando, contiene datos que pueden
perderse al realizarle una modificación en el hardware en tiempo real.
Porque si no lo hacemos, se estropeará el hardware actual e impedirá la
actualización del mismo.
Porque el usuario debe manualmente realizar los cambios de hardware y para
precaución de sí mismo, debe apagar el hardware.
Justificación
Cierre
Introducción a los servicios centra les de Amazon Web Services: Amazon Web Services ofrece a
sus clientes un amplio conjunto de servicios agrupados según la natur aleza o solución que aporta
cada uno de ellos. Estos servicios contribuyen con las empresas a reducir los costos de IT
(tecnologías de la información) y escalar .
Servicios de cómputo: La capacidad de cómputo hace referencia a la capacidad de brindar  la
infraestructura necesaria para que los productos funcionen de manera eficiente y rápida. Dentro de
este grupo, Amazon EC2 es probablemente uno de los servicios más famosos e importantes. Se
trata de capacidad  de cómputo (hardware) en modo servicio y con la característica principal de la
elasticidad.
Introducción a los servicios de almacenamiento:
El almacenamiento en la nube es un modelo de informática en la nube que almacena datos en
internet a través de un proveedor de cloud que administra y opera el almacenamiento como un
servicio. Se ofrece bajo demanda con capacidad y costo oportunos, y elimina la necesidad de tener
que comprar y administrar su propia infraestructura de almacenamiento de datos. Esto le otorga
agilidad, escala global y durabilidad con acceso a los datos en cualquier momento y lugar .
Elastic Block Store (EBS): Amazon Elastic Block Store (EBS) es un servicio de almacenamiento de
bloque de alto rendimiento diseñado para usar EC2, tanto en cargas de trabajo intensivas de
rendimiento como  de transacciones, a cualquier escala, como en base s de datos relacionales y no
relacionales, aplicaciones empresariales, aplicaciones en contenedores , motores de análisis de big
data, sistemas de archivos y flujos de trabajo de medios.
Amazon S3 (Simple Storage Serv ice): “Es el servicio principal de AWS para el almacenamiento y
recuperación de archivos mediant e una API. Utilizando esta API, los programadores pueden
desarrollar aplicaciones para almacenar y recuperar archivos de manera ágil y segura”
Amazon Glacier:  Amazon S3 Glacier es un servicio de almacenamiento, “extensión” de S3 para
archivos que van a tener una tasa reducida de acceso. “Es un servici o de costo extremadamente
bajo, que ofrece almacenamiento seguro, duradero y flexible para archivos y copias de seguridad de
datos”
Amazon Elastic File System (EFS): Amazon EFS (Elastic File System ) es un servicio de
almacenamiento de archivos basado en la nube para aplicaciones y cargas de trabajo que se
ejecutan en la nube pública de Amazon Web Services. AWS implementa y administra
automáticamente la infraestructura de EFS, que se distribuye en una cantidad ilimitada de servidores
para evitar “cuellos de botella” en el rendimiento.
Referencias
[Imagen sin título de Amazon Glacier ]. (2017). MPS360.
https://www .msp360.com/resources/wp-content/uploads/2017/1 1/AWS-Glacier-Pricing-3-
350x250.png.
[Imagen sin título sobre Amazon EC2]. (s.f.). Benjamín Garrido. https://b enjagarrido.com/wp-
content/uploads/2020/03/Amazon_A WS_EC2.jpg.
[Imagen sin título sobre Amazon Elastic File System ]. (2018). RnD Solutions. https://rnd-
solutions.net/2018/05/10/how-to-scale-aws-efs-elastic-file-system/.
[Imagen sin título sobre Amazon S3] (2022). Aprender Big Data.
https://aprenderbigdata.com/amazon-s3/.
Amazon Web Services  (2 de junio de 2020). ¿Cómo puedo realizar una copia de datos en
Amazon EFS maximizando el rendimiento en paralelo?  [archivo de video]. YouTube.
https://www .youtube.com/watch?v=sPp0DW9kgng
Amazon Web Services  (28 de agosto de 2015). Introduction to Amazon EC2 - Elastic Cloud
Server & Hosting with AWS [archivo de video]. YouTube. https:// www .youtube.com/watch?
v=TsRBftzZsQo.
Amazon Web Services Latin America  (20 de abril de 2019). Glacier Deep Archive  – Spanish
[archivo de video]. YouTube. https://www .youtube.com/watch?v=ImfskSQ9dxM.
Amazon Web Services  (s.f.). Tipos de instancias de Amazon EC2. Amazon AWS.
https://aws.amazon.com/es/ec2/instance-types/.
Amazon Web Services  (s.f.). Ciclo de vida de la instan cia. Amaz on AWS.
https://docs.aws.amazon.com/es_es/A WSEC2/latest/UserGuide/ec2-instance-lifecycle.html.
Amazon Web Services . (2020). Amazon Elastic Compute Cloud: Guía del usuario de instancias
de Linux. Amazon AWS. https://docs.aws.amazon.com/es_es/A WSEC2/latest/UserGuide/ec2-
ug.pdf#compute-optimized-instances.
Amazon Web Services . (s.f.). Características de AWS Lambda . Amazon AWS.
https://aws.amazon.com/es/lambda/features/.
Amazon Web Services . (s.f.).  Almacenamiento en la nube . Amaz on AWS.
https://aws.amazon.com/es/what-is-cloud-storage/.
Amazon Web Services . (s.f.).  Amazon Elastic Block Store . Amaz on AWS.
https://aws.amazon.com/es/ebs/?ebs-whats-new .sort-by=item.additionalFields.postDateT ime&ebs-
whats-new .sort-order=desc.
Amazon Web Services . (s.f.). Características de Amazon EBS. Amazon AWS.
https://aws.amazon.com/es/ebs/features/.
Amazon W eb Services . (s.f.). Amazon S3. Amazon AWS. https://aws.amazon.com/es/s3/.
Amazon Web Services . (s.f.). Características de Amazon S3. Recup erado de
https://aws.amazon.com/es/s3/features/.
Amazon Web Services  (s.f.). ¿Qué es Amazon S3? Amazon AWS.
https://docs.aws.amazon.com/es_es/AmazonS3/latest/userguide/W elcome.html. 
Amazon Web Services . (s.f.). Preguntas frecuen tes sobre Amazon S3 Glacier . Amazon AWS.
https://aws.amazon.com/es/glacier/faqs/.
Amazon Web Services . (s.f.). Amazon S3 Glacier y S3 Glacier Deep Archive . Amazon AWS.
https://aws.amazon.com/es/glacier/.
Amazon Web Services . (s.f.). Características de Amazon Glacier . Amazon AWS.
https://aws.amazon.com/es/glacier/features/.
Amazon Web Services . (s.f.). Amazon Elastic File System . Amazon AWS.
https://aws.amazon.com/es/efs/.
Amazon Web Services . (s.f.). Características de Amazon EFS. Amaz on AWS.
https://aws.amazon.com/es/efs/features/.
Arquitectura AWS (31 de julio de 2017). Cómo crear funcio nes o microservicios en AWS Lambda
[archivo de video]. YouTube. https://www .youtube.com/watch?v=mUGx2brCsAI.
Barr, J. (20 de marzo de 2014). ELB Connection Draining – Remove Instances From Service With
Care. Amazon AWS. https://aws.amazon.com/es/blogs/aws/elb-connection -draining-remove-
instances-from-service-with-care/. 
Carvajal, R. (20 de mayo de 2020). Funciones Lambda (AWS): ¿Qué son y cómo funciona esta
tecnología? [archivo de video]. YouTube. https://www .youtube.com/watch?v=oCE8LlcHtbw .
González, J. M. (2018). ¿Qué es Amazon Elastic Load Balancing?  Recuperado de
https://www .josemariagonzalez.es/amazon-web-services-aws/que-es-amazon-elastic-load-
balancing.html.
López, D. (2 de diciembre de 2016). Amazon S3, excelente servicio  de almacenamiento en la
nube [archivo de video]. YouTube. https://www .youtube.com/watch?v=CNE2KifiF18.
Nubersia (s.f.). AWS Elastic File System . Nubersia. https://www .nubersia.com/es/blog/aws-elastic-
file-system/.
Oré Vilchez, E. D. (2022). Almacenamiento en la nube. LinkedIn.
https://www .linkedin.com/pulse/almacenamiento-en-la-nube-eber-daniel-or%C3%A9-vilchez/?
originalSubdomain=es. 
Red Hat. (s.f.).  El concepto de la integración empresarial . Red Hat.
https://www .redhat.com/es/topics/integration.
Rootstack (2023). AWS Amplify vs AWS Lambda: diferencias de ambas herramientas . Rootstack.
https://rootstack.com/es/blog/aws-amplify-vs-aws-lambda-diferencias-de-ambas-herramientas. 
Sielva, B. (2017). Cloud Computing:  servicios principales de Amazon Web Services . Belike.
https://www .belikesoftware.com/cloud-computing-servicios-principales-de-amazon-web-service/.
TP-Link Techno logies  (s. f.). Balanceador de carga [imagen] . Static. https://s tatic.tp-
link.com/res/images/products/gallery/TL-R480T%2B.jpg.
A continuación podrás descargar la lectura en formato PDF o MP3:


----- M3-Lectura.pdf -----
Módulo 3. Base de datos y redes
Video de inmersión
Unidad 1. Servicios de redes y bases de datos
Tema 1. Virtual private cloud
Figura 1: Virtual private cloud  (VPC)
Fuente: Neeru, 2017, https://bit.ly/2XodQ6L.
Video 1: Introducción a virtual private cloud  en español
Fuente: Kalerolinex (2017). AWS050: VPC - Ejemplo gráfico de una V irtual Private Cloud [archivo de video]. YouTube. https://n9.cl/uhgyd.
“Amazon Virtual Private Cloud (Amazon VPC) le permite lanzar recursos de AWS en una red
virtual que haya definido” (Amazon Web Services, s.f., https://amzn.to/2UcJvqD). Se trata de una
red perso nalizable que nos permite definir un rango propio de direcciones IP, agregar y eliminar
subredes, crear rutas, agregar puertas de enlace VPN (virtual private netw ork), asociar políticas
de seguridad, conectar instancias EC2 (elastic compute cloud) a nuestr o propio centro de datos,
entre otras tantas funcionalidades.
Al principio, cuando la VPC no estaba disponible, todas las instancias de EC2 en la zona de
disponibilidad se encontraban en una única red plana que se compartía entre todos los clientes.
¿Qué tan cómodo se sentía el cliente al poner su información en la nube? No mucho. Entre el
lanzamiento de EC2 en 2007 y el lanzamiento de VPC en 2009, las funciones de VPC fueron
algunas de las características más solicitadas de AWS.
Figura 2: Estructura de VPC
Fuente: Open Data Science, 2020, https://bit.ly/37D59Y8.
Desde diciembre de 2013, todas las instancias EC2 son solo de VPC. Es decir , ya no es posible
crear una instanci a EC2 que no sea VPC (EC2-Classic). Si usamos un asistente de lanzamiento
para crear nuestra  instancia EC2, se colocará automáticamente en una VPC predeterminada con
una puerta de enlace de Internet virtual para acceso público. 
Video 2: Creación de una virtual private cloud con todos sus componentes en español
Fuente: Arquitectura AWS (2017). Cómo crear una red VPC, security groups, Gateway , ACL en ambiente de alta disponibilidad en AWS
[archivo de video]. YouTube. https://n9.cl/nvris.
Amazon Virtual Private Cloud  es un servicio que nos permite provisionar una sección
aislada de forma lógica en la red de Amazon Web Services  (AWS) donde poder lanzar
recursos de AWS en una red que se defina. Permite seleccionar el rango de direcciones IP
que se desee, la creación de subredes y configuración de tablas de enrutamiento y puertas
de enlace de red.
       
Un ejemplo de configuración habitual es crear una subred para los servidores que
necesiten acceso a Internet, y otra subred, para los sistemas de backend como bases de
datos y servidores  de aplicaciones, de uso privado sin acceso a Internet. También permite
crear una red privada virtual (VPN) de hardware para conectar un centro de datos con la
VPC.
Características, consideraciones técnicas y best practises:
La limitación de rango y clases de IP en las redes es de /16, es el recomendado
para poder “jugar” y no tener limitaciones a la hora de escoger direccionamiento.
En el caso de las subredes la limitación de rango de IP es /24 y tambié n es el
recomendado.
Permite la utilización de dhcp . En la mayoría de los casos es muy interesante el
utilizarlo, ya que, dada la elasticidad de los servicios de AWS al levantar una nueva
instancia, se le asigna una IP  del rango seleccionado por el dhcp.
Dividir el rango privado de direcciones IP en la VPC en una o varias subredes
públicas o privadas. Dentro de la VPC es muy interesante dividir subredes, una para
la parte pública asignando un "internet gateway" para darle acceso a Internet y otra
para la parte privada. También se pueden crear otras subredes para otro tipo de
comunicaciones o conexiones entre aplicaciones o servicios que puedan interesar .
Elastic IP. Para que las instancias que están dentro de la VPC puedan alcanzarse
desde Internet, es posible utilizar las IP fijas que ofrece AWS. Como excepción, es
posible utilizar un servidor “de salto” (Bastion host), que tenga una IP pública y se
conecte a las demás instancias dentro de la VPC mediante las IP privadas de las
mismas.
VPC Peering . En el caso de tener infraestructuras en varios países, cuando se hace
necesario el conectar unas VPC con otras, e incluso con VPC de distinta s cuentas de
AWS, se utiliza este tipo de conexión. AWS aprovecha la infraestructura  que crea la
VPC para crear una conexión VPC Peering. Consiste en crear una conexión de red
entre 2 VPC que permite enrutar el tráfico entre ellas a través de las direcciones
privadas de las mismas, como si estuvieran dentro de una misma red, lo que facilita
la transferencia de datos y el acceso a los recursos.
Utilización de Listas de Control de Acceso (ACL). En algunos casos puede
resultar interesante controlar el tráfico a nivel de subredes filtrando el acceso de
entrada y salida entre las mismas.
Utilizar Security Groups . Es el firewall que AWS ofrece para gestionar el acceso a
IP y puertos. Es primordial utilizar esta capa para restringir los accesos y dotar de
seguridad a la VPC.
VPN. Si se desea (aunque es recomendable), se puede enrutar todo el tráfico
proveniente y dirigido a las instancias de la VPC mediante una conexión VPN
encriptada. Hay diferentes casos de uso y distintas configuraciones con respecto a
las VPN:
Mediante un túnel ipsec . Si tenemos parte de la infraestructura en un centro de
datos y queremos  conectarlo con la VPC de AWS, podemos realizar una conexión
IPsec encriptada.
AWS Direct Connect . Es un servicio de AWS que estab lece una conexión de red
privada dedicada desde un centro de datos, oficina o entorno de coubicación, a AWS.
La conexión se puede particionar en varias interfaces virtuales. Así, con la misma
conexión, podemo s acceder mediante una interfaz virtual a servicios de Amazon o
recursos que estén en la parte pública. Y mediante otra interfaz virtual, podemos
acceder a recurso s privados dentro de la VPC. Con ello se mantiene el aislamiento
de la red.
Instalando en una instancia dentro  de la VPC un servidor de VPN como, por ejemplo,
OpenVPN y que todo el tráfico pase por esa instancia. (Ibáñez  y Marco, 2017,
https://bit.ly/3CIxn1J)
Figura 3: Amazon W eb Services
Fuente: Ibáñez y Marco, 2017, https://bit.ly/3CIxn1J.
Integración con otros recursos de AWS
Se integra con servicios de AWS como EC2, IAM, S3, Amazon RDS, Dyna moDB, SQS,
SNS, ECS, etc. ¿Qué podemos obtener de esas integraciones? Entre otras, las siguientes
ventajas:
Levantar instancia s EC2 directamente dentro de una VPC, al igual que el servicio de
contenedores ECS.
Provisionar IP dentro de la VPC, de servicios y recursos de AWS, por ejemplo,
Amazon RDS, Load Balancer , Elasticache , etc.
Para limitar el acceso a los recurso s de AWS (como buckets de Amazon S3, temas
de Amazon SNS y colas de Amazon SQS), se pueden crear directrices de IAM que
limiten el acceso a dichos recurs os únicamente a las direcciones IP elásticas
asociadas con la VPC. (Ibáñez y Marco, 2017, https://bit.ly/3CIxn1J)
Tema 2. Amazon Relational Database Service (RDS)
Figura 4: Amazon Relational Database Service
Fuente: [Imagen sin título sobre Amazon RDS], s.f.,  https://images.app.goo.gl/BzE9zuNpEe1CGkgA6.
Video 3: Introducción a Amazon RDS
Fuente: Amazon Web Services (2018). Underst anding Amazon Relational Database Service (RDS) [archive de video]. YouTube.
https://n9.cl/x03r0.
Amazon Relational Database Service o Amazon RDS es un servicio de base de datos en
la nube administr ado de AWS. Fue diseñado para simplificar la creación, operación,
administración y escalado de una base de datos relacional para su uso como backend de
aplicación. AWS lanzó el servicio RDS inicialmente en octubre de 2009 con soporte para
MySQL. Con el paso de los años, el servicio RDS agregó servicios administrados para
otras bases de datos como SQL Server , Oracle Database, Postgr eSQL  y MariaDB.
(Krishna, 2020, https://bit.ly/3lUDudp)
El caballo de batalla de Amazon es RDS para AWS
RDS es uno de los servicios más populares en AWS y cuenta con una amplia gama de
clientes que buscan reducir la dependencia de sus DBA y permiten que su personal
existente opere más bases de datos de las que podían hacerlo anteriormente . . .
       
La transferencia de una parte importante de la administración de la infraestructura a AWS
permitió a los equipos pequeños concentrarse en un trabajo de mayor valor agregado. Al
mismo tiempo, AWS aprovechó esta oportunidad para fortalecer su oferta de productos y
servicios, un beneficio mutuo para ambas partes. RDS ahora cuenta con muchos clientes
empresariales como Unilever , Airbnb, Netflix y Expedia, lo que demuestra la capacidad, la
conveniencia y el valor que brinda el servicio. (Krishna, 2020, https://bit.ly/3lUDudp)
Características de Amazon RD
Gastos administrativos más bajos
Figura 5: Características de Amazon RD
Fuente: Krishna, 2020, https://bit.ly/3lUDudp.
Es muy fácil de usar
AWS ofrece varias  formas de acceder y administrar el servicio RDS, incluida la Consola de
administración de AWS, la Interfaz de línea de comandos (CLI) de RDS y las llamadas a la
API REST . Tras la invocación de un proceso de creación de instancias de RDS con
parámetros prede finidos, se activa una instancia de RDS y está lista para su uso en
cuestión de minutos. Los admi nistradores continúan tenie ndo acceso a los parámetros
de configuración de la base de datos que pueden modificar para obten er un rendimiento
óptimo de su instancia de RDS. (Krishna, 2020, https://bit.ly/3lUDudp)
Parcheo automático de software de Amazon RDS
Amazon maneja el parche del sistema operativo subyacente y la base de datos aliviando la
carga de los administradores de la base de datos. Sin embargo, los administradores de
RDS siguen teniendo la opción de decidir cuándo aplicar un parche a la instancia de RDS.
Amazon RDS se asegura de que el software de base de datos relacional que impulsa su
implementación se mantenga actual izado con los últimos parches. Puede ejercer control
opcional sobre cuándo y si su instancia de base de datos requiere parches . (Krishna,
2020, https://bit.ly/3lUDudp)
Motor de recomendación de Amazon RDS
El servicio Amazon RDS ejecuta miles de bases de datos para varios clientes, lo que les
permite identificar las mejores prácticas para lograr una utilización, seguridad y
rendimiento óptim os de la insta ncia RDS. Los clientes de RDS reciben estas
recomendaciones. Pueden evaluar la validez de las recomendaciones y tomar las acciones
adecuadas según sus preferencias o ignorar la sugerencia. (Krishna, 2020,
https://bit.ly/3lUDudp)
Rendimiento de Amazon RDS
Los usuarios pueden elegir entre una gran cantidad de opciones de procesamiento y
almacenamiento que están disponibles en Amazon RDS. El almacenamiento respaldado
por SSD admite casos de uso de IOPS [Input and Output por Seco nds]. Medición de
escritura y lectura, útil para evaluar si un disco puede ser usado para almacenar bases de
datos] aprovisionados y de uso general. (Krishna, 2020, https://bit.ly/3lUDudp)
Escalabilidad de instancias de RDS
El almacenamiento, la computación y la memoria son los tres aspectos de una base de
datos donde se requiere escalabilid ad. RDS ofrece una opción de escalabilidad de botón
para los administr adores y les perm ite agregar más almacenamiento a su instancia de
RDS o escalar hacia arriba o hacia abajo la computación y la memoria asignada a la
instancia. Las opciones de escalabi lidad de almacenamiento varían según el tipo de RDS
en uso, es decir , MySQL, Oracle, SQL Server y otros. No se requiere tiempo de inactividad
para aprovisionar almacenamiento adicional para una instancia de RDS. Actualmente,
RDS limita las operaciones de escalado a un máximo de 32 CPU virtuales y 244 GiB de
memoria. Escalar la computación implica tomar un tiempo de inactividad , aunque el tiempo
de inactividad generalmente dura solo unos minutos. (Krishna, 2020, https://bit.ly/3lUDudp)
Réplicas de lectura de Amazon RDS
RDS es una base de datos de instancia única. Como resultado, el usuario solo puede
escalar para abordar la creciente  demanda de cargas de trabajo de escritura. Sin
embargo, RDS también ofrece la capacidad de crear múltiples réplica s de lectura para
atender solicitudes de lectura provenientes de usuarios de aplicaciones y usuarios de
bases de datos en la instancia de RDS. (Krishna, 2020, https://bit.ly/3lUDudp)
Copias de seguridad y recuperación automatizadas RDS
Amazon RDS crea automáticamente copias de seguridad de la instancia y admite la
recuperación en un momento determ inado. Amazon RDS realiza una copia de seguridad y
almacena los registros de la base de datos y los registros de transacciones durante un
período de retención específico  que selecciona un usuario. (Krishna, 2020,
https://bit.ly/3lUDudp)
Instantáneas de la base de datos de Amazon RDS
Los usuarios pueden iniciar instantáneas de la base de datos para almacenarlas en
depósitos de S3. Estas instantáneas son útiles en la creación de nueva s instancias como
instancias de desarrollo o prueba en cuestión de minutos. Las instantáneas también se
duplican como copias de seguridad de la base de datos. (Krishna, 2020,
https://bit.ly/3lUDudp)
Disponibilidad de Amazon RDS
Las insta ncias de RDS se pueden  implementar en varias zonas de disponibilidad para
aumentar la disponibilidad del servicio de base de datos. En una configu ración de zona de
disponibilidad múltiple, RDS garantiza que el modo de espera esté actualizado con la
instancia de RDS de producción. El inicio de un proceso de conmutación por error ocurre
automáticamente cuando falla una instancia de producción.
Es una buena práctica para los entornos de producción tener un modo de espera en
una zona de disponibilidad diferente, preferiblemente una región, para mitigar los
impactos de una falla completa de la zona de disponibilidad . Aunque estos casos son
raros, ocurren ocasionalmente. En caso de una falla de hardware subyacente, RDS
reemplaza el nodo de cálculo. (Krishna, 2020, https://bit.ly/3lUDudp)
Seguridad de Amazon RDS
Cifrado
Los servi cios de bases de datos en la nube pública generalmente, vienen con capacidades
de cifrado en reposo y en tránsito. RDS ofrece sólidas capacidade s de cifrado. Los
usuarios pueden optar por administrar sus claves de cifrado mediante AWS Key
Management Service (KMS). Las capacidades de cifrado no se limitan a la instancia de
producción. Todas  las instantáneas, copias de seguridad, réplicas de lectura y nodos en
espera también están cifrados. SSL se utiliza para proteger los datos en tránsito. (Krishna,
2020, https://bit.ly/3lUDudp)
Redes
El énfasis en la seguridad en la capa de red también es vital. Una instancia de base de
datos se puede aislar del resto del entorno ejecutando la instancia en su VPC. RDS
también está bien integrado con servicios de AWS como firewall y VPN. (Krishna, 2020,
https://bit.ly/3lUDudp)
AWS Identity and Access Management
AWS Identity and Access Management (IAM) se integra con todos los servicios de AWS.
IAM permite a los clientes controlar el acceso a las instancias de RDS y otros recursos de
la nube que se ejecutan en AWS. Los controles de acceso basados en roles otorgan
permisos específicos a los usuarios sobre las acciones que pueden realizar en la instancia
de RDS. (Krishna, 2020, https://bit.ly/3lUDudp)
Capacidad de gestión y supervisión de RDS
Amazon CloudW atch captura métricas como el uso de CPU y memoria, E / S y actividad
de conex ión para las instancias de RDS sin cargo adicional. Los potentes mecanismos de
alerta garantizan que los problemas críticos se comuniquen a una audiencia adecuada
inmediatamente después de que ocurra cualquier problema. (Krishna, 2020,
https://bit.ly/3lUDudp)
Precios de RDS
Los precios de RDS son similares a otros servicios de bases de datos de AWS como
Amazon Redshift.  Pago por uso y precios de instancia reservada con compromisos de
varios años disponibles para que los clientes elijan. El precio de pago por uso se aplica a
entornos inferiores, mientras que los entornos de producción y de espera suelen
ejecutarse en instancias reservadas. (Krishna, 2020, https://bit.ly/3lUDudp)
Tabla 1: Pros y contras de Amazon RDS
Pros Contras
Aplicación de parches automatizadaEl parch e fuerza un tiempo de
inactividad
Copias de seguridad automatizadasSin escalamiento horizontal para
cargas de trabajo de escritura
Cifrado en reposo y en tránsitoTiempo de inactividad necesario para
escalar operaciones
Mejora significativa con respecto a las bases de
datos locales Sin ajuste automático del rendimiento
Integrado con el resto del ecosistema de AWSNo es una base de datos de
administración cero
No se necesita mantenimiento de hardware Sin gestión de particiones automatizada
Escalado simplific ado en comparación con las bases
de datos localesSin gestión de compresión
automatizada
Envío de registros  automatizado y réplica de lectura
y lectura Sin acceso de root al servidor
Recuperación ante desastres simplificada y
conmutación por error automáticaSin sopo rte nativo como réplica de
lectura para bases de datos locales
Asignación de almacenamiento adicional
automatizadaEl rendimiento de la CPU y el
almacenamiento no está garantizado
Recuperación en un momento determinadoNo se garantiza la pérdida de datos
cero
Fuente: Krishna, 2020, https://bit.ly/3lUDudp.
Tema 3. Amazon DynamoDBa
Figura 6: Amazon DymanoDB
Fuente: Squadex, 2018, https://bit.ly/3lYW yHA.
Video 4: Comprensión inicial de Amazon DynamoDB
Fuente: Amazon W eb Services (2012). Amazon DynamoDB - What's It All About? [archivo de vídeo]. YouTube. https://n9.cl/v22ac.
Introducción 
DynamoDB es una base de datos sin servidor NoSQL  proporcionada por AWS. Sigue una
estructura de tienda de valor clave y adopta una arquitectura distribuida para alta
disponibilidad y escalabilidad.
Como en cualquier sistema sin servidor , no se necesita  aprovisionamien to de
infraestructura. Dynamo ofrece dos modos de capacidad que pueden servir cargas de
trabajo altamente variables y predecibles.
Los datos se organizan en tablas, que contienen elementos. Cada elemento contiene un
conjunto de pares de atributos clave-valor . Hay dos tipos especiales de atributos: el
primary-key , que funciona de manera similar a un ID de artículo, y el sort-key , que
permite ordenar los artículos .
Dynamo admite índices secundarios. Se pueden utilizar para hacer referencia y ordenar
artículos por diferentes primary-key y sort-keys. Es una base de datos sin esquema, en la
que los elementos pueden tener diferentes conjuntos de atributos. Esto permite índices
dispersos: compue stos solo por elementos que contienen un atributo particular . (Dashbird,
2020, https://bit.ly/3xFHX69)
Conceptos principales
Tabla: como colección que puede contener una cantidad prácticamente  infinita de
elementos, también puede tener índices secundarios asociados.
Índice secundari o: duplica elementos de la tabla utilizando un diferente primary-key  y
sort-key .
Ítem: la unida d más básica en Dynamo, contiene los atributos de datos estructurados en
un JSON.
Atributo : un par clave-valor que contiene puntos de datos informativos sobre un elemento
en la tabla de la base de datos.
Clave principal : una forma especial de atributo que se utiliza para hacer referencia  a
elementos, de manera similar a un ID de elemento.
Clave de clasificación : otra forma espe cial de atributo que se utiliza para organizar
elementos en un orden de clasificación diferente.
Flujos : un flujo constante de operaciones de cambio de estado ejecutadas contra una
tabla.
Consulta : operación para recuperar un elemento en particular (o conjunto de elementos).
Escanear : operación para escanear toda la tabla o una sección de ella.
Filtro : reglas para aplicar después de que se haya ejecutado una consulta  o escaneo,
pero antes de que los resultad os se devuelvan al solicitante. (Dashbird, 2020,
https://bit.ly/3xFHX69) 
Visión general
DynamoDB tiene dos tipos básic os de modelos de precios, segú n los modos de
capacidad:
Capacidad aprovisionada.
Capacidad bajo demanda.
Como sugiere el nombre, bajo demanda asignará recursos a medida que la aplicación los
necesite, sin ningún aprovisionamiento previo. Todos los costos se cobran por uso.
    En el modo de capacidad previst a, los desarrolladores pueden elegir cuántos recursos
recibirá cada tabla de base de datos. También pueden elegir si Dynamo DB puede escalar
automáticamente los recursos si es necesario, o si la base de datos debe comenzar a
limitar las solicitudes una vez que se alcanza la capacidad aprovis ionada. (Dashbird,
2020b, https://bit.ly/2VHkd4L) 
Conceptos básicos
Operación de lectura : una llamada a la API para leer datos de una tabla de DynamoDB.
Operación de escritura : una llamada a la API para insertar , modificar o eliminar un
elemento en una tabla de DynamoDB.
Cada operación de lectura puede leer hasta 4 KB de datos. Si el elemento es más grande,
DynamoDB cobrará varias operaciones de lectura, redondeadas al siguiente múltiplo de 4
KB. Las lecturas consistentes eventuales se cobran solo la mitad de la operación. Las
operaciones de lectura dentro de las transacciones se cobran el doble del precio normal.
Cada operación de escritura puede escribir hasta 1 KB de datos. Para elementos más
grandes, Dynamo DB cobrará varias operaciones de escritura, redondeadas al siguiente
múltiplo de 1 KB. Las operaciones  de escritura dentro de las transacciones cuestan el
doble del precio normal.
[Debemos tener en cuenta que] . . . al utilizar índices secundarios, DynamoDB necesita
replicar todos los cambios de la tabla principal en los índices. Se contará una operación de
escritura adicional por cada índice asociado. (Dashbird, 2020b, https://bit.ly/2VHkd4L)
Precios bajo demanda
La operación de escritura cuesta $ 1.25 por millón  de solicitudes.
La operación de lectura cuesta $ 0.25 por millón  de solicitudes.
    El uso de la capacidad se cobra por unidades. Si la base de datos no llega a un millón
de opera ciones, no se redondea al millón más cercano, sino que se cobra solo por las
solicitudes realmente utilizadas.
    No es posible comprar capacidad reservada a precios con descuento en el modo On-
Demand.
Dynamo también cobra la cantidad de datos almacenad os al precio  de $ 0.25 por GB al
mes.
Las copias de seguridad se modifican de la siguiente manera:
Recuperación en un momento determinado : 0,20 USD por GB al mes.
A pedido (instantánea):  0,10 USD por GB al mes.
Restauración de una copia de seguridad : $ 0.15 por GB.
DynamoDB ofrece  Global Tables , un sistema de replicación automatizado de múltiples
regiones. Se cobra a $ 1.875 por millón de operaciones de escritura  replicadas.
DynamoDB corrie ntes tienen un coste de $ 0,02 por cada 100.000 operaciones de
lectura.
Los datos  solicitad os por solicitantes fuera de la región de AWS donde se implementa la
tabla de DynamoDB se cobran a $ 0.09 por GB.  (Dashbird, 2020b, https://bit.ly/2VHkd4L)
Nivel gratuito a pedido
La capa  gratuita de AWS le permite adquirir experiencia práctica sin cargo en los
servicios de AWS. Los siguientes beneficios de DynamoDB se incluyen como parte de la
capa gratuita de AWS. Cada benefic io se calcula mensualmente de acuerdo con la región
y la cuenta de pago.
25 GB de almacenamiento de datos.
2,5 millones de solicitudes de lectura de streams de DynamoDB Streams.
Se añaden 1 GB de transferencia [saliente] de datos. (Dashbird, 2020b,
https://bit.ly/2VHkd4L)
Precios aprovisionados
La operación de escritura se cobra a $ 0,00065  por unidad de capacidad por hora.
       
La operación de lectura se cobra a $ 0,00013  por unidad de capacidad por hora.
    En el modo aprovisionado, DynamoDB aprovisionará la capacidad y la cargará cuando
esté disponible. Observe que es un modelo diferente en comparación con on-demand, que
cobra por solicitud.
En el modo aprovisionado, la aplicación puede emitir varias consulta s de lectura, por
ejemplo, y cobrar solo una unidad de capacidad. Si todas las solicitudes son secuenciales,
consumen la misma capacidad de lectura asignada.
Es posible reservar capacidad por adelantado con un compromiso mensual en trozos de
100 unidades de capacidad (lectura o escritura). El precio es el siguiente:
100 operaciones con capacidad de lectura reservada: $ 150.00 (1 año, pagado por
adelantado) o $ 0.0128 por hora.
100 operaciones con capacidad de lectura reservada: $ 30.00 (1 año, pagado por
adelantado) o $ 0.0025 por hora.
La capacidad reservada puede reducir drásticamente los costos con DynamoDB. Sin
embargo, si no se utilizan, no queda crédito para el siguiente ciclo de facturación.
Las tablas globales (replicación multirregional) se cobran a $ 0.000975  por capacidad de
lectura consumida.
Backup , DynamoDB Streams y transferencia de datos tienen el mismo precio que el modo
On-Demand. (Dashbird, 2020b, https://bit.ly/2VHkd4L)
Unidad 2. Elastic Load Balancer , autoescalado y Amazon
CloudW atch
Tema 1. Elastic Load Balancer (ELB)
Figura 7: Elastic Load Balancer
Fuente: González, 2019, https://bit.ly/2UbVkND.
Video 5: Explicación inicial de esta tecnología
Fuente: Cloud Academy (2019). What is an AWS Elastic Load Balancer (ELB)? - AWS Training [archivo de video]. YouTube. https://n9.cl/3gjd7.
Un Elastic Load Balancer (ELB) tiene la capacidad de escalar automáticamente los
balanceadores de carga y las aplicaciones según el tráfico en tiempo real. Debido a
la elasticidad, generalmente se implementa como un equilibrador de carga de software .
Utiliza verificaciones de estado del sistema para conocer el estado de los miembros del
grupo de aplicacio nes (servidores de aplicaciones) y enruta el tráfico de manera adecuada
a los servidores disponibles, admin istra la conmutación por error a los objetivos de alta
disponibilidad o activa automáticamente la capacidad adicional. (Avi Networks, 2020,
https://bit.ly/3CJXeGQ) 
Figura 8: Funcionamiento de Elastic Load Balancer
Fuente: Avi Networks, 2020, https://bit.ly/3CJXeGQ.
¿Qué es Elastic Load Balancing?
Elastic Load Balan cing escala el tráfico a una aplicación a medida que la demanda cambia
con el tiempo. También escala las instancias de equilibrio de carga de forma automática y
bajo demanda. Dado que el equilibr io de carga elástico utiliza algoritmo s de enrutamiento
de solicit udes para distribuir el tráfico de aplicaciones entrante en varias instancias o
escalarlas según sea necesario, aumenta la tolerancia a fallas de sus aplicaciones. (Avi
Networks, 2020, https://bit.ly/3CJXeGQ)
¿Cómo funciona un Elastic Load Balancer?
Elastic Load Balancing escala su balanceador de carga a medida que cambia el tráfico
hacia sus servido res. Enruta el tráfico de aplicaciones entrante a través de instancias
automáticamente. El equilibrador de carga elástico actúa como punto de contacto para el
tráfico entrante y, al monitorear el estado de las instancias, el servicio de equilibrio de
carga elástico puede enviar las solicitudes de tráfico a las instancias en buen estado. (Avi
Networks, 2020, https://bit.ly/3CJXeGQ)
Figura 9: Esquema de un load balancer
Fuente: V inoth, s.f., https://bit.ly/2Xh07yp.
¿Cuáles son las diferencias básicas entre Classic Load Balancer y Application Load
Balancer?
AWS Classic Load Balancer (CLB)  se parece más al equilibrio de carga tradicional, pero
los dispositivos virtuales reemplazan  el hardware físico para distribuir de manera uniforme
las solicitudes entrantes y garantizar una experiencia de usuario limpia y rápida.
AWS Application Load Balancer (ALB)  identifica el tráfico entrante y lo dirige al tipo de
recurso correcto. Por ejemplo, las URL etiquetadas con extensiones [o las] API se pueden
enrutar a los recursos de la aplica ción apropiados, mientras que el tráfico destinado a
dispositivos móviles, se puede dirigir a los recursos que administran el acceso móvil.
(Sumo Logic, 2019, https://n9.cl/86knz)
¿Qué balanceadores de carga son compatibles con EC2 Classic?
“Classic Load Balancer admite EC2 Classic, mientras que Application Load Balancer no lo hace”
(Sumo Logic, 2019, https://n9.cl/86knz). 
¿Cuántos balanceadores de carga necesitamos?
Como práctica recomendada, desea al menos dos equilibradores de carga en un par
agrupado. Si solo tiene un equilibrador de carga y falla por cualquie r motivo, todo su
sistema fallará. Esto se conoce como punto único de falla (SPOF). Con los balanceadores
de carga, el número que necesita depende de la cantidad de tráfico que maneja y de la
disponibilidad de tiempo de actividad que desee. Generalmen te, cuantos más
balanceadores de carga tenga, mejor . (Sumo Logic, 2019, https://n9.cl/86knz)
Comprensión del equilibrador de carga clásico
El ELB clásico tiene una serie de funciones disponibles para ayudar a proporcionar alta
disponibilidad, monitoreo y mejor seguridad para su pila de aplicaciones.
AWS Classic Load Balancer (CLB) opera en la capa 4 del modelo OSI. Esto significa que
el equilib rador de carga enruta el tráfico entre los clientes y los servidores backend según
la dirección IP  y el puerto TCP.
Por ejem plo, un ELB en una dirección IP determinada recibe una solicitu d de un cliente en
el puerto  TCP 80 (HTTP). Luego, enrutará esa solicitud según las reglas configuradas
previamente al configurar el balanc eador de carga a un puerto específico en uno de un
grupo de servidores backend. En este ejemplo, el puerto en el que el equilibrador de carga
enruta al servidor de destino a menudo será el puerto 80 (HTTP) o 443 (HTTPS).
       
El servid or de destino backend cumplirá la solicitud del cliente y enviará los datos
solicitados al ELB, que luego reenvia rá la respuesta del servidor backen d al cliente. Desde
la perspe ctiva del cliente, esta solicit ud parecerá haber sido cumplida en su totalidad por el
ELB. El cliente no tendrá conocimiento del servidor backend o de los servidores que
satisfacen las solicitudes del cliente. (Sumo Logic, 2019, https://n9.cl/86knz)
Zonas de disponibilidad y ELB clásicas
Aunque es posible tener un solo servidor detrás de un equilibrador de carga, es mejor
tener un grupo de servidores detrás de un ELB. También es una buena práctica tener
varios servidores en varias zonas de disponibilidad dentro de una región para admitir la
alta dispo nibilidad. De esa manera, si una AZ deja de estar disponible por algún motivo, el
ELB puede enrutar el tráfico a las AZ que son accesibles y evitar la AZ inaccesible
mientras no esté disponible. 
       
Habilitar el equilibrio de carga entre  zonas ayudará a mitigar el posible desequilibrio de
carga y también garantizará una mejor disponibilidad de su aplicación. En aras de la
coherencia y la facilidad de manten imiento, también se recomienda mantener el mismo
número de instancias de destino en cada zona de disponibilidad. (Sumo Logic, 2019,
https://n9.cl/86knz)
Comprensión del balanceador de carga de aplicaciones
AWS Application Load Balancer (ALB) opera en la Capa 7 del modelo OSI. En la Capa 7,
ELB tiene la capac idad de inspeccionar el contenido a nivel de aplicación , no solo la IP y el
puerto. Esto le permite enrutar basándose en reglas más complejas que con el Classic
Load Balancer .
En otro ejemplo, un ELB en una IP determinada recibirá una solicitud  del cliente en el
puerto 443 (HTTPS). Application Load Balancer procesará la solicitud, no solo al recibir el
puerto, sino también al mirar la URL  de destino.
Varios servicios pueden compartir un solo equilibrador de carga median te el enrutamiento
basado en rutas. En el ejemplo que se da aquí, el cliente podría solicitar cualquiera de las
siguientes URL:
El Applic ation Load Balancer  conocerá  cada una de estas URL en función de los
patrones establecidos al configurar el equilibrador de carga y puede enrutar a
diferentes clústere s de servidores según las necesidades de la aplicació n. Las reglas
también se puede n agregar en un momento posterior a medida que agrega nuevas
funciones a su pila.
El Application Load Balancer  también se integra con EC2 Container Service (ECS)
mediante Service Load Balancing. Esto permite el mapeo dinámico de servicios a
puertos, como se especifica en la definición de tarea de ECS. Se pueden apuntar
varios contenedores en la misma instancia EC2, cada uno de los cuales ejecuta
diferentes servicios en diferentes puertos. El programador de tareas de ECS
agregará automáticamente estas tareas al ALB. (Sumo Logic, 2019,
https://n9.cl/86knz)
Conceptos clave de ALB
Hay algunos conc eptos clave que necesitará conocer al configurar su ALB. En primer
lugar , están las reglas. Cada regla especifica una condición, un grupo objetivo  y una
prioridad .
Las reglas  determinan qué acción se toma cuando una regla coincide con una solicitud
del cliente. Se pueden definir hasta 10 reglas basadas en URL  en el ALB.
La condición es el patrón de ruta que desea que el ALB evalúe para que pueda enrutar las
solicitudes.
El grupo objetivo  se utiliza para enrutar solicitudes a objetivos registrados como parte de
una acción para una regla. Los grupos de destino especifican un protocolo y un puerto de
destino. Las comprobaciones de estado se pueden configurar por grupo objetivo. Un ALB
puede dirigirse a varios grupos objetivo.
Los objetivos  especifican los puntos finales y se registran en el ALB como parte de un
grupo objetivo.
La prioridad  le dice al ALB en qué orden evaluar las reglas. Las reglas se evalúan
numéricamente en orden de menor  a mayor valor . Cuando una regla coincide con una
solicitud, el tráfico se enrutará al grupo objetivo especificado. (Sumo Logic, 2019,
https://n9.cl/86knz)
Tema 2. Auto scaling  (autoescalamiento) 
Figura 10: Auto scaling
Fuente: González, 2019, https://bit.ly/2UbVkND.
Amazon EC2 Auto Scaling te ayud ará a garantizar que tenga la cantidad correcta de
instancias de Amazon EC2 disponibles para manejar la carga de su aplicación.
Se crean  colecciones de instancias de EC2, denominadas grupos de Auto Scaling .
Puede especificar  el número mínim o de instancias en cada grupo de Auto Scaling. Así
Amazon EC2 Auto Scaling garantiza que su grupo nunca esté por debajo de este tamaño.
Si especifica políticas de escalado, Amazon EC2 Auto Scaling puede iniciar o finalizar
instancias a medida que la demanda en su aplicación  aumenta o disminuye.
Por ejemplo, puede crear grupo de Auto Scaling que tenga un tamaño mínimo de una
instancia, una capacidad deseada de dos instancias y un tamaño máximo de cuatro
instancias. Las políticas de escalado que defina ajustan el número de instancias, dentro de
su número mínimo y máximo de instancias, según los criterios que especifique. (González,
2019, https://bit.ly/2UbVkND)
Componentes de autoescalado
A continuación, se describen los componentes clave de Amazon EC2 Auto Scaling.
Los grupos
Sus instancias de EC2 están organizadas en grupos para que puedan ser tratadas como
una unidad lógica para fines de escalado y administración. Cuando se crea un grupo, se
puede especificar su número mínimo, máximo y el número deseado de instancias de EC2.
(González, 2019, https://bit.ly/2UbVkND)
Plantillas de configuración
Su grupo utiliza una plantilla de inicio o una configuración de inicio como plantilla de
configuración para sus instancias de EC2. Puede especificar información como el ID de
AMI, el tipo de instancia, el par de claves, los grupos de seguridad y la asignación de
dispositivos de bloque para sus instancias. (González, 2019, https://bit.ly/2UbVkND)
Opciones de escalado
Amazon EC2 Auto Scaling le ofrece varias formas de escalar sus grupos de Auto Scaling.
Por ejemplo, puede configurar un grupo para escalar en función de la aparición de
condiciones específicas (escala dinámica) o en una programación.
Puede especificar  el número máximo de instancias en cada grupo  de Auto Scaling.
Amazon EC2 Auto Scaling garantizara así que su grupo nunca supere este tamaño .
Si especifica la capacidad deseada,  ya sea cuando cree el grupo o en cualquier momento
posterior , Amazon EC2 Auto Scaling garantiza que su grupo tenga tantas instancias.
(González, 2019, https://bit.ly/2UbVkND)
El uso de AWS Auto Scaling puede ser tan perjudicial como beneficioso. A
continuación, estudiaremos las mejores prácticas a la hora de autoescalar nuestras
instancias y lograr mejores resultados en las aplicaciones.
AWS Auto Scaling es un proceso complejo que requiere la combinación correcta de configuración,
pruebas y supervisión para funciona r correctamente. La supervisión diligente de la aplicación y el
ajuste frecuente de su plan de escalado automático nos ayudarán a obtener las recompensas
posibles. A continuación, dejamos algunas lecciones que hemos aprendido para mejorar el ajuste
de escala automático de AWS, para que ustedes no tengan que hacerlo. 
Diseñar imágenes personalizadas de máquinas de Amazon (AMI)
Al considerar una estrategia de escalado, es importante la rapidez con la que escala nuestro
sistema. Ahorrare mos tiempo si diseñamos nuestras propias AMI que se incorporen a las
bibliotecas y los componentes de software necesarios para su instanc ia de servidor específica.
Esto reducirá los tiempos de implementación porque se eliminan las esperas de que las
bibliotecas y dependencias se descarguen en el servidor que necesita aprovisionar . 
Definir las métricas que afectan el rendimiento de su aplicación
Al comprender las métricas que controlan los recursos, podemos comprender cómo administrarlos
para lograr un mejor rendimiento. Esto es importante porque ciertas métricas, como el uso de la
CPU, afectan su rendimiento. Estos valores nos permitirán determinar cómo necesitamos escalar
los recursos en relación con nuestra carga de trabajo.
Si bien existen muchas opciones comerciales y de código abierto para monitorear sistemas en la
nube, AWS CloudW atch es la opción predeterminada para AWS y está perfectamente integrado
en el ecosistema de AWS. Solo se necesitan unos pocos clics en la interfaz de usuario o un solo
comando CLI para activar o desactivar la supervisión. CouldW atch proporciona métricas acerca
del comportamiento de todo el grupo de Auto Scaling, así como el rendimiento de instancias
individuales. Podemos realizar un seguimiento constante de las métricas y se pueden utilizar para
determinar cuándo ampliar sus grupos de Auto Scaling en función de un análisis de sus métricas. 
Utilizar AWS Auto Scaling
Dado el tema de este módulo, esto parece un hecho, pero muchos usuarios de AWS tienen la
percepción errónea de que AWS Auto Scaling es demasiado difícil de usar. AWS ha hecho un gran
trabajo al hacer que AWS Auto Scaling sea fácil de utilizar . En este sentido, el pequeño esfuerzo
para activar Auto Scaling será recompensado con un sistema más resistente y con menores
costos en la nube.
¿Por qué necesit amos AWS Auto Scaling?  Vamos a analizarl o. Auto Scaling funciona mediante
el diseño de un grupo de Auto Scaling que administra instancias detrás de un equilibrador de
carga. Esto se hace para que el rendimiento se mantenga constante y aumente su capacidad
cuando se aumente la carga (para asegurar el rendimiento), a su vez, se disminuya la capacidad
cuando la carga baje (para ahorrar costos). El ajuste de escala automático de AWS se puede
utilizar para cualquier aplicación, ya sea con estado o sin estado. 
Aprender cómo funcionan los grupos de Auto Scaling con Dynamic Auto Scaling 
Para configurar sus recursos, debemos especificarlos en la función AWS Auto Scaling Groups.
Los grupos de Auto Scaling definen un recurso máximo y mínimo que indica cuándo los recursos
se lanzarán o eliminarán dinámicamente. AWS permite asignar grupos de ajuste de escala
automático a Elastic Load Balancer s (ELB) para asegurarse de que los recursos recién creados
se descubran y utilicen sin problemas. 
Crear métricas personalizadas para ajustar nuestro Auto Scaling 
A menos  que se ejecute una aplicación muy genérica, por ejemplo, un servidor de WordPress,
deberíamos consi derar mirar más allá de las métricas predeterminadas proporcionadas por
CloudW atch. Si codificamos una métrica personalizada, podemos ajustar el rendimiento de la
aplicación en función de lo que le importa específicamente. Incluso si definimos métricas
específicas para su aplicación, también podemos usar las métricas predeterminadas. Las métricas
personalizadas se crean utilizando Python y el marco de Boto, y se expresan como funciones
booleanas.
Para configurar con precisión sus políticas de escalado automático, debemos definirlas en
relación con sus zonas de dispo nibilidad (AZ). La planificación previa de una política de
escalamiento basa da en porcentajes que tenga en cuenta los costos variados entre las diferentes
regiones y zonas de disponibilidad puede resultar en un rendimiento óptimo y costos reducidos. 
 Integrar servicios de cola simple (SQS)
Es posib le emparejar un SQS con una alerta de CloudW atch sobre la longitud de la cola.
CloudW atch pued e activar un evento de escalado cuando las colas superan una longitud
predefinida.
Ampliar el AWS DynamoDB
Si bien las instancias EC2 son el objetivo más común de Auto Scaling, otros servicios de AWS
también pueden beneficiarse de él. Desde la perspectiva de la función de la aplicación, los
servicios de base de datos (por ejemplo, AWS DynamoDB) son probablemente, el segundo
servicio más popular para escalar . 
Si bien existen ligeras diferencias en las políticas entre Auto Scaling, si hemos creado planes de
escalado automático para nuestra s instancias EC2, escalar el almacenamiento de AWS
DynamoDB o Amazon RDS nos será familiar . 
Utilizar escalamiento predictivo 
Hasta ahora hemos analizado cómo  escalar con los límites de recursos que hemos predefinido,
también conocido como escalado dinámico. No obstante, AWS también admite el escalado
predictivo según el rendimiento del sistema anterior y de acuerdo con las métricas que hayamos
configurado. Debe mos asegurarnos de disponer de una capacidad mínim a de recursos basada en
el modelo predictivo. Debido a que el escalado predictivo asegura una capacidad mínima de
recursos, podemo s combinarlo con políticas de escalado dinámico para que los aumentos de
carga inesperados también se administren sin problemas. 
Tema 3. Amazon CloudW atch
Video 7: Introducción a Amazon CloudW atch 
Fuente: Amazon Web Services (2019). Monitor AWS Resources Using Amazon CloudW atch Dashb oards [archivo de video]. YouTube.
https://n9.cl/ea9jc.
¿Qué es Amazon CloudW atch?
Figura 1 1: Amazon CloudW atch
Fuente: [Imagen sin título sobre Amazon CloudW atch], s.f., https://n9.cl/kp1vt. 
Amazon CloudW atch permite a los desarrolladores, cloud architects y administradores el
monitoreo de aplicaciones basadas en la nube de AWS. CloudW atch funciona por medio
de la recopilación en tiempo real de datos de monitorización y operaciones en formato de
registros, eventos y métricas lo que permite al equipo de IT conocer solicitudes, latencia
y uso de almacenamiento de servidores o CPU.
Cabe señalar que este servicio se configura de forma automática y de acuerdo a las
demandas del negocio. Además, al ser un servicio escalable , permite monitore ar métricas
de servic ios adicio nales de AWS o aplicaciones externas. Lo que más llama la atención de
CloudW atch es que ofrece una vista unificada de todos los recursos y servicios
contratados, ya sea que se encue ntren alojados en servidores locales o en la nube.
(Redacción Apser , 2019, https://bit.ly/3lYCg12)
Ventajas de CloudW atch metrics
Como ya mencionamos, este servicio es muy sencillo de gestionar gracias a su gran
capacidad de integración. Entre los beneficios que proporciona podemos encontrar:
Seguimiento fácil y rápido:  todos los datos e informes que proporciona CloudW atch
permiten a los usuarios hacer un seguimiento de la aplicación, uso de recursos,
problemas operati vos y limitaciones. Esto ayuda a agilizar las operaciones en el área
de IT .
Compatible con diversas instanci as: aunque su uso es más común con instancias
EC2, también puede monitorear volúmenes de Amazon Elastic Book Store (EBS) o
Elastic Load Balancers (ELB) e instancias RDS, además de otras fuentes externas.
Rapidez de escalado y flexibilidad máxima : al ser automatizado, es capaz de
detectar al instante cuando se requiere el escalado de alguna instancia.
Siempre alerta : Amazon CloudW atch permite establecer alarmas o automatizar
acciones basadas en umbrales predefinidos o algoritmos. Ofrece herramientas como
el Auto Scaling para EC2 o CloudW atch Events para servicios Lambda, SNS y
CloudFormation.
Supervisión básica: con este servicio se podrán selec cionar métricas específicas
para su rastreo y análisis. (Redacción Apser , 2019, https://bit.ly/3lYCg12)
Opciones de monitoreo       
Por si fuera poco , CloudW atch cuenta con dos tipos de monitoreo  adaptados a las
necesidades y capacidad de inversión de las empresas en cuanto a recursos EC2:
Monitoreo básico : no se requiere tarifa adicional a la que se paga de inicio. Incluye siete
métricas preseleccionadas y otras tres de verificación de estado.
Monitoreo detallado : con un cargo adicional, en donde se aumenta la frecuencia de todas
las métricas en intervalos de un minuto. (Redacción Apser , 2019, https://bit.ly/3lYCg12) 
Beneficios de Amazon CloudW atch
Amazon Cloudwat ch te permite acceder a toda nuestra data desde una sola plataforma,
además viene con más de 70 servicios integrados nativamente. Los registros de Amazon
CloudW atch permi ten monitorear , procesar , almacenar y acceder a los archivos de registro
de las instancias EC2, AWS CloudT rail, funciones Lambda, registro de flujo de VPC, y
otras fuentes. Con los registros CloudWatch el administrador de la nube  puede solucionar
problemas en las aplicaciones y la infraestructura AWS usando un sistema, aplicación o
archivo de registro existente.
Métricas
Podemos ver las gráficas estadísticas de las métricas publicadas con la Consola de
Administración de AWS. CloudW atch almacena la información métrica como una serie de
puntos de data (data points), cada punto está asociado con una etiqueta de tiempo.
Incluso podemos publicar un conjunto estadístico con un grupo de puntos de data.
Alarmas
Las carac terísticas de las alarmas en CloudW atch nos permiten recibir notificaciones cada
vez que tus métricas se salen de los niveles configurados, ya sea a la baja o al alza . . . 
Escabilidad
Escabilidad puede  implementarse con la ayuda de CloudW atch. Los clientes de Nub8 usan
Amazon CloudW atch con autoesca bilidad para monitorear el uso del CPU para escalar
desde 3 instancias de Amazon EC2 a 9 durante los períodos pico de forma automática.
Autorrecuperación
La autorr ecuperación puede ser implementada con la ayuda de CloudW atch, si una
instancia falla un chequeo del sistem a, podemos usar CloudW atch para automáticamente
reiniciarla o recuperarla.
Costos operativos
CloudW atch provee percepciones en tiempo real, así podremos mejorar los costos
operacionales y los recursos de AWS. (Nub8, 2020, https://bit.ly/3xH8M9O)
Figura 12: CloudW atch Amazon EC2
Fuente: [Imagen sin título sobre CloudW atch], s.f., https://n9.cl/thoej.
¡Vamos a practicar!
Si querés conocer más sobre cómo utilizar la plataforma de Amazon y poner a prueba tus
conocimientos, te dejamos la siguiente actividad.
Video de habilidades
¿Cuál es la opción que nos permite empezar el proceso de creación de
Auto Escalado?
Always On Service from Amazon.
Duplicate Instance Configuration.
Start Auto Scaling mode.
Create Launch Configuration.
Setup Application Model.
Justificación
Es la elasticidad un factor muy importante para el valor que representa la
nube como tecnología innovadora.
Verdadero
Falso
Justificación
El usuario debe interactuar para hacer que sus servidores crezcan y
decrezcan cuando lo demande la circunstancia.
Verdadero
Falso
Justificación
Existe una limitación en el tipo de instancia al momento de elegir qué
Sistema Operativo será la base para escalar .
Verdadero
Falso
Justificación
El Auto Escalado se encuentra ligado a una forma de contratar instancias
específicas.
Verdadero
Falso
Justificación
Cierre
Virtual private cloud:  Amazon  Virtual Private Cloud (Amazon VPC) le permite lanzar recurs os de
AWS en una red virtual que haya definido. Se trata de una red personalizable que le permite definir
su propio rango de direcciones IP, agregar y eliminar subredes, crear rutas, agregar puertas de
enlace VPN (virtua l private network), asociar políticas de seguridad, conectar instancias EC2 (elastic
compute cloud) a su propio centro de datos, entre otras tantas funcionalidades.
Amazon Relational Database Serv ice (RDS):  Amazon Relational Database Service o Amazon RDS
es un servicio de base de datos en la nube administrado de AWS. Fue diseñado para simplificar la
creación, operació n, administración y escalado de una base de datos relacional para su uso como
backend de aplicación. AWS lanzó el servicio RDS inicialmente en octub re de 2009 con soporte para
MySQL. Con el paso de los años, el servicio RDS agregó servicios administrados para otras bases
de datos como SQL  Server , Oracle Database, PostgreSQL  y MariaDB.
Amazon DynamoDB: DynamoDB es una base de datos sin servidor NoSQL  proporcionada por
AWS. Sigue una estructura de tienda de valor clave y adopta una arquitectura distribuida para alta
disponibilidad y escalabilidad.
Elastic load balancer (ELB): Un Elast ic Load Balancer (ELB) tiene la capacidad de escalar
automáticamente los balanceadores de carga y las aplicaciones segú n el tráfico en tiempo real.
Debido a la elasticidad, generalmente se implementa como un equilibrador de carga de software.
Auto scaling – Autoescalamiento: Amazon EC2 Auto Scaling te ayudará a garantizar que tenga la
cantidad correcta de instancias de Amazon EC2 disponibles para manejar la carga de su
aplicación.Se crean colecciones de instancias de EC2, denominadas grupos de Auto Scaling. Puede
especificar el número mínimo de instancias en cada grupo de Auto Scaling. Así Amazon EC2 Auto
Scaling garantiza que su grupo nunca esté por debajo de este tamaño.
Amazon CloudW atch: Amazon CloudW atch permite a los desarrolladores, cloud architect s y
administradores el monitoreo de aplicaciones basadas en la nube de AWS. CloudW atch funciona por
medio de la recop ilación en tiempo real de datos de monitorización y operaciones en formato de
registros, eventos y métricas lo que permite al equipo de IT conocer solicitudes, latencia y uso de
almacenamiento de servidores o CPU.
Referencias
Amazon Web Services  (s.f.). Precios de la capacidad bajo demanda . Amazon AWS.
https://aws.amazon.com/es/dynamodb/pricing/on-demand/.
Amazon Web Services  (s.f.). ¿Qué es Amazon VPC?  Amazon AWS.
https://docs.aws.amazon.com/es_es/vpc/latest/userguide/what-is-amazon-vpc.html.
Amazon Web Services  (2019). Monitor AWS Resourc es Using Amazon CloudW atch Dashboards
[archivo de video]. YouTube. https://www .youtube.com/watch?v=I7EFLChc07M.
Amazon Web Services (2012). Amazon DynamoD B - What's It All About? [archivo de vídeo].
YouTube. https://www .youtube.com/watch?v=nMhWJJACZSA.
Amazon Web Services  [Amazon Web Services]. (2018). Understanding Amazon Relational
Database Servic e (RDS) [archivo  de video]. YouTube. https://www .youtube.com/watch?
v=eMzCI7S1P9M.
Arquitectura AWS (2017). Cómo crear una red VPC,  security groups, Gateway , ACL en ambiente
de alta disponibilidad en AWS [archivo de video]. YouTube. https:// www .youtube.com/watch?
v=rgUk0wGMmqo.
Arranz, M. (2016). Usar Auto Scaling con la cuenta gratuita  [archivo de video]. YouTube.
https://www .youtube.com/watch?v=BhNZd_cxxko.
Avi Networks (2020). Balanceador de carga elástico. Avi Networks.
 https://avinetworks.com/glossary/elastic-load-balancer/.
Cloud Academy  (2019). What is an AWS Elastic Load Balancer (ELB)? - AWS Training [archivo
de video]. YouTube. https://www .youtube.com/watch?v=uT rpk-atNFc.
Dashbird  (2020). Descripción general y conc eptos principales de Amazon DynamoDB. Dashbird.
https://dashbird.io/knowledge-base/dynamodb/overview-and-main-concepts/.
Dashbird (2020b). Precios de DynamoDB . Dashbird https://dashbird.io/knowledge-
base/dynamodb/dynamodb-pricing/ 
González, J. M. (2019).  ¿Qué es Amazon EC2 Auto Scaling? José María González.
https://www .josemariagonzalez.es/amazon-web-services-aws/que-es-amazon-ec2-auto-
scaling.html.
Ibáñez, E. y Marco, E. (2017). Cómo montar tu propia nube con la ayuda de AWS y
Cloudformation . Paradigma. https://www .paradigmadigital.com/dev/montar-nube-la-ayuda-aws-
cloudformation/.
Kalerolinex (2017). AWS050: VPC - Ejemplo gráfico de una Virtual Private Cloud  [archivo de
video]. YouTube. https://www .youtube.com/watch?v=8fhbmfXycjs.
Krishna , (2020). Pros y contras de Amazon RDS: descripción general detallada  [entrada de blog].
Saras Disclaimer . https://sarasanalytics.com/blog/amazon-rds-pros-and-cons.
Neeru, J. (2017). Basics of VPC Peering  – Amazon Virtual Private Cloud [entrada de blog].
Whizlabs Software Pvt. Ltd. https://www .whizlabs.com/blog/vpc-peering-basics/.
Nub8 (15 de enero de 2020). Beneficios De Amazon  CloudW atch. Nub8.
https://nub8.net/es/beneficios-de-amazon-cloudwatch/. 
Open Data Science  (2020). An Introduction to AWS Networking — Virtual Private Cloud . Medium.
https://medium.com/@ODSC/an-introduction-to-aws-networking-virtual-private-cloud-
1639a91c67c1.
Redacción Apse r (2019). Un vistazo a CloudW atch de Amazon Web Services . Asper.
https://apser .es/un-vistazo-a-cloudwatch-de-amazon-web-services/.
Squadex , (2018). Big Data Platform & Next Gene ration Business Intelligence . Squadex.
https://squadex.com/big-data-analytics/big-data-platform-next-generation-business-intelligence/.
Sumo Logic (2019). AWS Elastic Load Balancer: el Classic Load Balancer frente al Applica tion
Load Balancer . Sumo Logic. https://www .sumologic.com/blog/aws-elastic-load-balancers-classic-
vs-application/. 
Vinoth, G. (s.f.). High Availability and Disaster Recovery for Application Architects . Medium .
https://medium.com/@vinot84/high-availability-and-disaster-recovery-for-application-architects-
a05378ccb094.
A continuación podrás descargar la lectura en formato PDF o MP3:


----- M4-Lectura.pdf -----
Módulo 4. Arquitectura de soluciones de
cómputo en la nube
Video de Inmersión
Unidad 1. Arquitectura
En este módulo analizaremos los tipos de arquitectura y cómo se pueden obtener diferentes
opciones de soporte de Amazon Web Services. Conocer los tipos de arquitectura que se pueden
tener en la nube ayuda a comprender cuál es la mejor solución para cada necesidad y qué tipo de
soporte se requiere.
Tema 1. Introducción a la arquitectura de soluciones de cómputo en la nube
La arquitectura de nube constituye la forma en la que se integran las distintas tecnologías
para crear las nubes, es decir , los entornos de TI que extraen, agrupa n y comparten los
recursos escalable s en una red. También define cómo se conectan todos los elementos y
las funcio nes que se necesitan para diseñar una nube y obtener una plataforma en línea
en la que se puedan ejecutar las aplicaciones. 
Es simila r a la construcción de una vivienda: la infraestructura de nube  incorpora todos
los materiales, y la arquitectura de nube es el plano técnico.
¿Cómo es una arquitectura de nube?
Las nubes se consideran plataformas como servicio  (PaaS), ya que un proveedor de
nube  ofrece a los usua rios tanto la plataforma como la infraestructura de TI subyace nte.
Diseñar la arquitectura de una plataforma de nube implica mucho más que extraer las
funciones informát icas de los elementos de hardware , lo cual sintetiza la forma en la que
los proveedores crean una infraestructura de nube y la ofrecen a los usuarios. También
requiere niveles adicionales de desarrollo para incorporar la organización en
contenedores, la coordinación, las interfaces de programación de aplicaciones  (API),
el enrutamiento, la seguridad , la gestión y el software de automatización . El diseñ o de la
experiencia del usuario (UX) tambié n es importante para crear un entorno en línea por el
que se pueda navegar con facilidad.
Si bien la arquitectura de nube varía en función de los objetivos, la mayoría de ellas
necesitan el hardware , el middleware , la gestió n y el software de automatización . Además,
utilizan la virtualización para extraer los recursos de hardware y convertirlos en lagos de
datos  que se gestionan de forma centralizada. Por otra parte, algunas nubes (conocidas
como las nubes sin sistema operativo ) conectan a los clientes directamente con el
hardware.
Un ejemplo práctico: OpenStack es un proyecto de nube open source [de código abierto]
muy popular que combina muchos otros proyectos de código abierto para diseñar y
gestionar las nubes usando recursos virtualizados. (Red Hat Inc., s.f.,
https://red.ht/37BwA4p)
Figura 1: Arquitectura básica de nube 
Fuente: Red Hat Inc., s. f. a, https://red.ht/37BwA4p.
Arquitecturas privadas, públicas, híbridas y multicloud
Arquitectura de nube privada : entorno de nube diseñado solo para el usuario final,
generalmente dentro del cortafuegos del usuario y , a veces, on-premise.
Arquitectura de nube pública : entorno de nube  creado a partir de recursos ajenos
al usuario final que pueden redistribuirse a otros inquilinos.
Arquitectura de nube híbrida : varios entornos de nube con cierto nivel de
portabilidad, coordinación y gestión de las cargas de trabajo entre ellos.
Arquitectura multicloud : sistemas de TI que incluyen más de una nube, pública o
privada, y que pueden conecta rse en red (o no). (Red Hat Inc., s.f.,
https://red.ht/37BwA4p)
Tema 2. T ipos de arquitecturas
Arquitectura de nube pública
Se trata de un conjunto de recursos virtuales desarrollados a partir del hardware que
pertenece a una empresa externa encargada también de gestionarlo. La nube se asigna y
se pone a disposición de varios clientes a través de una infraestructura de autoservicio de
forma automática. Es una forma sencilla de escalar horizontalmente las cargas de trabajo
que experimentan fluctuaciones inesperadas de las demandas.
       
Por lo general, las nubes públicas actuales no se implementan como una solución de
infraestructura independiente, sino como parte de una mezcla heterog énea de entornos
que genera más seguridad y rendimiento, menor costo y mayor disponibilidad de
infraestructura, servicios y aplicaciones. (Red Hat Inc., s.f., https://red.ht/3jNRe74)
Aprendamos más acerca de las nubes públicas, privadas e híbridas
¿Qué es una nube pública?
Figura 2: Nube pública
Fuente: Hybrid ITC, 2018, https://bit.ly/3iCloe6.
Las nube s públicas son la forma más común de implementar la informát ica en la nube. Los
recursos de la nube (como servidores y almacenamiento) son propiedad de otro
proveedor de servicios en la nube , que los administ ran y ofrecen a través de Internet.
Microsoft Azure  es un ejemplo de nube pública [también lo es Amazon Web Services].
Con una nube pública, todo el hardware , software y demás componentes de la
infraestructura subyacente son propiedad del proveedor de nube, que también los
administra. En una nube pública, comparte el mismo hardware, almacenamiento y
dispositivos de red con otras organi zaciones o "inquilinos" de la nube. Usted accede a los
servicios y administra su cuenta a través de un explorador web. Con frecuencia, las
implementaciones de nube pública se usan para proporcionar correos electrónicos web,
aplicaciones en línea, almacenamiento, y entornos de desarrollo y prueba.
Ventajas de las nubes públicas:
Costos inferiores: no es necesario adquirir hardware o software, y solo paga por el
servicio que usa.
Sin mantenimiento: su proveedor de servicios se encarga de ello.
Escalabilidad casi ilimitada: existen recursos a petición para satisfacer sus
necesidades empresariales.
Gran confiabilidad : una amplia red de servidores garantiza que no se produzcan
problemas.
¿Qué es una nube privada?
    Una nube priva da está compuesta por recursos informáticos que utiliza exclusivamente
una empr esa u organización. La nube privada puede ubicarse físicamente en el centro de
datos local de su organización u hospedarse en un proveedor de servicios externo. Sin
embargo, en una nube privada, los servicios y la infraestructura siempr e se mantienen en
una red privada, y el hardware y software se dedican únicamente a su organización. De
esta forma, una nube privada puede lograr que una organización pueda personalizar de
forma más sencil la sus recursos para cumplir requisitos específicos de TI. Las nubes
privadas suelen usarlas agencias gubernamentales, instituciones financieras y cualquier
organización mediana o grande que realice operaciones esenciales para la empresa y
busque aumentar el control sobre su entorno.
Ventajas de las nubes privadas:
Más flexibilidad: su organización puede personalizar el entorno de la nube para
satisfacer necesidades empresariales específicas.
Mejor seguridad: los recursos no se comparten con otros, por lo tanto, es posible
contar con mayores niveles de control y seguridad.
Mayor escalabilidad: las nubes privadas todavía pueden ofrecer la escalabilidad y la
eficacia de una nube pública.
¿Qué es una nube híbrida?
       
    Las nubes híbridas, que suelen llamarse "lo mejor de ambos mundos", combinan
infraestructura local (o nubes privadas) con nubes públicas, de modo que las
organizaciones puedan beneficiarse  de las ventajas de ambas. En una nube híbrida, los
datos y las aplicaciones pueden moverse entre nubes privadas y públicas para obtener
más flexibilidad y opciones de implementación. Por ejemplo, puede usar la nube pública
para satisfacer necesidades de gran volumen con menor seguridad , como un correo
electrónico web, y la nube privada (u otra infraestructura local) para operaciones
confidenciales esenciales para la empresa, como los informes financieros. En una nube
híbrida, también es una opción la "ampliación en la nube". Esto se refiere a cuando una
aplicación o recurso se ejecuta en la nube privada hasta que se produce una subida en la
demanda (por ejemplo, un evento estacional como ventas en línea o envío de formularios
de impuestos). En este punto, la organización puede "ampliarse" hacia la nube pública
para aprovechar más recursos informáticos.
Ventajas de las nubes híbridas:
Control: su organización puede mantener una infraestructura privada para los
recursos confidenciales.
Flexibilidad: puede  aprovechar los recursos adicionales de la nube pública cuando
los necesite.
Rentabilidad: gracias a la posibilidad de escalar a la nube pública, solo pagará por la
capacidad informática adicional cuando sea necesaria.
Facilidad: realizar la transición a la nube no tiene por qué ser compleja, ya que puede
realizar una migración gradual; es decir , trasladando cargas de trabaj o en etapas.
(Microsoft Azure, s.f., https://n9.cl/ge29n)
Almacenamiento en la nube privada
Gracias al big data y al Internet de las cosas  (IoT), el almacenamiento en la nube
privada es un factor muy importante para las empresas, en especial en una era en la que
es difícil apreciar el valor de un byte hasta mucho después de su creación. Las nubes
privadas utilizan el almacenamiento definido por software  (SDS) para archiva r y ordenar
los datos. Ceph es el proyecto open source que . . . [funciona] como una de las soluciones
de almac enamiento definido por software más comunes para las nube s privadas, sobre
todo para las que se imple mentan con OpenStack. (Red Hat Inc., s.f.,
https://red.ht/37xPFo2)
A continuación, se explican algunos conceptos básicos acerca de la nube híbrida.
Arquitectura de nube híbrida
La nube híbrida es una arquitect ura de TI que incorpora cierto grado de gestión,
organización y portabilidad de las cargas de trabajo en dos o más entornos. Según el tipo,
es posible que esos entornos deban incluir lo siguiente:
Al menos una nube privada y una pública.
Dos o más nubes privadas.
Dos o más nubes públicas.
Un entorno virtual o sin sistema operativo conectado a, al menos, una nube, ya sea
pública o privada.
Estos requisitos variables provienen  de una era anterior del cloud comp uting, en la cual la
diferencia entre las nubes públicas y las privadas radicaba en la ubicación y la propiedad.
Sin embargo, los tipos de nube actuales son mucho más complejos, ya que la ubicación y
la propiedad son aspectos abstractos. Por ejemplo:
Tradicionalmente, las nubes públicas se ejecutaban fuera de las insta laciones, pero los
proveedores de nube pública ahora ejecutan los servicios de la nube en los centros de
datos locales de sus clientes. 
       
Tradicionalmente, las nubes privad as se ejecutaban in situ, pero las empresas ahora
diseñan las nubes privadas en centr os de datos alquilados de terceros que se encuentran
fuera de las instalaciones.
Por eso, es más útil definir el cloud computing híbrido por sus funciones. Todas las nubes
híbridas deben poder realizar lo siguiente:
Conectar varias computadoras a través de una red. 
Consolidar los recursos de TI.
Escalar horizontalmente e implementar los recursos nuevos con rapidez.
Poder trasladar las cargas de trabajo entre los entornos.
Incorporar una sola herramienta de gestión unificada.
Organizar los procesos con la ayuda de la automatización .
¿Cómo funcionan las nubes híbridas?
    La forma en que las nubes públicas y privadas funcionan como parte de una nube
híbrida es similar a cómo lo hacen de forma independiente.
Una red de área local (LAN), una red de área amplia (WAN), una red privada virtual
(VPN) y las interf aces de programación de aplicaciones  (API) conectan varias
computadoras entre sí.
La virtualización , los contenedores o el almacenamiento definido por software
extraen los recursos, que pueden agruparse en lagos de datos .
El sistema de software de gestión  asigna esos recursos a entornos en los que las
aplicaciones pued en ejecutarse, los cuales, luego, se implementan, según se solicite,
con la ayuda de un servicio de autenticación.
Las nubes independientes se vuelven híbridas cuando esos entornos se conectan de la
forma más sencilla posible. Esa interconectividad es lo único que permite que las nubes
híbridas funcionen , y es por eso que estas nubes son la base del edge computing.
Además, determin an la forma en que se trasladan las cargas de trabajo, se unifica la
gestión y se organ izan los procesos. La calidad de las conexiones tiene un efecto directo
sobre el funcionamiento de su nube híbrida.
¿Cómo se diseña una nube híbrida?
Cada nube es única. Las nubes privadas son únicas y hay miles de proveedores de nube
pública. Todos los modelos de nube híbrida son diferentes, por lo que la forma en que se
organicen los recursos de la nube y se diseñe una nube híbrida tiene su propio sello. Sin
embargo, hay algunos principios básicos que corresponden a las dos formas generales de
diseñar un entorno de nube híbrida: la tradicional y la moderna.
    Arquitectura tradicional de la nube híbrida
Antes, las nubes híbridas eran el resultado de la conexión de una nube privada con una
pública. Era posible diseñar esa nube privada por cuenta propia o utilizar una
infraestructura de nube predefinida, como OpenStack. Además, se necesitaba una nube
pública . . .
Finalmente, había que conectar la nube pública a la privada. Por lo general, esta conexión
se realizaba utilizando una red compleja de LAN, WPN, API y VPN. Incluso, muchos
proveedores de servicios de nube ofrecen a los clientes una VPN preconfigurada como
parte de los paquetes de suscripción: 
Google Cloud ofrece Dedicated Interconnect .
Amazon W eb Services (A WS) ofrece Direct Connect .
Microsoft Azure ofrece ExpressRoute .
OpenStack ofrece OpenStack Public Cloud Passport .
Arquitectura moderna de la nube híbrida
Actualmente, las nubes híbridas ya no necesitan una red amplia de API para trasladar las
cargas de trabajo de una nube a otra. Para diseñar nubes híbridas, los equipos modernos
de TI ejecutan el mismo sistema operativo en todos los entornos de TI; desarrollan e
implementan aplicaciones como grupos de servicios pequeños, independientes y sin
conexión directa, y gestionan todo con una PaaS unificada. En términos más prácticos,
una nube híbrida puede crearse como resultado de las siguientes operaciones:
la ejecución de Linux en todos los entornos;
el diseño y la implementación de aplicaciones nativas de la nube;
la gestión de todos los sistemas  mediante un motor de organiz ación, como
Kubernetes o Red Hat OpenShift .
Si se utiliza el mismo sistema operativo, se extraen todos los requisitos del sistema de
hardware, mientra s que la plataform a de organización extrae todos los de las aplicaciones.
Esto genera un entorno informático  uniforme e interconectado en el que las aplicaciones
pueden trasladarse de un entorno a otro sin tener que mantener un mapa complejo de las
API que falle cada vez que se actualicen las aplicaciones o que cambie de proveedores
de nube . (Red Hat Inc., s.f., https://red.ht/3lV48Tp)
La nube multicloud , la combinación de todas las arquitecturas
Arquitectura de nube multiclou d
Figura 3: Entorno multicloud
Fuente: Hill, 2018, https://bit.ly/3fTjaFC.
Como podemos ver en la figura, la arquitectura de un entorno multicloud es la más compleja de
todas.
El términ o multicloud se refiere  a un enfoque de nube compuesto por más de un servicio
de nube, que proporcionan por lo menos dos proveedores de nube pública o privada.
Por ejemplo, una empresa invierte en la expansión de una infraestructura de nube . Ha
pasado de servido res básicos a cargas de trabajo basadas en la virtualización y, ahora,
está evaluando las opciones de nube pública, no para aplicar en todas las situaciones,
sino para admitir una aplicación específica orientada al cliente con tasas de uso muy
variables. Después de investigar un poco, se encuentra al proveedor de nube pública que
tiene la combinación exacta de acuerdos de nivel de servicio (SLA), protocolos de
seguridad  y el tiempo de actividad para alojar su aplicación personalizada. La elección
resulta satisfactoria. Pero eventualm ente, los clientes comienzan a solicitar funciones que
solo están disponibles mediante distintas aplicaciones que dependen  de proveedores.
Integrar estas funciones en la aplicación personalizada no solo requiere la compra de la
aplicación del proveedor , sino también alojar la aplicación en esa nube pública de
propiedad del proveedor , una soluci ón que permite a ambas aplicacione s escalar según la
demanda. 
Ahora tiene un entorno multicloud. 
. . .
Ventajas de las nubes múltiples
Shadow IT 
El "Shadow IT" se está convirtiendo en una realidad que contribuye a los entornos
multicloud. El hardware o el software implementados de forma independiente del equipo
de TI central pueden ser lo suficien temente grandes como para garantizar más control.
Llegados a ese punto, migrar la infraestructura y los datos a un sistema preferente
(supongamos que hablamos de nubes públicas) puede estar fuera de toda cuestión. Esa
implementación de "shadow IT" se agrega simplemente como parte de las nubes actuales
de la empresa, lo cual da lugar a la creación de un entorno multicloud.
Flexibilidad
Es posibl e encont rar la solución de nube perfecta para un aspecto de la empresa, como
una nube propietaria más precisa para alojar una aplicación con licencia, una nube
asequible perfecta  para archivar registros públicos, una nube que se expande en gran
medida para alojar sistemas con índices de uso muy variables; pero ninguna nube puede
hacerlo todo por sí sola. O, mejor dicho, ninguna nube sola puede hacer todo esto bien.
Proximidad
A fin de reducir los tiempos de respuesta deficientes para los usuarios de nube que se
encuentran a miles de millas de distancia de la oficina central de una empresa, algunas
cargas de trabajo se pueden alojar mediante proveedores de nube regionales que operan
más cerca de donde se encuentran los usuarios. Esta solución permite que la empresa
mantenga una alta disponibilidad y cumpla con las leyes de soberanía de datos: protocolos
que ponen los datos a disposición de las reglamentaciones del país en el que estos se
encuentran.
Conmutación por error
    Los entornos multicloud protegen a las empresas de las interrupciones. La multicloud es
una solución de conmutación por error; por lo tanto, permite que las empresas tengan una
copia de seguridad disponible y altamente escalable para los datos, los flujos de trabajo y
los sistemas por si la nube principal falla o, como sugiere la ley de Murphy , para cuando
falle.
Gestión y automatización de los entornos multicloud
    . . .
La automatización siempre se utilizó de forma aislada dentro de las empresas: los distintos
equipos usaban herramientas diferentes para dominios de gestión individuales. Sin
embargo, las tecnologías de automatización actuales . . . permiten automatizar los
recursos en todos los entornos. La incorporación de la función de automatización moderna
a los entornos multicloud limita la complejidad del entorno y, al mismo tiempo, mejora la
seguridad y el rendimiento de la carga de trabajo para las aplicaciones tradicionales y
nativas de la nube .
Entornos multicloud y contenedores
Cuando se trata de proveedores de nube pública, los contenedores de Linux, ofrecen
opciones a las empresas. Debido a que los contenedores empaquetan y aíslan las
aplicaciones con todos sus entornos de tiempo de ejecución, los usuarios pueden trasladar
la aplica ción contenida entre las nubes y, al mismo tiempo, conservar toda la
funcionalidad. Esto brinda a las empresas la libertad de elegir los proveedores de nube
pública en función de estándares universales (p. ej.: el tiempo de actividad, el espacio de
almacenamiento , los costos), en lugar de hacerlo en función de si admitirá o no su carga
de trabajo debido a las restricciones de propiedad.
Lo que facilita esta portabilidad son los microservicios, un enfoque de arquitectura sobre la
escritura de software en el que las aplicaciones se dividen en sus componentes más
pequeños e independientes entre sí. Los contenedores resultan ser el lugar ideal para
ejecutar aplicaciones basadas en microservicios. (Red Hat Inc., s.f., https://red.ht/3Az31x6)
Unidad 2. Servicios de soporte en cómputo en la nube
Tema 1. Introducción al soporte técnico en cloud computing
 AWS Support (soporte de Amazon W eb Services) 
Con AWS Support, se provee una combinación de herramient as y tecnología,
profesionales y programas diseñados para ayudar de manera proactiva a optimizar el
rendimiento, dismi nuir los costos e innovar con mayor rapidez. Se ahorra tiempo al equipo,
ya que se agilizan las tareas en la nube y ayuda a enfocarse en el negocio principal.
Estamos decididos a ayudar a nuestros clientes a lograr sus metas en relación con el
traspaso a la nube y a abordar las solicitudes que van desde responder preguntas sobre
prácticas recomendadas y brindar asesoramiento sobre configuraciones hasta suministrar
asistencia técnica y solucionar problemas. (Amazon W eb Services, s.f., https://n9.cl/wduf8)
Las acciones que acompañan a Amazon Web Services son la resolución de problemas, la
capacitación y la investigación de las mejores formas de aplicar las soluciones de AWS. Ellos
quieren que saquemos el mejor provecho de la herramienta para nuestro producto o negocio.
Beneficios
Agilizar el ritmo de trabajo con AWS
Recurra a los expertos de AWS para adquirir conocimientos y experiencia con rapidez.
Con AWS Support, puede conse rvar el nivel de agilidad con la orientación sobre
arquitectura a medida que crea aplicaciones y soluciones . . . Nuestros especialistas e
ingenieros de soporte en la nube tienen las respuestas y el asesoramiento que está
buscando. Siempre están investiga ndo para identificar nuevas maneras en que AWS
puede ayudar a su empresa. [La empresa ofrece las mejores solucione s si trabajamos en
conjunto con expertos].
Automatizar la administración del entorno
Podemos monitorear el entorno y automatizar la resolución de problemas de manera
proactiva. En AWS Support se incluyen herramientas, como AWS Personal Health
Dashboard y AWS Trusted Advisor , que le permiten mantener nuestro entorno funcionando
de manera óptima. Con estas herramientas, es posible recibir alertas acerca de estrategias
para mejorar el nivel de seguridad, optimizar el rendimiento y reducir los costos.
. . .
Ingenieros con la capacidad necesaria para ayudarlo a lograr sus metas
En AWS, los ingenieros de soporte en la nube no se limitan a seguir un proceso
predeterminado, sino que realizan un seguimiento de los casos desde  el inicio hasta la
resolución. Este modelo evita las derivaciones que normalmente emplean las
organizaciones de soporte y elimin a la necesidad de que los clientes interactúen con
varios ingenieros de soporte, lo que puede extender el plazo de resolución y permite
agilizar su traspaso a la nube. (Amazon W eb Services, s.f., https://n9.cl/wduf8)
Developer Support
Se recomienda utilizar AWS Developer Support 
si se realizan pruebas o si se está en una etapa inicial de desarrollo en AWS y se quiere
contar con la posibilidad de recibir soporte técnico durante el horario comercial, así como
también asesoram iento general sobre arquitecturas mientras crea y realiza pruebas.
(Amazon W eb Services, s. f., https://n9.cl/wduf8)
Business Support
Se recomienda AWS Business Support 
Si ejecutamos cargas de trabajo de producción en AWS y deseamos tener acceso las 24
horas del día, los 7 días de la semana, a soporte técnico de ingenieros, acceso a la API de
Health y asesoram iento contextual sobre arquitecturas para los casos de uso. (Amazon
Web Services, s.f., https://n9.cl/wduf8)
Figura 4: Enterprise Support
Fuente: Amazon W eb Services, s.f., https://n9.cl/wduf8.
Video 1: ¿Qué es el soporte empresarial de Amazon?
Fuente: Amazon Web Services (06 de septiembre de 2018). AWS Enterprise Support: Customer Obsession at Work [archivo de video].
YouTube. https://n9.cl/hrpg5.
Se recomienda Enterprise Support 
Para soporte técnico de ingenieros, herramientas y tecnología de alta calidad, las 24 horas
del día, los 7 días de la semana,  para administrar automáticamente  el estado de su
entorno, asesoram iento consultivo sobre arquitectura y un director técnico de cuenta
(TAM) designado para coordinar el acceso a programas proactivos y preventivos y a
especialistas de AWS. (Amazon W eb Services, s.f., https://n9.cl/wduf8)
Alcance de AWS Support
Los nivele s de AWS Support cubren  problemas de producción y desarro llo para servicios y
productos de AWS, junto con otros componentes clave de pila:
Consultas sobre servicios y características de AWS.
Prácticas recomendadas para ayudarlo a integrar , implementar y administrar
correctamente aplicaciones en la nube.
Solución de problemas relacionados con API y SDK de AWS.
Solución de problemas operacionales o sistémicos con recursos de AWS.
Problemas con la consola de administración o con otras herramientas de AWS.
Problemas detectados por las comprobaciones de estado de EC2.
Una serie de aplicaciones de terceros, como configuración de sistemas operativos,
servidores web, email, VPN, bases de datos y almacenamiento.
AWS Support no incluye:
Desarrollo de código.
Depuración de software personalizado.
Ejecución de tareas de administración del sistema.
Ajuste de las consultas de las bases de datos.
Soporte entre las cuentas. (Amazon W eb Services, s.f., https://n9.cl/wduf8)
Tecnología y herramientas para monitorear , administrar y optimizar el entorno de AWS
AWS Support crea tecnología y herramientas que sirven para administr ar y monitorear el entorno
a fin de garantizar el rendimiento y la optimización de costos; administrar los riesgos relacionados
con la seguridad y el tiempo de inactividad; y automatizar la solución de problemas en la medida
de lo posible. Su objetivo es proveer asistencia para eliminar problemas que se pueden evitar y
brindar una excelente experiencia de soporte.
AWS ofrece varias herramientas para ayudar en el control del estado del entorno y en el
cumplimiento de las mejores prácticas. Con ellas, podemos ahorrar tiempo al automatizar las
respuestas a las alertas y notificaciones que se integran con otros sistemas de administración.
Figura 5: AWS Personal Health dashboard
Fuente: Barr , 2016, https://amzn.to/3s5PLNg.
Esta herramienta brinda alertas y orientación de corrección cuando AWS experimenta eventos
que pueden afectar las prácticas. También proporciona una visión personalizada del rendimiento y
la disponibilidad de los servicios de AWS que subyacen a los recursos de la plataforma. Además,
muestra informac ión relevante y oportuna para ayudar en la admin istración de eventos en
progreso, y activa notificaciones para planificar aquellas actividades programadas.
AWS T rusted Advisor
AWS Trusted Advisor proporciona asesoramiento en tiempo real para ayudarlo a
aprovisionar los recursos según las prácticas recomendadas de AWS. Las
comprobaciones de Trusted Advisor , con un conjunto de comprobacion es incluidas en el
plan Enterprise Support, ayudan a optimizar su infraestructura de AWS, a aumentar el nivel
de seguridad y rendimiento, a reduc ir los costos generales y a monitorear los límites de los
servicios. (Amazon W eb Services, s.f., https://n9.cl/fx26md)
AWS Health API 
Figura 6: AWS Health Organizational V iew Alerts (AHOV A)
Fuente: Roth, 2020, https://amzn.to/37wmeT u.
Este servicio proporciona acceso programático a la información de AWS Health que se presenta
en el panel de salud personal. Podemos usar estas operaciones de API (application program ming
interface ) para obtener información acerca de eventos que afectan los recursos de AWS.
Tema 2. Planes de soporte       
AWS Developer Support
Además de lo que se encuentra disponible con Basic Support, Deve loper Support ofrece las
siguientes herramientas. 
Figura 7: AWS T rusted Advisor
Fuente: Chapel, 2019, https://n9.cl/jxcp5w .
Video 2: ¿Cómo utilizar el servicio T rusted Advisor?
Fuente: Amazon W eb Services (17 de abril de 2020). How do I start using Trusted Advisor? [archivo de video ]. YouTube. https://n9.cl/0bk5t.
Figura 8: Información que brinda AWS T rusted Advisor
Fuente: Patil, 2018, https://n9.cl/4r8hr .
Figura 9: AWS Personal Health Dashboard
Fuente: Barr , 2008, https://amzn.to/3lT72YR.
Este tablero es 
Una vista personalizada del estado de los servicios de AWS y las alertas cuando se
afectan sus recursos. Además, incluye la API de estado para fines de integración con los
sistemas de administración existentes. (Amazon W eb Services, s.f., https://n9.cl/7iflo)
AWS Business Support
Además de lo que se encuentra disponible con Basic Support, Enterprise Support ofrece:
AWS Trusted Advisor: acceso a la totalidad de las comprobaciones de Trusted Advisor y
a aseso ramiento para aprovision ar sus recursos de acuerdo con las prácticas
recomendadas a fin de reducir los costos, mejorar el rendimiento y la tolerancia a errores,
y optimizar la seguridad.
       
AWS Personal Health Dashboard : una vista personalizada del estado de los servicios de
AWS y las alertas cuando se afectan sus recursos. Además, incluye la API de estado para
fines de integración con los sistemas de administración existentes.
API de AWS Support : acceso mediante programación a las características del centro de
AWS Support para crear , gestionar y cerrar los casos de soporte, adem ás de administrar
las solicitudes y los estados de las comprobaciones de Trusted Advisor .
Soporte técnico optimizado : acceso las 24 horas a ingenieros de soporte en la nube
mediante teléfono,  chat y correo electrónico. Puede tener un número ilimitado de contactos
que pueden crear una cantidad ilimitada de casos. Plazos de respuesta:
Asesoramiento general: < 24 horas.
Fallo en el sistema: < 12 horas.
Fallo en el sistema de producción: < 4 horas.
Sistema de producción inactivo: < 1 hora.
Sistema crítico para la empresa inactiva: < 15 min. (Amazon Web Services, s.f.,
https://n9.cl/fx26md)
       
¡Vamos a practicar!
Si querés conocer más sobre cómo utilizar la plataforma de Amazon y poner a prueba tus
conocimientos, te dejamos la siguiente actividad.
Video de habilidades
¿Cómo se llama el servicio de notificaciones que ofrece Amazon para
notificar a los administradores de las actividades de sus recursos.
Simple Notification Service (SNS).
Simple Name System.
Service Notification Send.
Send Notification Service.
Email Notification Service.
Justificación
¿Qué opción nos permite elegir un título para la notificación, a fin de saber
que nos es notificado?
Display Name.
Resource Information Name.
Select Topic.
Configure Information Notification.
Select Name System.
Justificación
Debemos saber el ARN de nuestro recurso, por el cual seremos
notificados.
Verdadero
Falso
Justificación
¿Cuál es el protocolo que debemos seleccionar para configurar las
notificaciones para correos electrónicos?
SSL.
TCP/IP .
HTTP .
UDP.
SSH.
Justificación
¿Cómo sabremos si nuestra configuración de suscripción a SNS fue
correcta?
No lo sabremos hasta que se notifique un servicio o recurso.
Debemos contactar a Amazon para consultar si el servicio se encuentra activo.
Debemos generar actividad a propósito para ser notificado
Recibiremos un correo de confirmación de suscripción.
Debemos enviar un correo a Amazon para que nos confirme la suscripción correcta.
Justificación
Cierre
Introducción a la arquitectura de soluciones de cómputo en la nube: La arquit ectura de nube
constituye la forma en la que se integran las distintas tecnologías para crear las nubes, es decir , los
entornos de TI que extraen, agrupan y comparten los recursos esca lables en una red. También
define cómo se conectan todos los elementos y las funciones que se necesitan para diseñar una
nube y obtener una plataforma en línea en la que se puedan ejecutar las aplicaciones.
Tipos de arquitecturas: Si bien la arquitectura de nube varía en función de los objetivos, la mayoría
de ellas necesitan el hardware, el middleware, la gestión y el software de automatización. Además,
utilizan la virtualización para extraer los recursos de hardware y convertirlos en lagos de datos que
se gestionan de forma centralizada. Por otra parte, algunas nubes (conocidas como las nubes sin
sistema operativo) conectan a los clientes directamente con el hardware.
Arquitectura de nube privada: entorn o de nube diseñado solo para el usuario final, generalmente
dentro del cortafuegos del usuario y , a veces, on-premise.
Arquitectura de nube pública: entorno de nube creado a partir de recursos ajenos al usuario final
que pueden redistribuirse a otros inquilinos.
Arquitectura de nube híbrida: varios entornos de nube con cierto  nivel de portabilidad,
coordinación y gestión de las cargas de trabajo entre ellos.
Arquitectura multicloud: sistemas de TI que incluyen más de una nube, pública o privada, y que
pueden conectarse en red (o no).
Introducción al soporte técnico en cloud computing: Con AWS Support, se provee una
combinación de herramientas y tecnología, profesionales y programas  diseñados para ayudar de
manera proactiva a optimizar el rendimiento, disminuir los costos e innovar con mayor rapidez. Se
ahorra tiempo al equipo, ya que se agilizan las tareas en la nube y ayuda a enfocarse en el negocio
principal. Estamos decididos a ayudar a nuestros clientes a lograr sus metas en relación con el
traspaso a la nube y a abordar las solicitudes que van desde responder preguntas sobre prácticas
recomendadas y brindar asesoramiento sobre configuraciones hasta suministrar asistencia técnica y
solucionar problemas.
Planes de soporte : Además  de lo que se encuentra disponible con Basic Support, Enterprise
Support ofrece:
AWS Trusted Advisor - Acceso a la totalidad de las comprobaciones de Trusted Advisor y a
asesoramiento para aprovisionar sus recursos de acuerdo con las prácticas recomendadas a fin de
reducir los costos, mejorar el rendimiento y la tolerancia a errores, y optimizar la seguridad.
AWS Personal Health Dashboard - Una vista personalizada del estado de los servicios de AWS y
las alertas cuando se afectan sus recursos. Además, incluye la API de estado para fines de
integración con los sistemas de administración existentes.
API de AWS Supp ort: Acceso mediante programación a las características del centro de AWS
Support para crear , gestionar y cerrar los casos de soporte, además de administrar las solicitudes y
los estados de las comprobaciones de Trusted Advisor .
Soporte técnico optimizado: Acceso  las 24 horas a ingenieros de sopo rte en la nube mediante
teléfono, chat y correo electrónico. Puede tener un número ilimitado de contactos que pueden crear
una cantidad ilimitada de casos.
Referencias
Amazon Web Services (s.f.).  AWS Premium Support . Amazon AWS.
https://aws.amazon.com/es/premiumsupport/.
Amazon Web Services  (s.f.). AWS Enterprise Support. Amazon AWS.
https://aws.amazon.com/es/premiumsupport/plans/enterprise/.
Amazon Web Services  [Amazon  Web Services] (17 de abril de 2020). How do I start using
Trusted Advisor? [YouTube] Recuperado de https://www .youtube.com/watch?v=i0IkKN9NoPk.
Amazon Web Services  (06 de septiem bre de 2018). AWS Enterprise Support: Custom er
Obsession at Work  [archiv o de video]. YouTube. https://www .youtube.com/watch?
time_continue=1 1&v=S4Vbfv72HSw .
Barr, J. (2016). New – AWS Personal Health Dash board – Status You Can Relate to. Amazon
AWS. https://aws.amazon.com/es/blogs/aws/new-aws-personal-health-dashboard-status-you-can-
relate-to/.
Barr, J. (2008). The Service Health Dashboard . Amazon AWS.
https://aws.amazon.com/es/blogs/aws/the-service-hea/.
Chapel, J. (2019). AWS Trusted Advisor Implies the Existence  of AWS Doubted Advisor . Medium.
https://jaychapel.medium.com/aws-trusted-advisor-implies-the-existence-of-aws-doubted-advisor-
f135719ca88a.
Hill, D. (2018). Consideraciones en un mundo de nubes múltiples . Veeam.
https://www .veeam.com/blog/es-lat/multi-cloud-considerations.html.
Hybrid ITC (2018). Public Cloud . Hybrid ITC https://www .hybridict.com.au/corporate-cloud-
services/cloud-computing/public-cloud/.
Microsoft Azure  (s.f.). ¿Qué es la nube pública, privada e híbrida?  Microsoft.
https://azure.microsoft.com/es-mx/overview/what-are-private-public-hybrid-clouds/.
Patil, J. (5 de marzo de 2018). AWS Trusted Advisor – Certification . Jayendr a’s Cloud  Certification
Blog. https://jayendrapatil.com/aws-trusted-advisor-categories/. 
Red Hat Inc. (s.f.). Cloud Computing: ¿Qué es la arquitectura de nube?  Red Hat Inc.
https://www .redhat.com/es/topics/cloud-computing/what-is-cloud-architecture.
Red Hat Inc. (s.f.). Cloud Computing: ¿Qué es una nube pública?  Red Hat Inc.
https://www .redhat.com/es/topics/cloud-computing/what-is-public-cloud.
Red Hat Inc. (s.f.). Cloud Computing : ¿Qué es una nube privada? Red Hat Inc.
https://www .redhat.com/es/topics/cloud-computing/what-is-private-cloud.
Red Hat Inc. (s. f. d). Nube híbrida: su función, diseño y seguridad ¿Qué es una nube híbrida?
Red Hat Inc. https://www .redhat.com/es/topics/cloud-computing/what-is-hybrid-cloud.
Red Hat Inc. (s. f. e). Cloud Computing: ¿Qué es una muticloud? Red Hat Inc.
https://www .redhat.com/es/topics/cloud-computing/what-is-multicloud. 
Roth, J. (2020). Send Organizational AWS Health Events to Amazon Chime or Slack . Amazon
AWS. https://aws.amazon.com/es/blogs/mt/send-organizational-aws-health-events-to-amazon-
chime-or-slack/.
A continuación podrás descargar la lectura en formato PDF o MP3:


----- AnexoM2.pdf -----
 
Gestión Operativa en la Nube (Cloud 
Practitioner)  
Módulo 2            
  
Creación de Volúmenes EBS EN AWS y Adición 
de los mismos a una Instancia EC2 (Linux)  
 
En este documento vas a encontrar algunos conceptos y definiciones 
necesarias para la realización del laboratorio AWS correspondiente a este 
módulo. En esta oportunidad aprenderemos a dividir volúmenes en varias 
particiones, conservando el tamaño base de 8-10 GB o haciéndolos incluso 
más pequeños para ahorrar costos.   
  
Requerimientos previos  
 
  
Para llevar a cabo este procedimiento es necesario contar con una instancia 
EC2 auxiliar, además de aquella instancia cuyo volumen raíz queramos 
particionar. Cualquier tipo de instancia servirá como auxiliar, por lo que 
podemos optar por la más económica disponible. Al momento de la realización 
de este instructivo, esta es: t2.nano. Y, dado que Amazon sólo nos cobrará por 
el tiempo que tardemos en ejecutar el procedimiento (unos 30 minutos), el 
coste asociado será muy bajo.  
  
Si ya disponemos de otra instancia EC2 corriendo en la misma región y zona 
de disponibilidad no será necesario crear una nueva, ya que podremos usar la 
existente para montar los volúmenes que vamos a necesitar más adelante.   
Estos montajes no tendrán ningún impacto significativo sobre el rendimiento ni 
la capacidad del servidor auxiliar que utilicemos, pero aun así no es 
recomendable usar uno en producción que sea crítico para nosotros, pues si 
nos equivocamos en algún paso podemos afectar el servicio que presta.  
No es imprescindible, pero sí muy recomendable, que la instancia auxiliar 
tenga la misma distribución y versión de Linux que la instancia que queremos 
particionar para que la instalación del cargador de arranque en el nuevo 
volumen sea lo más directa y exenta de problemas posible. Para el ejemplo 
será una instancia Ubuntu 16.04.2 LTS.  
  
 
Partimos por tanto con 2 instancias en ejecución: a aquella que queremos 
particionar la llamaremos AMI y la instancia auxiliar, la denominaremos AUX, 
cada una con su correspondiente root volume: amiroot y auxroot.  
Imagen 1: Instancias EC2 de partida  
  
  
Fuente: captura de pantalla.   
  
Imagen 2: Volúmenes EBS de partida   
  
  
Fuente: captura de pantalla.   
  
1. Crear un nuevo volumen EBS  
En nuestro ejemplo vamos a crear un volumen más pequeño (6 GB) que el 
tamaño por defecto de 8 GB que ofrece Amazon, pero podemos elegir el 
tamaño que más nos convenga. Podemos aprovechar también para cifrar el 
nuevo volumen, ya que por defecto todos los volúmenes raíces que utilizan las 
AMI’s de Amazon no están encriptados.  
Imagen 3: Creación del nuevo volumen EBS a particionar  
  
  
Fuente: captura de pantalla.   

  
 
En la siguiente imagen, vemos como el nuevo volumen se incorporó al 
dashboard.   
Imagen 4: Creación del nuevo volumen EBS a particionar  
  
Fuente: captura de pantalla.   
  
2. Vincular el nuevo volumen a una instancia.   
Lo primero que se debe hacer es desvincular el volumen  amiroot de la instancia 
AMI y vincularlo a la instancia auxiliar AUX. Para ello es necesario detener 
primero la instancia AMI, ya que al ser su root volume no se puede desvincular 
sin pararla antes.   
Por el contrario, ambos volúmenes se pueden vincular a la instancia auxiliar en 
caliente, sin ningún problema, pues su volumen raíz es auxroot y ese no lo 
tocaremos en ningún momento. Asignaremos el dispositivo /dev/sdf al volumen 
amiroot y el /dev/sdg a myroot. En las siguientes imágenes puedes ver cada 
uno de estos pasos.  
  
  
  
  
  
  
  

  
 
Imagen 5: Desvincular volumen amiroot de la instancia AMI  
  
  
Fuente: captura de pantalla.   
  
Imagen 6: Vincular volumen amiroot a la instancia auxiliar  
  
  
Fuente: captura de pantalla.   
  
3. Comprobar que la instancia auxiliar reconoce los nuevos volúmenes 
vinculados:  
Entraremos mediante SSH a la instancia auxiliar y comprobaremos que los 
nuevos volúmenes están disponibles con el comando lsblk:  

  
 
 
Si todo ha ido bien debería aparecer nuestro volumen amiroot como xvdf y 
myroot como xvdg. Como se puede observar, existe una partición /dev/xvdf1 
de 8 GB ya creada, que se corresponde con la partición que traía el volumen 
raíz de la instancia creada a partir de la AMI de Amazon. El volumen myroot 
como se ha creado desde cero no tiene todavía ninguna partición creada.  
4. Crear esquema de particiones personalizado en el volumen myroot  
Ha llegado el momento de particionar el volumen a nuestro gusto, que es 
realmente nuestro objetivo inicial. No obstante, si has especificado el tamaño 
de las particiones usando porcentajes (%) en lugar de GB, MB o sectores no 
tendrás que preocuparte por esto porque “parted” siempre las alineará de 
forma óptima y el resultado de la comprobación anterior será siempre 
satisfactorio.  
  
Al salir de parted es posible que recibas el siguiente mensaje:  
 
~ 
$ ssh ubuntu@ec2  
- 
54 
- 
194 
- 
114 
- 
199 
.eu 
- 
west 
- 
1 
.compute 
. 
amazonaws  
. 
com  
- 
i  
~ 
/.ssh/ 
awskey 
. 
pem 
  
Welcome 
  
to  
Ubuntu 
  
16.04 
. 
2 
  
LTS  
( 
GNU 
/ 
Linux 
  
4.4 
. 
0 
- 
1020 
- 
aws x86_64  
) 
  
... 
  
... 
  
ubuntu@ip  
- 
172 
- 
31 
- 
17 
- 
107 
: 
~ 
$ lsblk 
  
NAME  
    
MAJ 
: 
MIN RM SIZE RO TYPE MOUNTPOINT  
  
xvda  
    
202 
: 
0 
  
    
0 
  
   
8 
G 
  
  
0 
  
disk 
  
└─ 
xvda1  
202 
: 
1 
  
    
0 
  
   
8 
G 
  
  
0 
  
part  
/ 
  
xvdf  
    
202 
: 
80 
  
   
0 
  
   
8 
G 
  
  
0 
  
disk 
  
└─ 
xvdf1  
202 
: 
81 
  
   
0 
  
   
8 
G 
  
  
0 
  
part 
  
xvdg  
    
202 
: 
96 
  
   
0 
  
   
6 
G 
  
  
0 
  
disk 
  
  
( 
parted 
) 
  
quit 
  
Informaci 
ó 
n 
: 
  
Puede 
  
que sea necesario actualizar  
/ 
etc 
/ 
fstab 
  
  
  
 
En ese caso, si no vemos el nuevo esquema de particiones con el comando 
lsblk tendremos que ejecutar el comando partprobe, y a continuación, ya 
debería mostrarse correctamente:  
~# lsblk                                               
NAME    MAJ :MIN RM  SIZE RO TYPE MOUNTPOINT   
xvda    202:0    0    8G  0 disk   
└─xvda1 202:1    0    8G  0 part /  
xvdf    202:80   0    8G  0 disk   
└─xvdf1 202:81   0    8G  0 part   
xvdg    202:96   0    6G  0 disk    
├─xvdg1 202:97   0    1M  0 part    
├─xvdg2 202:98   0  1.2G  0 part    
├─xvdg3 202:99   0  307M  0 part    
├─xvdg4 202:100  0  307M  0 part    
├─xvdg5 202:101  0  2.1G  0 part    
└─xvdg6 202:102  0  2.1G  0 part  
5. Formatear las nuevas particiones  
Una  vez  encontremos  el  esquema  de  particiones  a  nuestro  
gusto, procederemos a formatear todas ellas, excepto la partición de arranque 
BPP y la de swap. Usaremos el sistema de ficheros más estándar de Linux, el 
ext4:  
  
  
~# for I in 2 4 5 6; do mkfs.ext4 /dev/xvdg${I}; done  
...  
...  
~# mkswap /dev/xvdg3  
Setting up swapspace version 1, size = 307 MiB (321908736  bytes)  no label, UUID=1aad1fa2 -188e-
4b7a-8a0f-33f775cdd329   
  
  
 
6. Montar las particiones:   
Montaremos todas aquellas particiones cuyo contenido nos interese replicar a 
partir del disco raíz de la AMI de partida, que serán la partición raíz (/), /home, 
/usr y /var del volumen myroot. También montaremos la partición raíz del 
volumen amiroot:  
~# mkdir /mnt/amiroot  
~# mkdir -p /mnt/myroot/root /mnt/myroot/home /mnt/myroot/usr /mnt/myroot/var  
  
~# tree /mnt   
/mnt   
├── amiroot  └── 
myroot   
    ├── home   
    ├── root   
    ├── usr   
    └── var   
   
6 directories , 0 files  
  
~# mount /dev/xvdf1 /mnt/amiroot  
~# mount /dev/xvdg2 /mnt/myroot/root  
~# mount /dev/xvdg4 /mnt/myroot/home  
~# mount /dev/xvdg5 /mnt/myroot/usr  
~# mount /dev/xvdg6 /mnt/myroot/var  
7. Sincronizar el contenido de amiroot en su correspondiente partición.  
Sincronizaremos con rsync el contenido de los distintos directorios de la única 
partición del volumen raíz de la AMI de partida (amiroot) en sus 
correspondientes particiones asignadas. Hay que tener la precaución de no 
copiar en la nueva partición raíz el contenido de esos mismos directorios que 
ahora tienen una partición propia asignada, por lo que usaremos el parámetro 
  
 
–exclude de rsync. Dado que hemos excluido esos directorios, los crearemos 
manualmente, pero vacíos y con los permisos adecuados:  
~# rsync -av /mnt/amiroot/home/ /mnt/myroot/home/  
~# rsync -av /mnt/amiroot/usr/ /mnt/myroot/usr/  
~# rsync -av /mnt/amiroot/var/ /mnt/myroot/var/  
~# rsync -av --exclude=home --exclude=usr --exclude=var /mnt/amiroot/ /mnt/myroot/root/  
~# mkdir /mnt/myroot/root/home;chmod 755 /mnt/myroot/root/home  
~# mkdir /mnt/myroot/root/usr;chmod 755 /mnt/myroot/root/usr ~# 
mkdir /mnt/myroot/root/var;chmod 755 /mnt/myroot/root/var  
  
  
Es muy importante que llegados a este punto, desmontemos la partición del 
volumen original amiroot y lo desvinculemos de la instancia auxiliar para que 
el instalador del cargador de arranque grub, que ejecutaremos en el siguiente 
punto, no detecte que hay otra partición bootable, para que no interfiera con la 
de nuestro nuevo volumen.   
No basta sólo con desmontarla con el comando umount, sino que será 
necesario también desconectarla de la instancia como hemos hecho 
anteriormente en el apartado 2.  
~# sync && umount /mnt/amiroot  
8. Instalar el cargador de arranque grub en el nuevo volumen myroot  
Antes de hacer la instalación, tendremos la precaución de deshabilitar los 
scripts /etc/grub.d/10_linux y /etc/grub.d/20_linux_xen porque pueden generar 
algún problema a la hora de detectar nuestra partición arrancable BPP.   
Para ello bastará con que añadamos el comando exit a la segunda línea de 
ambos ficheros, justo después de #! /bin/sh.  
A continuación, eliminaremos el fichero /boot/grub/grub.cfg que era el que traía 
la AMI en origen para sustituirlo por uno adaptado a nuestro nuevo volumen 
recién particionado:  
~# rm /mnt/myroot/root/boot/grub/grub.cfg  
~# grub-mkconfig -o /mnt/myroot/root/boot/grub/grub.cfg  
  
 
  
Ahora ya podemos instalar el cargador de arranque grub en nuestro nuevo 
disco de 6 GB:  
 
No olvidar volver a habilitar los scripts 10_linux y 20_linux_xen cuando 
hayamos terminado, si hemos utilizado como instancia auxiliar un servidor que 
estemos usando para otro cometido. Si no estamos utilizando una instancia 
previa, al finalizar el procedimiento terminaremos la instancia y ésta se 
destruirá.  
9. Reflejar en el fichero /etc/fstab las nuevas particiones:  
Primero será necesario obtener los identificadores UUID de las particiones con 
el comando blkid. Es mejor ejecutarlo como root, de otra forma, no mostrará 
información de la partición de swap.  
~# blkid   
/dev/xvda1: LABEL="cloudimg-rootfs"  UUID="567ab888-a3b5-43d4-a92a-f594e8653924"  
TYPE="ext4" PARTUUID ="1a7d4c6a-01"    
/dev/xvdg2: UUID="286a4418-45b4-40c6-aece-6a4e1efd247a " TYPE="ext4" PARTLABEL ="root" 
PARTUUID ="56c0cfb6-20eb-4123-a766-420911980fb3"    
/dev/xvdg4: UUID="6e244eed-310f-4aae-aaa1-7ef549bbdbd1 " TYPE="ext4" PARTLABEL ="home" 
PARTUUID ="bdbacb79-532b-410f-853e-f5530c4f9fa7"    
/dev/xvdg5: UUID="cceffcdd-1aeb-4aab-b8e0-7ac04893858c " TYPE="ext4" PARTLABEL ="usr" 
PARTUUID ="fbee2b01-9d41-4c16-bda6-a4b2abc02a04"    
/dev/xvdg6: UUID="b3fe50cb-b147-4b3b-b8ce-17ee445db64c " TYPE="ext4" PARTLABEL ="var" 
PARTUUID ="b4983050-a4e6-4d8a-9284-1a269a451d35"   
/dev/xvdg3: UUID="1aad1fa2-188e-4b7a-8a0f-33f775cdd329 " TYPE="swap" PARTLABEL ="swap" 
PARTUUID ="24eecaf3-4942-4ead-bab4-909e359dd5ae"   
/dev/xvdg1: PARTLABEL ="bbp" PARTUUID ="916ca11f-db90-48d1-93d2-de6a99b60f40"   
  
A continuación, trasladamos esos identificadores al fichero 
/mnt/myroot/root/etc/fstab así:  
~# 
  
grub 
- 
install  
-- 
target 
= 
i386 
- 
pc  
-- 
directory 
= 
/mnt/ 
myroot 
/ 
usr 
/ 
lib 
/ 
grub 
/ 
i386 
- 
pc  
-- 
recheck  
-- 
boot 
- 
directory 
= 
/mnt/ 
myroot 
/ 
root 
/ 
boot  
/ 
dev 
/ 
xvdg 
  
  
  
 
UUID=286a4418 -45b4-40c6-aece-6a4e1efd247a   /      ext4   
defaults,discard,noatime,errors=remount-ro      0 1  
UUID=6e244eed -310f-4aae-aaa1-7ef549bbdbd1   /home  ext4   
defaults,noatime,acl,user_xattr ,nodev,nosuid    0 2  
UUID=cceffcdd-1aeb-4aab-b8e0-7ac04893858c   /usr   ext4   
defaults,noatime,nodev,errors=remount-ro        0 2  
UUID=b3fe50cb -b147-4b3b-b8ce-17ee445db64c   /var   ext4   defaults ,noatime,nodev,nosuid          
0 2  
UUID=1aad1fa2 -188e-4b7a -8a0f-33f775cdd329   swap   swap   defaults                                        0 0 
tmpfs                                      /tmp   tmpfs  defaults ,noatime,nodev,noexec,nosuid,size=256m  0 0  
10. Vincular el nuevo volumen como root volume de la instancia que lanzamos 
a partir de la AMI  
Como parte del último punto de este procedimiento, vamos a desmontar todas 
las particiones que armamos anteriormente y a desvincular el volumen myroot 
ya particionado, configurado y listo para el arranque de la instancia auxiliar, 
para vincularlo a la instancia definitiva en la que será utilizado (en nuestro caso 
la instancia AMI que lanzamos en un primer momento)  
~# sync && umount /mnt/myroot/root /mnt/myroot/home /mnt/myroot/usr /mnt/myroot/var  
Es muy importante que cuando vinculemos el volumen myroot a la instancia 
EC2, indiquemos como dispositivo /dev/sda1 para indicar que se trata del root 
volume de la instancia, ya que, si no lo ponemos así, tendremos problemas 
con el arranque del sistema operativo.  
Si todo ha ido bien, nuestra instancia arrancará normalmente y podremos ver 
en el log de sistema de la instancia EC2 el mensaje de login. Si algo va mal 
obtendremos más información del problema en ese mismo log.  
Finalmente, hemos creado nuestro Volumen EBS y lo hemos particionado en 
nuestra Instancia Linux.   
  
  


----- AnexoM3.pdf -----
 
Gestión Operativa en la Nube (Cloud 
Practitioner)  
Módulo 3            
  
Creación de una Instancia EC2 en una VPC con 
un Web Server  
 
Del extenso abanico de servicios AWS, trabajaremos en esta ocasión con 
Amazon Elastic Compute Cloud (Amazon EC2), el cual nos permite tener un 
servidor virtual VPS de manera gratuita, siempre y cuando no se superen las 
750h de uso al mes. Más que suficiente para dar los primeros pasos.  
  
Cómo configurar un servidor en Amazon Web 
Service  
 
1. Login en AWS  
Lo primero que nos aparece cuando hacemos login en AWS es el dashboard 
principal. Allí, para comenzar a crear un servidor (instancia) nos dirigiremos a 
la pestaña Services  y seleccionaremos EC2.  
Imagen 1: Dashboard  
 
  
  
Fuente: captura de pantalla.  
2. Luego deberás asegurarte de tener la ubicación del centro de datos  en la 
zona que creas conveniente. En este caso, hemos elegido California, puesto 
que queremos montar un servidor web cerca de LATAM.  

 
  
  
Definida la zona del centro de datos, daremos clic en el botón “Launch 
Instance”.  
  
Imagen 2: Launch Instance  
  
 
  
Fuente: captura de pantalla.  
  
  
3. Elegir SO  
  
Para seguir el asistente, debes seleccionar el sistema operativo del servidor , 
del listado que te ofrece AWS. En este caso, elegimos ubuntu 16.04 ya que 
es una de las opciones gratuitas.  
  
Imagen 3: Sistemas operativos.  
  
 
Fuente: captura de pantalla.  
4. Elegir tipo instancia   
  
El hardware es el siguiente paso a elegir. Podrán observar que AWS ofrece un 
largo listado de ellas, cada una con cualidades particulares. Sin embargo, en 
esta oportunidad, utilizaremos el tipo de instancia predeterminado, llamado 

 
  
“General purpose”  y haremos clic en el botón “Next:Configure Instance 
Details” , ubicado en la esquina inferior derecha de la pantalla.  
  
Imagen 4: Tipos de instancia  
  
 
  
Fuente: captura de pantalla.  
  
5. Configuración de instancia  
  
En esta pantalla podrás validar las características de la instancia que se está 
por lanzar. Podemos ver en el ejemplo que se asignó la vpc-506e4137  
(default).  
  
Dejamos estos valores por defecto, en caso de no necesitar otras 
características particulares, de manera de seguir disfrutando de la capa 
gratuita de AWS. En este apartado, se creará automáticamente la VPC en la 
cual residirá nuestra Instancia, ya que la misma, se generará por “default”.  
Esto significa que Amazon hará un “deployment” de nuestra instancia dentro 
de una VPC, sin coste alguno.  
  
  
  
  
  
  
  
Imagen 5: Configuración de la instancia  
  

 
  
 
  
Fuente: captura de pantalla.  
  
6. En la misma pantalla en la que nos encontramos, haciendo clic en el botón 
“Next: Add Storage”  podemos configurar el almacenamiento y tenemos la 
posibilidad de crear un contenedor de unos 30Gb sin problema.  
  
Imagen 6: Configurar almacenamiento  
  
  
  
Fuente: captura de pantalla.  
  
  
7. En el siguiente paso, se podrán añadir Tags. Esta es una práctica 
recomendada por AWS y es un recurso muy útil para llevar una buena 
organización de las máquinas que vayamos desplegando, no es más que 
un nombre asociado a la instancia.  
  
Realizado este paso, haremos clic en “Next: Configure Security Group”  para 
seguir adelante.  

 
  
  
8. Configurar grupo de seguridad  
  
En este grupo definiremos las reglas de nuestro firewall, por defecto viene 
añadida la de permitir todo el tráfico del servicio SSH. Los puertos se 
mantendrán bloqueados hasta que se añada la excepción en el grupo de 
seguridad de nuestro servidor web en Amazon.  
9. Luego procederemos a hacer clic en “REVIEW AND LUNCH” para pre  
visualizar los datos finales y las características del VPS  
Imagen 7: Review and Lunch  
  
  
 
  
Fuente: captura de pantalla.  
  
En este momento, si todo está correcto, ya estamos en condición de lanzar la 
instancia. Simplemente se debe clicar sobre el botón “Lanzamiento”  para 
iniciar la instalación de la misma. Sin embargo, antes de iniciarla, veremos 
cómo generar un par de claves SSH para autenticar la cuenta.  
  
  
10. Generación de llaves SSH  
  
En este paso, indicaremos que queremos crear un nuevo par de llaves SSH 
con las que, posteriormente, iniciaremos sesión en la instancia:   
1- Crear un nuevo par de claves  
2- Otorgar un nombre  

 
  
3- Descargar el par de claves. Este paso es muy importante ya 
que esta es la única instancia en la que podrás descargar el 
archivo de claves. No podrás recuperarlo una vez que se 
haya creado.   
4- Hacer clic en “Instancias de Lanzamiento”   
Imagen 8: Generación de llaves SSH  
  
  
Fuente: captura de pantalla.  
  
  
11. Ahora sí, haremos clic sobre el botón “Lanzamiento” . Tras un par de 
minutos tendremos la instancia finalizada y operativa. Puedes verificarla, 
haciendo clic en el botón “Ver instancia” .  
  
Conectarse a una instancia.  
  
Este es el panel donde verás la instancia. Para conectarte al servidor tendrás 
que seleccionarla y hacer clic en “Connect” .  
  
  
  
  
  
Imagen 9: Panel de instancias: “Connect”  
  

 
  
 
  
Fuente: captura de pantalla.  
  
Conectarse a la instancia de Linux: Guía para conectarse 
usando putty   
  
Para conectarse a la instancia mediante SSH:  
1. Puedes verificar la huella digital de la clave RSA en la instancia en ejecución 
utilizando un comando en el sistema local (no en la instancia).  
Debes localizar la sección SSH HOST KEY FINGERPRINTS , anotar la huella 
digital de RSA (por ejemplo,  
1f:51:ae:28:bf:89:e9:d8:1f:25:5d:37:2d:7d:b8:ca:9f:f5:f1:6f) y compararla 
con la huella digital de la instancia.  
Este paso es opcional y resultará muy útil si has lanzado la instancia desde 
una AMI pública de terceros.  
  
 ▪  get-console-output (AWS CLI)  
aws ec2 get-console-output --instance-id instance_id  
  
  
2. Asegúrate de que la instancia está en el estado running y no en pending. La 
sección SSH HOST KEY FINGERPRINTS  solo está disponible después del 
primer arranque de la instancia.  
3. En un shell de línea de comandos, cambia los directorios a la ubicación 
del archivo de clave privada que creaste al lanzar la instancia.  
4. Usa el siguiente comando para configurar los permisos del archivo de 
clave privada, de manera que solo tú puedas leerlo:  
  

 
  
chmod 400 /path/my-key-pair.pem  
  
Si no configuras estos permisos, no podrás conectarte a la instancia con 
este par de claves.   
  
5. Usa el comando ssh para conectarte a la instancia, especificando el 
archivo ( .pem) de clave privada y  
nombre_de_usuario@nombre_dns_pública.   
  
Por ejemplo, si has utilizado Amazon Linux 2 o la AMI de Amazon Linux, 
el nombre de usuario es ec2-user.  
ssh -i /path/my-key-pair.pem ec2-user@ec2-198-51-100-
1.compute1.amazonaws.com  
  
Deberías ver una respuesta como la siguiente:  
The authenticity of host 'ec2-198-51-100-1.compute-1.amazonaws.com  
(10.254.142.33)' can't be established. RSA key fingerprint is  
1f:51:ae:28:bf:89:e9:d8:1f:25:5d:37:2d:7d:b8:ca:9f:f5:f1:6f. Are you sure 
you want to continue connecting (yes/no)?  
6. También puede conectarse a la instancia mediante su dirección IPv6. 
Especifica el comando ssh con la ruta al archivo de clave privada ( .pem), 
el nombre de usuario adecuado y la dirección IPv6.  
Por ejemplo, si has utilizado Amazon Linux 2 o la AMI de Amazon Linux, 
el nombre de usuario es ec2-user.  
ssh -i /path/my-key-pair.pem ec2- 
user@2001:db8:1234:1a00:9691:9503:25ad:1761  
  
7. Opcionalmente, puedes verificar que la huella digital en la alerta de 
seguridad coincide con la huella digital que obtuviste en el paso 1. Si estas 
huellas digitales no coinciden, alguien podría intentar un ataque man-
inthe-middle (MITM). Si coinciden, puedes continuar con el siguiente 
paso.  
  
8. Escribe yes y deberías ver una respuesta como la siguiente:  
Warning: Permanently added 'ec2-198-51-100-
1.compute1.amazonaws.com' (RSA) to the list of known hosts.  
Instalar servidor web en Amazon (Apache)  
Basta con iniciar sesión en el servidor y ejecutar el siguiente comando:  
apt-get install apache2  
  
Instalar servidor web en Amazon (Nginx)  
Basta con iniciar sesión en el servidor y ejecutar el siguiente comando:  
 
  
apt-get install nginx  
  
  


----- AnexoM4.pdf -----
  
 
Gestión Operativa en la Nube (Cloud 
Practitioner)  
 
Módulo 4     
 
Buenas Prácticas en IAM (Identity and Access 
Management) y Configuraciones Recomendadas 
por Amazon Web Services  
 
A continuación, vas a encontrar algunos conceptos y definiciones relacionadas 
con las características de los usuarios, grupos y roles IAM. Además, te 
enseñaremos los primeros pasos necesarios para iniciarte en el uso de la 
consola de AWS.  
  
  
Los usuarios IAM  
 
Como hemos visto, IAM es un servicio web que permite a los clientes de AWS 
administrar los usuarios y sus respectivos permisos.  Los usuarios IAM, son 
objetos de la cuenta que permiten a un usuario individual acceder al entorno 
AWS con un conjunto de credenciales. Si bien no es lo más recomendable, los 
permisos se pueden aplicar individualmente a un usuario, y lo más idóneo es 
vincular a cada uno a un grupo IAM. Es a este grupo al que se asignan los 
permisos para acceder a los recursos y objetos de AWS. Por eso, lo primero 
que vamos a hacer es crear un usuario en IAM.  
  
Cómo crear un usuario en AWS  
1. Al acceder a la consola de AWS, selecciona el servicio IAM:  
Imagen 1: Consola AWS  
  
  
 
 
  
Fuente: captura de pantalla.  
2. En el panel lateral izquierdo, selecciona Usuarios (Users):  
Imagen 2: Agregar un usuario  
  
Fuente: captura de pantalla.  
  
3. En la parte superior, se muestra un botón azul con el texto “Add User”; hace 
clic para lanzar el asistente para la creación de un usuario. Allí verás la 

  
 
siguiente pantalla donde deberás: elegir un nombre para el usuario y cómo 
va a “comunicarse” con AWS. Imagen 3: Creación de un usuario  
 
Fuente: captura de pantalla.  
  
4. Selecciona un tipo de acceso:  
La primera opción, el acceso programático , es el adecuado para la 
interacción de aplicaciones, desde línea de comandos, etc. El acceso a través 
de la consola  (la web de AWS) es el acceso que estamos usando en estos 
momentos, a través de un navegador. Este es el tipo de acceso que usará una 
persona, moviendo el ratón y pulsando botones.  
Un usuario puede tener los dos tipos de accesos. Sin embargo, las acciones (y 
por tanto los permisos) que asocies a cada usuario debe ser siempre los 
mínimos requeridos.  
Como los usuarios no tienen costo, lo más recomendable es crear un usuario 
programático (o varios) para las aplicaciones o scripts con permisos ajustados 
a su funcionalidad, mientras que el usuario con el que interacciones a través 
de la consola tenga permisos diferentes.  
En función del tipo de acceso que selecciones, aparecen opciones diferentes 
en cuanto a la manera de validar la identidad del usuario:  
→ En el caso de un usuario de consola : puedes hacer que AWS genere una 
contraseña ( “Autogenerated  password” ) o puedes introducir una manualmente 
(“Custom  password” ).   

  
 
Como puedes ver en la siguiente imagen, si se elige la opción “ Autogenerated 
password ”,  AWS  automáticamente  asocia  al  usuario una política 
llamada IAMUserChangePassword . Esta permite que el propio usuario 
cambie la contraseña la primera vez que acceda a AWS, de esta forma se 
garantiza que sólo él conozca su password.  
Imagen 5: Usuario de consola  
 
Fuente: captura de pantalla.  
  
→ En el caso del acceso programático:  para que el usuario pueda 
autenticarse en la API de AWS, deberás habilitar una clave de acceso (Access 
Key) y una Secret Key. Para ello, debes seleccionar qué permisos vas a 
asociar al usuario. En este caso tenés 3 opciones:  
1- Asignar el usuario a un grupo (de forma que heredará los permisos 
asociados al grupo).  
2- Copiar los permisos de otro usuario  
3- Asignar una política  
Actualmente existen más de 400 políticas gestionadas por Amazon. Por lo que, 
para empezar, lo habitual y lo más práctico es crear un usuario con permisos 
de administración total ( AdministratorAccess ).  
El tema de las políticas es quizás uno de los temas más importantes con el que 
debes familiarizarte. A muy grandes rasgos, una política permite definir 
con muchísima granularidad qué puede hacerse y dónde.   
En la siguiente imagen, puedes ver que la política AdministratorAccess  permite 
("Effect":"Allow"), todas las acciones en cualquier servicio ( "Action": "*") y sobre 
cualquier recurso ( "Resource": "*" ):  

  
 
Imagen 6: Política AdministratorAccess   
  
Fuente: captura de pantalla.  
  
5. El siguiente paso es opcional, y consiste en aplicar etiquetas (“tags”) al 
usuario. Si bien los mismos pueden no etiquetarse, como forma parte de las 
buenas prácticas de AWS, se recomienda hacerlo, para una correcta 
organización.  
Imagen 7: Tags  
 
Fuente: captura de pantalla.  
  
6. En la siguiente pantalla, realiza una revisión final antes de crear 
definitivamente el usuario. En este caso observa que tienes dos políticas 
aplicadas: AdministratorAccess  y IAMUserChangePassword.  Si todo está 
correcto, hace clic en “Create User”   

  
 
Imagen 8: Revisión de usuario  
 
Fuente: captura de pantalla.  
  
7. Tras la creación del usuario, Amazon te ofrece la posibilidad de 
descargar las credenciales generadas. También tienen un botón para “mostrar” 
la contraseña generada y copiarla. Esta es la única instancia para hacerlo, en 
cuanto cierres esta pantalla, no es posible recuperar la contraseña (aunque sí 
podrás cambiarla por una nueva).   
8. Finalmente, el cartel de “Succes” te indica que el usuario está listo y con 
el permiso para acceder a la consola web de Amazon.  

  
 
Imagen 9: Usuario exitoso 
 
Fuente: captura de pantalla.  
  
Roles IAM  
La segunda herramienta que utilizaremos de la consola, tiene que ver con la 
creación de roles. Un rol es la forma que tenemos de asignar permisos a 
recursos AWS . Vamos a crear un rol para permitir que las instancias EC2 
accedan al almacenamiento S3:  
1- En el panel de control IAM, iremos a Roles > Create Role . En la pantalla, 
verás que es posible seleccionar distintas opciones. En este caso, 
seleccionaremos el rol para EC2 y pulsaremos el botón “Next: 
Permissions”  ubicado en la esquina inferior derecha  
      
     

  
 
Imagen 10: Roles IAM  
 
  
2- Los roles tienen ciertas “policies” asociadas, por lo que en la siguiente 
pantalla buscaremos, en el listado de permisos S3, la que queremos 
utilizar. En esta oportunidad seleccionaremos “AmazonS3FullAccess”  y 
aceptaremos con el botón “Next: Review”    
   
     
Imagen 11: Seleccionar policies.  

  
 
   
Fuente: captura de pantalla.  
  
En el paso siguiente, le daremos un nombre al rol que hemos creado y 
pulsaremos el botón: “Create Role” .  
  
Imagen 12: Nombrar rol  
 
Fuente: captura de pantalla.  
  
  

  
 
Los grupos IAM  
Los grupos IAM son objetos que permiten gestionar de manera eficiente 
los permisos y el acceso a sus recursos en AWS.  Su uso es recomendable 
para gestionar los permisos y necesario en el caso de que haya un número 
considerable de usuarios con acceso a recursos AWS. Cada grupo abarca 
distintos usuarios con los mismos permisos, en el caso de que no se les 
asignen explícitamente permisos directamente.  
El usar grupos de IAM te permite tener los usuarios bien organizados y ahorrar 
tiempo. Dado que, el caso de que tengas que añadir un nuevo usuario 
únicamente deberás vincularlo al grupo que corresponda y los permisos se le 
añadirán automáticamente. Una buena práctica de AWS es, por ejemplo, crear 
un grupo para cada departamento (Admins, Developers, etc) dado que todos 
los integrantes de cada grupo deberán ejercer tareas similares dentro del 
entorno AWS.  
  
Políticas IAM  
Las “políticas IAM” es un documento, en el que enumeran las acciones que un 
usuario, grupo o rol puede realizar sobre los recursos de AWS. A continuación, 
mencionaremos algunas de las características de las políticas IAM:  
• Archivos en formato JSON.  
• Por defecto el permiso está denegado ( Deny by default )  
• En el caso de que haya varias políticas, siempre prevalecerán las más 
restrictivas.  
• El orden de prioridad es el siguiente:   
  
1 Explicit Deny  
  
2 Explicit Allow  
  
3 Implicit Deny  
      
  
 
Imagen 13: Políticas IAM  
  
Fuente: captura de pantalla.  
  
El campo “Effect”  es donde se establece si es una política de permitir o 
denegar, por lo que son políticas explícitas. Tal y como hemos indicado en las 
características, el caso de denegar (más restrictivo), prevalecerá sobre 
cualquier permitir que se haya creado.  
El campo “Action”  es donde se indica la llamada a la API a los recursos de 
AWS. En este campo se pueden indicar varias acciones las cuales se deberán 
separar por una coma. También se puede incluir todas las acciones posibles 
escribiendo *.  
Por ejemplo, si tenemos la siguiente acción, estamos indicando que se podrá 
crear y eliminar un bucket en S3:  
“Action”:”s3:CreateBucket”,”s3:DeleteBucket”  
Con la siguiente acción, sabemos que podrá realizar cualquier acción sobre 
S3:   
“Action”:”s3:*”  
En el campo “Resource”  se indica sobre qué recurso de AWS se aplicará la 
política. Por ejemplo, si estás creando una política para S3, aquí mencionarás 
el bucket al que quieres aplicar esta política. En este elemento se deben indicar 
varios campos:  
  
arn:partition:service:region:account-id:resource  
  
Con “partition”  se indica dónde se encuentra el recurso, por lo que se indicará 
que es en AWS.  

  
 
En “service”  se indicará el servicio al que se hace mención, como por ejemplo 
ec2, dynamodb o s3.  
Para “region” indicaremos la región en la que se encuentra el recurso. En 
algunos casos no se indicará ninguna región específica.  
En el caso de “account-id” se mencionará el ID de tu cuenta AWS. Para algunos 
servicios tampoco será necesario rellenar este campo.  
El posterior elemento, “Condition” , es opcional y es donde se indicarán las 
condiciones que se deben cumplir para que se aplique la política.  
  
Cómo crear una política de contraseñas AWS  
El último punto del asistente de seguridad de AWS IAM, concierne a la política 
de contraseñas que debemos establecer para que los usuarios IAM puedan 
acceder a la consola web.   
Esto se puede ver en la sección Account Settings . Allí se muestra una serie 
de requisitos que podemos marcar para reforzar la seguridad de las 
contraseñas de nuestros usuarios como longitud mínima requerida, exigencia 
de caracteres especiales, mayúsculas, números, etc.   
  
Autenticación Multifactor  
AWS IAM te permite utilizar autenticación multifactor (MFA) para añadir una 
capa adicional de protección para mayor seguridad , ya que exige a los 
usuarios que proporcionen una autenticación exclusiva obtenida de un 
mecanismo de MFA admitido por AWS, además de sus credenciales de inicio 
de sesión habituales, para obtener acceso a los sitios web o servicios de AWS. 
Existen diversas formas de obtener una autenticación MFA:  
     
  
 
Imagen 14: Opciones MFA en Amazon WS  
 
Fuente: captura de pantalla.  
Esto es recomendable para usuarios IAM con muchos privilegios. De esta 
forma, el usuario, aparte de introducir el nombre de usuario y contraseña, 
deberá realizar una segunda autenticación que puede ser generada por un 
software o por un hardware.  
Es posible habilitar MFA para usuarios de IAM o usuario de la cuenta root de 
AWS. Si se hace para el usuario raíz, esto solo afecta a las credenciales del 
usuario raíz. En cambio, como los usuarios de IAM de la cuenta son 
identidades diferenciadas que tienen sus propias credenciales, cada identidad 
deberá tener su propia configuración de MFA.  
  
Configurar la autenticación MultiFactor (MFA)   
Para entrar como root, el usuario necesitará contar con su contraseña y alguna 
aplicación para activar la Autenticación de Doble Factor. Como mencionamos, 

  
 
existen varias formas de autenticarse y en este ejemplo, utilizaremos Microsoft 
Authenticator para Android o iOS:   
  
1- Acceder a la pestaña «Security Credentials»  del usuario y pulsar 
sobre la opción «Manage MFA Device».   
  
Imagen 15: Manage MFA Device  
 
Fuente: captura de pantalla.  
  
2- Al seleccionarlo, se inicia el proceso. En nuestro caso, 
seleccionamos dispositivo virtual (app para móvil):  
  
Imagen 15: Seleccionar dispositivo  
  
Fuente: captura de pantalla.  
  
3- Allí se deberá arrancar la aplicación y escanear el QR que aparece 
en pantalla. Tras hacerlo, nos pedirá dos códigos consecutivos para 
comprobar que todo funciona correctamente.  

  
 
 
 Fuente: captura de pantalla.  
  
4- Finalmente, la próxima vez que entremos en el panel de control de 
Amazon WS con este usuario, se nos pedirá un código que 
podremos consultar en nuestra app.  
  
 
Fuente: captura de pantalla.  
  
  
  



----- M1-Lectura.pdf -----
Módulo 1. Conceptos de cloud
computing
Introducción
Transitamos una era de cambio hacia la transformación digital. Esto quiere decir que los negocios,
productos y servicios apuntan a estar cada día más presentes en los medios digitales, para
expandir sus fronteras y establecer se en mercados globales. En medio de esta era, una de las
herramientas más fuertes para esta transformación digital es el cloud computing  o, como se lo
conoce en español, capacidad de computación en la nube.
En este módulo, profundizaremos acerca de los beneficios y conceptos esenciales del cloud
computing , así como tambié n comenzaremos a analizar una de las herramientas más fuertes del
mercado actual de desarrollo en la nube: Amazon W eb Services (A WS).
Video de inmersión
Unidad 1. Introducción 
Tema 1. Introducción a cloud computing  (cómputo en la nube)
El cloud computing  o computación en la nube es un concepto que, a grandes rasgos, significa
que el hardware y software son proporcionados como un servicio de otra empresa a través de
internet (no es una nueva tecnología, pero sí una nueva manera de hacer negocios con internet),
de un modo comp letamente transparente. Este nuevo término promete varias ventajas atractivas
tanto para las empresas como para los usuarios finales.
El origen  que dio el puntapié al concepto de cloud se puede  ubicar en la época en la que los
primeros proveedores de servicio de internet comenzaron a ofrecer servidores compartidos, es
decir , que se utilizaban entre varios  clientes. El concepto, tal como lo se lo conoce hoy, es el
resultado de años y años de avances de estos pioneros en el mundo del desarrollo de software,
los negocios en internet y los servicios.
De acuerdo con Solop (2014):
Tal y como lo cono cemos hoy podemos decir que comenzó en 2006 con el lanzamiento de
Amazon Web Services o AWS, con un alto grado de automatización de los procesos de
aprovisionamiento de servicios . . . es cuando la cosa comienza a «nublarse» un poco.
       
Por esos años las tecnologías de virtualización estaban ampliamente adoptadas en casi
todo el mundo simplificando las operaciones diarias de los departamentos de tecnología,
por lo que no era extraño que solo unos años después el concepto tomara velocidad.
(https://bit.ly/2XxHW55)
El principal ejemplo de este crecimiento, el cual abordaremos en esta materia, lo representa
Amazon Web Services, una empre sa que tiene años de trabajo en el mercado, con servicios
pensados para la nube como, por ejemplo, servicio de correo electrónico, almacenamiento de
archivos (Dropbox) o la plataforma Salesforce.
Figura 1: Cloud computing
Fuente: Nubit Consulting, 2016, https://bit.ly/3iqZI1Z.
Cuando se habla de cloud computing , entonces, se habla 
De acceso a: servicios de correo, de informació n, acceso a plataformas de gesti ón y
tiendas virtuales, entre muchas otras . Es recomendable hacer un recorrido breve por
los precursores y genios que han permitido que el cloud sea hoy una realidad. (Social
Geek, 2014, https://bit.ly/3A wObqH)
A continuación, presentamos las plataformas principales.
1. Urs Hölzle, Google
Hölzle es senior VP de infraestructura  de TI en Google. Fue el octavo empleado de la
compañía y ha jugado un rol importante en todo el proceso de escalar la infraestructura de
forma adecuada para responder a las demandas de los servicios de Google en la nube.
(Social Geek, 2014, https://bit.ly/3A wObqH)
Figura 2: Urs Hölzle, Google
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
2. Werner V ogels, Amazon
“Werner Vogels es el CTO y vicepresidente de Amazon.com. Es considerado la fuerza y el gurú
detrás del crecimiento de Amazon Web Services (AWS)” (Social Geek, 2014,
https://bit.ly/3A wObqH).
Figura 3: W erner V ogels, Amazon
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
3. Chris Kemp, NASA
“Chris Kemp es el fundador y CEO de Nebula Inc. y ex-CIO de NASA  Ames Research Center . Su
trabajo en la nube piloto de Nebula es considerado uno de los esfuerzos pioneros de la nube
actual” (Social Geek, 2014, https://bit.ly/3A wObqH).
Figura 4: Chris Kemp, NASA
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
4. Doug Hauger , Microsoft
“Doug Hauger es el líder de la plataforma cloud de Micro soft, Windows Azure. Azure ofrece
servicios de IaaS (Infrastructure as a Service ) y de PaaS (Platform as a Service ). Fue lanzado en
2010” (Social Geek, 2014, https://bit.ly/3A wObqH).
Figura 5: Doug Hauger , Microsoft
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH
5. Marc Benioff, Salesforce
Marc Beniof f y Parker Harris ayudaron a fundar Salesforce en 1999, justamente cuando
internet apenas ganaba popularidad  como plataforma de negocios. Salesforce fue una de
las prime ras plataformas de SaaS (Software as a Service ) y una de las primeras
soluciones basadas en cloud . (Social Geek, 2014, https://bit.ly/3A wObqH).
Figura 6: Marc Benioff, Salesforce
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
6. Drew Houston, Dropbox
“Drew Houston es el fundador y CEO de Dropbox, el cual cofundó junto a Arash Ferdowsi.
Dropbox fue uno de los primeros, y más ampliamente usados, servicios de backup y
almacenamiento basados en nube” (Social Geek, 2014, https://bit.ly/3A wObqH).
Figura 7: Drew Houston, Dropbox
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
7. Taylor Rhodes, Rackspace
“Taylor Rhodes es el presidente de Rackspace. Rackspace, basada en Texas, ofrece toda la
infraestructura en cloud de hosting e e-mail  para departamen tos de TI” (Social Geek, 2014,
https://bit.ly/3A wObqH).
Figura 8: T aylor Rhodes, Rackspace
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
8. Brett Caine, Citrix
“Brett Caine fue el líder de la división de servicios online de Citrix, que estaba detrás del servicio
GoToMeeting (servicio de videoconferencia online ), considerado uno de los servicios top en su
campo” (Social Geek, 2014, https://bit.ly/3A wObqH).
Figura 9: Brett Caine, Citrix
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
9. Phil Libin, Evernote
“Phil Libin  es el fundador y CEO de Evernote , el primer servicio de herramientas  documentales
que ofrec ió sincro nización en tiempo real de documentos a través de diferentes plataformas”
(Social Geek, 2014, https://bit.ly/3A wObqH).
Figura 10: Phil Libin, Evernote
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
10. David Friend, Carbonite
“David Friend fundó Carbonite junto a Jeff Flowers en 2005. Carbonite llegó a ser uno de los más
conocidos proveedores de servicios  de backup de información personal en nube de forma online ”
(Social Geek, 2014, https://bit.ly/3A wObqH).
Figura 1 1: David Friend, Carbonite
Fuente: Social Geek, 2014, https://bit.ly/3A wObqH.
Entonces, ¿qué es cloud computing ? La computación  de la nube es un modelo de entrega de
servicios, una nueva forma de hacer negocios con servicios de internet.
Cloud computing no es:
Una tecnología específica.
Una revolución, en cuanto a una tecnología creada para reemplazar otras tecnologías.
Una aplicación ni un descubrimiento tecnológico.
Cloud  computing es el producto final de una forma de ver el mundo y su relación con internet. Es
un conjun to de servicios de infraestr uctura que se consumen a través de internet. Estos servicios
son utilizados bajo demanda; debemos hacer hincapié en este punto, ya que los proveedores de
servicios en la nube como Amazon se encuentran constantemente creando servicios para
satisfacer las demandas de sus clientes.
Estos conjuntos de servicios tienen algunas características en común:    
Accesibilidad inmediata : “un punto esen cial del cloud computing es que ofrece a los
profesionales de la empresa acce so a su software , aplicaciones, bases de datos o
documentos desde cualquier lugar y a cualquier hora” (Tecnología para los negocios, s.f.,
https://n9.cl/qawd). 
Agilidad de implementación : no hace falta esperar a la instalación o configuración del
recurso, se ofrece un acceso sencillo e inmediato para cuando se necesite usar .
Flexibilidad o posibilidad  de adaptarse a la demanda: se tienen a mano los recursos que
se necesitan, ni más ni menos. Es necesario comprender cómo utilizar  la nube para evitar
contratar servicios que luego no se van a utilizar .
Pagar por lo que se consume : el pago de estos servicios está relacionado con el consumo
que haga de ellos, no es un monto fijo y se encuentra bajo el control del cliente.
Minimización de recursos : los proveedores de estos servicios se encargan del
mantenimiento necesario para que funcione toda la infraestructura, y es parte del
costo que se paga según el cons umo. Para las empresas, es más conveniente
entrenar a sus empleados en una administración básica de la nube que contratar
servicios y especialistas en esos servicios. En un entorno cloud , muchas  de las
limitaciones de ordenadores y otros equipos de trabajo desaparecerán. El caso más
común es el almacenamiento de archivos: en la nube tendremos acceso a una
capacidad ilimitada para almacenar información (Be Services, s.f.,
https://n9.cl/y8tnc). 
Elasticidad : Si durante un período de tiempo concreto un negocio necesita de más
recursos en la nube, las solucione s de Cloud Computing  están preparadas para
asumir este incremento. O si por el crecimiento de la empresa, se requiere más
capacidad de forma permanente (Be Services, s.f., https://n9.cl/y8tnc). 
El siguiente video sirve para profundizar un concepto sencillo como lo es la nube como modelo de
entrega de servicios:
Video 1: ¿Qué es el cloud computing  (computación en la nube) con Amazon AWS?
Fuente: José María González [usuario] (16 de mayo de 2018). ¿Qué es el cloud computing (computa ción en la nube) con Amazon AWS?
[archivo de video]. YouTube. https://n9.cl/xnigm.
Servicios: on-premise versus cloud
Un software on-premise  o en «el local» es un tipo de instalación tradicional que se lleva a cabo
dentro del servidor y la infraestructu ra de la empresa. Si bien el software en la nube no difiere
necesariamente del local en cuanto a la gama de funciones, las dos soluciones presentan
diferencias considerables. Se pueden observar algunos de estos aspectos en la tabla 1.
Tabla 1: Diferencias entre servidores on-premise  (físicos) y servidores en la nube
 On-premise Cloud
Costos El precio de la licencia es
relativamente alto; se paga solo una
vez.El modelo con suscripción supone un
pago regular, aunque relativame nte
bajo.
Instalación Los usuarios instalan el software  en
su propio hardware.Los usua rios acceden al software  a
través de internet.
Mantenimiento Los usua rios tienen que instalar las
actualizaciones.El fabricante instala las actualizaciones
en un segundo plano.
Escalabilidad A veces es posible adquirir
extensiones para el software ,
aunque en la mayoría de los caso s
hay que comprar otro nuevo.Se puede n añadir o eliminar funcion es
y usuarios sin hacer apenas ningún
esfuerzo.
Hardware El usuario debe contar con el
hardware  adecuado y asegurarse de
que el software  sea compatible.
Adicionalmente, no todos los
hardwares  se adaptan a las
diferentes capacidades, por lo que
podría pasar que la persona se
quede con pocos o demasiados
recursos.Como el software  está alojado en
servidores especiales, el usuario ha de
disponer únicamente de conexión a
internet. Al ser de bajo consumo, se
puede adaptar más fácilmente a las
necesidades.
Protección de
datosLos datos  perman ecen en la PC del
usuario.El fabricante tiene que asegurarse de
que terce ros no autorizados no pued an
acceder a los datos del usuario, ni
siquiera durante la transmisión en
internet.
Personalización Todo lo que se desee, dado que los
recursos son propios de la empresa.Uno se tiene que ceñir a un contra to,
en el cual puede limitar las
personalizaciones de los recursos para
usos específicos.
Fuente: Ionos, 2019, https://n9.cl/of fzd.
Se puede afirmar que más del 80 % de las grandes empresas utilizarán entornos de cloud híbrida
(es decir , que combina servicios de nube pública de terceros y nube privada). Esto refuerza la
hipótesis de que se obtienen más beneficios cuando se cuenta con una infraestructura de cloud
computing , en comparación con los clásicos centros informáticos con soluciones on-premise .
Es necesario, entonces, hacer un breve análisis de los beneficios que apareja migrar a la nube y
las desventajas que conlleva no tomar esa decisión.
Ventajas de migrar a la nube
“Las ventajas de contratar los servicios basados en la nube inciden en la efectividad, seguridad,
accesibilidad y rendimiento de un negocio, y se consolidan como el futuro en el mundo IT de las
empresas” (Nubersia, s.f., https://bit.ly/3gvCWV0).
De acuerdo con Nubersia (s.f.):
1. Sistema cómodo  y práctico : poseer un sistem a IT basado en la nube elimina todas
las obliga ciones que requiere mantener y gestionar una infraestructura de este tipo.
Tanto de equipos físicos como de software . Todo lo que nece sitamos se encontrará
de forma remota. Esto permite dedic ar el tiempo y el esfuerzo a cuestio nes del core
de la empresa o negocio.
2. Flexibilidad : si no se cuenta con los recursos suficientes para ejecutar aplicaciones ,
los nego cios o empresas pueden verse limitados y perjudicados. En cambio, los
recursos en la nube son flexibles y más rentables que los de infraestructura
dedicada, ya que ofrecen la posib ilidad de incrementar o disminuir los servicios
según la necesidad.
3. Fácil adaptabilidad : migrar a la nube no requiere de grandes conocimientos en
nuevos sistemas, ni complicadas técnicas. Basta disponer de la asesor ía correcta y
el acompañamiento durante el proceso.
4. Bajos costes y ahorro : el gasto es la principal preocupación de las empresas, y
trabajar en un sistema basado en servidores virtuales disminuye estos costos. En
primer lugar , porque no involucran un gran desembolso en instalación, configuración
o manten imiento del sistema. En segundo lugar , por el ahorro que representa esto en
el coste de energía, al no poseer toda la infraestructura física local.
5. Movilidad : la propia tecnolo gía facilita el acceso desde diferentes plataformas en
cualquier lugar y momento permitie ndo un entorno que siempre está funcionando y
[está] disponible para ser utilizado.
6. Seguridad : todo el tema relacionado con el respaldo de los datos y las copias de
seguridad están disponibles en los servicios cloud . Esto garantiza, junto a las buenas
prácticas y usos del sistema, alta disponibilidad y tolerancia a los posibles fallos del
servicio y una rápida recuperación ante desastres.
7. Concentración en el negocio : migrar a la nube y delegar el hospedaje a un
proveedor de servicios gestionados permite a las empresas recuperar el tiempo que
antes se invertía en tareas que no estaban relacionadas con el negocio. Este
beneficio resalta mucho en las pequeñas y medianas empresas.
(https://bit.ly/3gvCWV0)
Por otra parte, el no migrar a la nube puede implicar ciertas desventajas; algunas de ellas se
mencionan a continuación:
1. Gastos recurrentes : alto costo en el mantenimiento del hardware y software de los
sistemas y de la infraestructura del centro de datos. Así como también mayores
gastos en consumo de energía eléctrica, proveedores para el mantenimiento
preventivo y correctivo de los equipos y climatización del centro de cómputo, entre
otros.
2. Pérdida de dinero . Una interrupción en los servidores puede ocasionar pérdida de la
información y un tiempo prolongado de los servicios offline .
3. Pérdida de tiempo en documentación , análisis e implem entación. Las políticas de
seguridad y control de acceso físico , así como la robustez de la segur idad lógica y
las actualizacione s que se requieran, será responsabilidad total de la propia
empresa.
4. Latencia del servicio . El acceso a los recursos o servicios locales presentará
latencia (el tiempo  de respuesta que hay entre que se realiza físicamente una acción
y que un dispositivo la lleva a cabo), en zonas geográficamente distantes si se presta
el servici o a través de una aplicació n web, afectando negativamente la experiencia
de los usuarios.
5. Coste de mantenimiento . La sustitución del hardware averiado o licenciamiento
vencido supondrá un gasto considerable en la contabilidad de la empresa.
6. Otras limitaciones : todas las pruebas que se quieran realizar estarán condicionadas
a la capacidad de cómputo disponible, por lo que limitará la creatividad de
producción de los equipos de trabajo de la organización. (Nubersia, s. f.,
https://bit.ly/3gvCWV0)
Actividad de repaso 
¿Qué características tienen el conjunto de servicios de cloud computing?
Acceso inmediato.
Adaptación.
Pago por consumo.
Servidores compartidos.
Personalización de recursos.
Justificación
Tema 2. Conceptos de cloud computing
¿Qué son las nubes?
“Las nubes son entornos de infraestructura que extraen, agrupan  y comparten recursos
escalables en una red” (RedHat, s. f. a, https://red.ht/3xEEcxR). Escalables significa que crecen o
decrecen bajo demanda, que siemp re están disponibles y que pueden  alcanzar la globalización
(presencia mundial) rápidamente. 
Suelen crearse para habilitar el cloud computing , que consiste en ejecutar cargas de
trabajo dentro del sistema. Sin embargo, las nubes y el cloud computing  no son
tecnologías en sí mismas.
Las nubes son entornos: sitios en los que se ejecutan las aplicaciones.
El cloud computing  es una acción : es la función que se encarga de ejecutar cierta
carga de trabajo en una nube.
Las tecno logías son elementos: sistemas de software y hardware  que se utilizan
para diseñar y usar las nubes (RedHat, s. f. a, https://red.ht/3xEEcxR)
Las diversas nubes: públicas, privadas, híbridas y multiclouds
En el momento de su surgimiento, “la diferencia entre las nubes públicas, privadas, híbridas y
multiclouds , radicaba en la ubicación y la propiedad de la misma, pero hacer esta división ya no
es tan simple” (RedHat, s.f., https://red.ht/3hvSNEC). A continuación, se definirán los tipos de
nube existentes, los cuales están sujetos a los cambios del mercado y a las implementaciones
que se hagan de cada una de ellas.
1. Nubes públicas : un entorno de nube creado a partir de recursos ajenos al usuario
final, los cuales pueden redistribuirse a otros inquilinos.
2. Nubes privadas : en líneas generales, se trata de un entorno de nube diseñado solo
para el usuario final, generalmente dentro del firewall del usua rio y, a veces, on-
premise .
3. Nubes híbridas : varios entornos de nube con cierto nivel de portabilidad,
organización y gestión de las cargas de trabajo entre ellos.
4. Multiclouds : sistemas de TI que incluyen más de una nube, pública o privada, y que
pueden conectarse en red (o no). (RedHat, s. f. a, https://red.ht/3xEEcxR)
Figura 12: T ipos de nube
Fuente: Teckilla, 2020, https://n9.cl/v542n.
El diseño de nubes
No hay una arquitectura o infraestructura de nube única e ideal. Todas las nubes necesitan
sistemas operativos, como Linux o Windows, pero la infraestructura de nube puede incluir
varios sistemas de software sin sistema operativo, de virtualización o de contenedores que
extraen , agrupan y comparten recursos escalables en una red.
Por eso, es mejor definir las nubes por lo que hacen , y no por lo que están hechas. Es
posible asegurar que se puede crear una nube si se configura  un sistema de
infraestructura en internet con las siguientes características:
Otras computadoras pueden acceder a él a través de una red.
Contiene un repositorio de recursos de informática.
Puede implementarse y ampliarse rápidamente.
Se puede diseñar una nube privada por cuenta propia o utilizar una infraestructura de nube
predefinida como OpenStack. Hay miles de proveedores de nube en todo el mundo, y los
que se pueden observar en las siguientes figuras son algunos de los más conocidos.
(RedHat, s. f. a, https://red.ht/3xEEcxR)
Figura 13: Alibaba Cloud
Fuente: [imagen sin título sobre logo de Alibaba Cloud], s.f., https://bit.ly/34vHokd. 
Figura 14: AWS
Fuente: [imagen sin título sobre logo de Amazon W eb Services], 2017, https://bit.ly/2Y ucy83.     
Figura 15: Google Cloud
Fuente: [imagen sin título sobre logo de Google Cloud], s.f., https://bit.ly/3jbRnPO. 
Figura 16: IBM
Fuente: [imagen sin título sobre logo de IBM], s.f., https://bit.ly/34ro9IK. 
Figura 17: Microsoft Azure
Fuente: [imagen sin título sobre logo de Microsoft Azure], s.f., https://bit.ly/3leaY AF. 
La creación de una nube híbrida requiere cierto nivel de portabilidad, organización y
gestión de las cargas de trabajo. Las interfaces de programación de aplicaciones (API) y
las redes privadas virtuales (VPN) son las formas estándares para crear estas conexiones.
       
Muchos de los principales proveedores de nube incluso ofrecen a los clientes una VPN
preconfigurada como parte de sus paquetes de suscripción:
Google Cloud ofrece Dedicated InterConnect ;
Amazon W eb Services ofrece Direct Connect ;
Microsoft Azure ofrece ExpressRoute ;
OpenStack ofrece OpenStack Public Cloud Passport.  (RedHat, s.f., https://red.ht/3xEEcxR)
Servicios de la nube
Infraestructura como servicio (IaaS)
De acuerdo con RedHat (s.f.):
La infraestructura como servicio (IaaS) ofrece a los usuarios los recursos de la nube, como
la informática, las redes y el almacenamiento en la nube, a través de una conexión de red.
El auge del big data, las aplicaciones móviles y el internet de las cosas (IoT) ha
aumentado la cantidad de proveedores de almacenamiento de datos de IaaS, como
Dropbox. (https://red.ht/3hvSNEC)
Plataforma como servicio (PaaS)
La Plataf orma como servicio (PaaS) ofrece a los usuarios una plataforma de software de
aplicaciones, adem ás de toda la infraestructura de TI que se necesita para ejecutarla, a
través de una conexión de red. Normalmente así se ofrecen las plataformas de nube.
(RedHat, s.f., https://red.ht/3hvSNEC)
Software como servicio (SaaS)
El software como servicio (SaaS) ofrece a los usuarios una aplicación en completo
funcionamiento, así como la plataforma en la que se ejecuta y la infraestructura de TI que
necesita, a través de una conexión  de red. Normalmente, esta es la forma en que se
ofrecen las aplicaciones de nube. (RedHat, s.f., https://red.ht/3hvSNEC)
Figura 18: Capas del cloud computing
Fuente: Flores, 2021, https://n9.cl/qa4j.
Conceptos económicos asociados con la nube: CAPEX y OPEX
La palabra CAPEX deriva de la expresión gastos de capital , y hace referencia a todos los bienes
comprados por la empresa y las inversiones relacionadas con bienes físicos. El acrónimo OPEX,
por otro lado, significa gasto operativo  y se relaciona con el costo de las operaciones y servicios
de una empresa u organización; por ejemplo: comprar un auto o un software para una empresa es
considerado un CAPEX. En cambio , un gasto único por servicios de transporte se clasificaría
como OPEX.
¿Cómo se relacionan estos conceptos con el cloud computing ?
Según lo establece Tres60 (s. f.):
Con el auge de la tecnología, nuevo s productos y servicios emergen cada día en el sector
de TI. A medida que avanza la trans formación digital, este proceso de renovación tiende a
ser cada vez más rápido y uno de sus efectos es que el hardware y el software se vuelven
obsoletos en períodos de tiempo cada vez más cortos.
Teniendo esto en cuenta, para una empresa, pensar en invertir en CAPEX podría ser
considerado una mala opción dado que, la inversión en instalaciones de TI requiere una
gran cantidad de capital, y el retorno del mismo exige tiempo. Inclu so, dado que las
innovaciones y la tecnología avanzan y se modifica casi a diario, es posible que se
necesite invertir en nuevos equipos y software antes del retorno de la inversión. Por lo
tanto, en este contexto actual, en el que las empresas requieren actuali zaciones en cortos
períodos de tiempo, OPEX es la solución más interesante para los departamentos de TI.
(https://bit.ly/3jclNkZ)
A pesar de todo ello, es importante que cada organización evalúe su propia situación, en cuanto a
su capita l de trabajo, para saber cuál de las dos opciones (CAPEX u OPEX) se ajusta mejor y, en
función de los montos, decidir cuál es la mejor opción. Es importante recordar que lo más barato
no siempre es lo mejor: lo que realmente debemos tener en cuenta es el costo-beneficio.
Tema 3. Introducción a la infraestructura Global de Amazon W eb Services
Amazon W eb Services, una plataforma para migrar a la nube
Figura 19: AWS
Fuente: [imagen sin título sobre logo de Amazon W eb Services], 2017, https://bit.ly/2Y ucy83.     
Como se ha mencionado con anterioridad, en esta materia haremos foco en los servicios de
AWS. 
Amazon Web Services (AWS) es una plataforma de servicios de nube que ofrece
potencia de cómputo, almacenamiento de bases de datos, entrega de contenido y otra
funcionalidad para ayudar a las empresas a escalar y crecer .
Millones de clientes aprovechan los productos y soluciones de la nube de AWS para crear
aplicaciones sofisticadas y cada vez más flexibles, escalables y fiables. (Nubersia, s.f.,
https://bit.ly/3gvCWV0)
AWS se posiciona como un servicio  para cualquier caso  de uso: desde el almacenamiento de
datos hasta las herramientas de implementación, y desde los directorios hasta la entrega de
contenido; AWS dispone de más de 50 servicios disponibles para respon der a múltiples requisitos
empresariales a solo unos pocos clics de distancia.
La segur idad en la nube se consid era mejor que aquella de una instalación física. Las
certificaciones y acreditaciones, el cifrado de datos en reposo y en tránsito, los módulos de
seguridad hardware y una fuerte seguridad física, contribuyen para crear un modo más
seguro de administrar la infraestructura de TI de tu negocio [sin importar si es una start-up
o una multinacional. (Nubersia, s.f., https://bit.ly/3gvCWV0) 
La amplia red mundial  y de ubicaciones de borde  permiten contar con “44 zonas de
disponibilidad dentro de 16 region es geográficas del mundo, incluida una exclusiva para el
Gobierno de los EE. UU.” (Nubersia, s.f., https://bit.ly/3gvCWV0).
Dentro del conjunt o de productos pertenecientes a AWS, se ofrecen diferentes herramientas para
construir servicios  y productos digitales. Cada uno de ellos permite ser adaptado a las diferentes
necesidades de cada cliente. Los servicios son los siguientes:
servicios de cómputo;
servicios de redes;
servicios de almacenamiento;
servicios de bases de datos;
trazabilidad y seguimiento de la información;
seguridad de datos y de disponibilidad.[1]
Para poder ofrecer esta gama de recursos, AWS cuenta con centros de datos creados en
clústeres o «racimos» unidos entre sí, por redes de alta velocidad que alojan entre 50 000 y 80
000 servidores. En estos centros, hay personas trabajando las 24 horas del día, durante toda la
semana, para mantener la infraestructura en funcionamiento.
[1]
 Se explicará en detalle cada uno de estos servicios en los siguientes módulos, pero para mayor información se puede revisar
el anexo al ﬁnal de esta unidad.
En caso de falla de uno de los centros, existen mecanismos de respaldo, datos en espejo,
servidores de backup y gestión de flujo de carga automáticos para mitigar , de manera
transparente para los usuarios, cualquier problema físico o de red que pudiera causar demoras o
caídas en los servicios prestados.
Al mismo tiempo, Amazon organiza estos centros de datos (data centers en inglés) en zonas de
disponibilidad ( availability zones ), mayormente conocidas como AZ.
Cada AZ está diseñada para ser independiente: están físicamente separadas y ubicadas en zonas
con bajo riesgo de inundación o de catástrofes climáticas, tienen suministro de energía redundado
e ininterrumpido y cuentan con instalaciones de respaldo independientes para reducir al máximo
posible los puntos de falla. Además, cada AZ tiene hasta seis centros de datos conectados entre
sí y ningún centro puede ser parte de otra zona de disponibilidad.
Las zona s de disponibilidad se agrupan en diferentes regiones (regions ) “conectadas a
múltiples proveedores de servicios de internet , así como a una red troncal de red global
privada que proporciona una latenc ia de red entre regiones más barata y más económica en
comparación con la internet pública”. (Gonzalez, 2018, https://n9.cl/ad1zc). 
Para esclarecer la explicación, se recomienda observar las siguientes figuras. La primera figura
explica cómo se compone una región y una zona de disponibilidad, y la segunda explica cómo
están distribuidas las regiones en el mundo.
Figura 20: Cómo se compone una región
Fuente: [imagen sin título sobre cómo se compone una región], 2017, https://bit.ly/3fvUGPD. 
Figura 21: Centro de datos de Amazon W eb Services
Fuente: [imagen sin título sobre centro de datos de Amazon W eb Services], s. f., https://bit.ly/31wN1Nn. 
Todo este diseño de arquitectura está pensado para brindar un servicio de alta calidad,
ininterrumpido, con la mayor seguridad posible para datos y negocios.
Amazon recomien da desplegar los productos o servicios en, al menos, dos zonas diferentes de la
misma región, para garantizar la redundancia y la alta tolerancia a errores. De esa manera, es
posible asegurarse de que, incluso ante diferentes incidencias, el producto será siempre accesible
para el usuario final. 
Se debe tener en cuenta que es responsabilidad de quien adquiere el servicio seleccionar la
región para almacenar los datos en función de sus necesidades. Dado que cada zona de
disponibilidad cuenta con sus propios requisitos de privacidad y cumplim iento que dependen de la
ubicación, como la directiva de privacidad de datos de la Unión Europe a, AWS nunca sacará los
datos por fuera de la región en la que el usuario los colocó. Es responsabilidad del cliente o la
empresa replicar los datos en todas las regiones en las que sea necesario.
Ubicaciones de los puntos de presencia
Según lo establecido por Tailhead (s.f.):
Para ofrecer conte nido a usuarios finales en el menor tiempo posible, AWS utiliza una red
global de 166 puntos de presencia (PoP) en 65 ciudades de 29 países.
Estos puntos de presencia se dividen en ubicaciones de perímetro y memorias caché de
perímetros regionales. Algunas zonas con tráfico intenso tienen múltiples zonas
perimetrales para garantizar una entrega de contenido eficiente cuando hay mucho tráfico.
       
Cuando un usuario hace una solicitu d inicial de su contenido, la ubicación perimetral más
cercana almacena una copia en caché. (https://sforce.co/3htkUnM)
 En este sentido, Tailhead (s.f.) plantea lo siguiente:
La ubicación perimetral distribuye el contenido recién almacenado en caché a los usuarios
que acceden al contenido y se encu entran más cerca del perímetro, en lugar de recuperar
el mismo contenido una y otra vez. Este proceso acelera la distribución de contenido
ofreciendo a los usuarios acceso a contenido desde una ubicación perimetral que puede
estar en la misma ciudad. 
       
El proceso se repite a medida que más usuarios acceden a contenido desde ubicaciones
perimetrales de todo el mundo.
Los almacenamien tos en caché perimetrales regionales se usan cuando no se accede al
contenido con la frecuencia suficien te para permanecer en una ubicación perimetral. Los
almacenamientos en caché perimetrales regionales absorben este contenido y
proporcionan una alternativa a la recuperación del contenido del servidor original.
(https://sforce.co/3htkUnM)
Pilares del servicio prestado por Amazon
A continu ación, se pueden observar los pilares en los que se basa Amazon para armar su
infraestructura. Se recomienda que los arquitectos de soluciones piens en en ellos a la hora de
armar soluciones en el modelo cloud de Amazon:
seguridad;
eficiencia de rendimiento;
fiabilidad;
excelencia operativa;
optimización de costos.
1. Seguridad
En AWS, la seguri dad empieza en [la] infraestructura central, creada específicamente para
la nube y diseñada para cumplir los requisitos de seguridad más exigentes del mundo. Se
supervisa ininterru mpidamente para ayudar a garantizar la confidencialid ad, la integridad y
la dispo nibilidad de los datos de [los] clientes. (Amazon Web Services, s.f.,
https://amzn.to/2U7fWqf)
La segur idad es uno de los pilares más importantes del modelo cloud. Y esta es una
responsabilidad compartida entre el proveedor del servicio y el usuario que utiliza estos servicios.
Amazon es responsable de la seguridad de la infraestructura de la nube. Sin embargo, resguardar
los acces os y la información sensible que se mueve a través de la plataforma es responsabilidad
del cliente.
¿A qué se refiere el concepto zero trust?
El modelo zero trust es un modelo de confianza cero, mediante el cual se plantea tratar a todos
los componentes de un servicio como potencialmente riesgosos. La seguridad de confianza cero
implica la verificac ión estricta de la identidad de los dispositivos y perso nas que intenten acceder
a los recursos.
Es posible acceder a más información relacionada con el concepto de zero trust mediante el
siguiente enlace:
Citrix (s.f.). ¿Qué es la seguridad Zero T rust? Citrix. https://n9.cl/wkt27 
Actividad de repaso
¿A cuál de estas frases hace alusión el concepto zero trust?
No se confía en nadie.
Ninguna conexión fuera de las regiones.
Todo debe ser auditado.
Justificación
2. Eficiencia de rendimiento
La infrae structura global de AWS está diseñada para el rendimiento. Las redes de regiones
ofrecen baja latencia, baja pérdida de paquetes y alta calidad general de la red. (Amazon Web
Services, s.f., https://amzn.to/2U7fWqf). Además, le permite al usuario utilizar recursos de manera
rápida, “a medida que los necesit e, e implementar cientos o incluso  miles de servidores en
cuestión de minutos”. (Amazon W eb Services, s.f., https://amzn.to/2U7fWqf). 
De acuerdo con Amazon W eb Services (s.f.):
El pilar de eficacia del rendimiento se centra en cómo puede ejecutar los servicios de
manera eficiente y escalable en la nube. Mientras la nube le brinda los medios para
gestionar cualquier cantidad de tráfico, requiere que elija y configure los servicios con la
escala en mente. (https://amzn.to/3gAFHp5)
3. Fiabilidad
El pilar de confiab ilidad se enfoca en cómo se pueden construir servicios que sean resistentes a
las interru pciones tanto del servicio como de la infraestructura. Al igual que con la eficiencia del
rendimiento, mientras que la nube brinde los medios para crear servicios resistentes que pueden
soportar interrupc iones, es preciso que los servicios se diseñen teniendo en cuenta la
confiabilidad.
4. Excelencia operativa
El pilar de excelencia operativa “. . . se centra en cómo se puede mejorar continuamente la
capacidad para ejecutar sistemas, crear mejores procedimientos y obtener información” (AWS,
s.f., https://amzn.to/2Xz7Sgp).
Al pensar en la excelencia operativa en la nube, 
Es útil pensar en términos de automatización. El error humano es la causa principal de
defectos e incidentes operativos. Cuantas más operaciones automatizadas, menos
posibilidades de error humano. Además de evitar errores, la automatización ayuda a
mejorar continuamente los procesos  internos. Estos promueven un conjunto de prácticas
recomendadas recurrentes que se pueden implementar en toda la organización. (AWS,
s.f., https://amzn.to/2Xz7Sgp)
Cuando pensamos  las operaciones como automatización, deseamos centrar los esfuerzos en las
áreas que en realidad requieren la mayor parte del trabajo manual y que podrían tener la mayor
consecuencia de error .
5. Optimización de costos
Cuando se considera la optimización de costos en la nube, es útil pensar en el gasto en la nube
en términos de OPEX en lugar de CAPEX.
Los costos tradicionales de TI en los centros de datos en las instalaciones fueron
mayormente inversión de capital. Paga por toda la capacidad anticipad amente, sin tener
en cuenta si terminó de utilizarla. La compra de nuevos servidores puede ser un proceso
extenso que implicó obtener certificaciones de varias partes. Esto es porque los costos de
los gastos operativos fueron genera lmente significativos y los errores costosos. Después
de haber hecho una compra, los servidores reales pueden demorar semanas en
comenzar .
       
En AWS, los costo s son gastos operativos. Paga sobre una base continua por la capacidad
que utiliza. Los ingenieros pueden aprovisionar nuevos servidores en tiempo real sin
necesidad de un proceso de aprobación extenso. (A WS, s. f. a, https://amzn.to/2Xz7Sgp)
Pasar de un modelo CAPEX a un modelo OPEX cambia fundamentalmente el enfoque para
calcular el costo de la infraestructura. En lugar de grandes costos fijos por adelantado, se piensa
en pequeños gastos variables continuos.
Anexo servicios AWS
Brevemente, se listan, de manera agrupada, los servicios disponibles de Amazon W eb Services.
Figura 22: Migración
Fuente: [imagen sin título sobre migración], s.f., https://n9.cl/a57tt.
       AWS Migration Hub;
AWS Application Discovery Service;
AWS Database Migration Service;
AWS Server Migration Service;
AWS Snowball;
AWS Snowball Edge;
AWS Snowmobile.
Figura 23: Almacenamiento
 Fuente: [imagen sin título sobre almacenamiento], s.f., https://n9.cl/1qqcv .
Amazon Simple Storage Service (S3);
Amazon Elastic Block Storage (EBS);
Amazon Elastic File System (EFS);
Amazon Glacier;
AWS Storage Gateway;
AWS Snowball;
AWS Snowball Edge;
AWS Snowmobile.
Figura 24: Base de datos
Fuente: [imagen sin título sobre base de datos], s.f., https://n9.cl/g3qtz.
Amazon Aurora;
Amazon RDS;
Amazon DynamoDB;
Amazon ElastiCache;
Amazon Redshift;
Amazon Neptune;
AWS Database Migration Service.
Figura 25: Computación
Fuente: [imagen sin título sobre computación], s.f., https://n9.cl/a57tt. 
Amazon EC2;
Amazon EC2 Auto Scaling;
Amazon Elastic Container Service;
Amazon Elastic Container Service for Kubernetes;
Amazon Elastic Container Registry;
Amazon Lightsail;
AWS Batch;
AWS Elastic Beanstalk;
AWS Fargate;
AWS Lambda;
AWS Serverless Application Repository;
Elastic Load Balancing;
VMware Cloud on AWS.
Figura 26: Redes y entrega de contenido
Fuente: [imagen sin título sobre redes y entrega de contenidos], s.f., https://n9.cl/scorj.
Amazon VPC;
Amazon CloudFront;
Amazon Route 53;
Amazon API Gateway;
AWS Direct Connect;
Elastic Load Balancing.
Figura 27: Seguridad, identidad y conformidad
Fuente: [imagen sin título sobre seguridad, identidad y conformidad], s.f., https://n9.cl/gti7x. 
AWS Identity and Access Management (IAM);
Amazon Cloud Directory;
Amazon Cognito;
Amazon GuardDuty;
Amazon Inspector;
Amazon Macie;
AWS Certificate Manager;
AWS CloudHSM;
AWS Directory Service;
AWS Firewall Manager;
AWS Key Management Service;
AWS Organizations;
AWS Secrets Manager;
AWS Single Sign-On;
AWS Shield;
AWS W AF;
AWS Artifact.
Video de habilidades
En el video apreciamos las características principales de la nube de Amazon, la cual introduce
conceptos que solo serán comprendidos dentro del amplio mundo de los servicios en la nube.
Acorde al video: 
¿Cuántos son los servicios que ofrece Amazon a sus clientes?
3 Servicios.
2 Servicios.
6 Servicios.
4 Servicios.
Justificación
Se podría decir que, entre sus características principales, se encuentra la
velocidad al momento de contratar y utilizar un servicio de AWS.
Verdadero
Falso
Justificación
Todas las opciones que ofrece Amazon en cuanto Sistema Operativo para
crear un servidor , son de pago.
Verdadero
Falso
Justificación
¿Qué significa AMI en la nomenclatura de Amazon?
Amazon Ignitive Module
Amazon Microsoft Image
Amazon Master Image
Amazon Machine Image
Justificación
Es necesario configurar aspectos de red como Subnets o V irtual Private
Clouds al momento de crear una Instancia en EC2.
Verdadero, es un requisito indispensable para la operabilidad del servidor .
Falso, Amazon automáticamente crea tanto una Subnet como una V irtual Private
Cloud para la instancia creada.
Justificación
Cierre
Introducción a cloud computing (cómputo en la nube): El cloud computing o computación en la
nube es un concepto que, a grandes rasgos, significa que el hardware y software son
proporcionados como un servicio de otra empresa a través de internet (no es una nueva tecnología,
pero sí una nueva manera de hacer negocios con internet), de un modo completamente
transparente. Este nuevo término promete varias ventajas atractivas tanto para las empresas como
para los usuarios finales.
Conceptos de cloud computing: Las nubes son entornos de infraestru ctura que extraen, agrupan y
comparten recurs os escalables en una red. Escalables significa que crecen o decrecen bajo
demanda, que siempre están disponibles y que pueden alcanzar la «globalización» (presencia
mundial) rápidame nte; suelen crearse para habilitar el cloud computin g, que consiste en ejecutar
cargas de trabajo dentro del sistema. Sin embargo, las nubes y el cloud computing no son
tecnologías en sí mismas.
Características en común de estos conjuntos de servicios:
Accesibilidad inmediata
Agilidad de implementación
Flexibilidad o posibilidad de adaptarse a la demanda
Pagar por lo que se consume
Minimización de recursos
Elasticidad
Introducción a la infraestructura  Global de Amazon Web Services: Amazon Web Services
(AWS) es una plataforma de servicios en la nube que ofrece potencia de cómputo, almacenamiento
de bases  de datos, entrega de contenido y otras funcionalidades para ayudar a las empresas a
escalar y crecer . Millones de clientes aprovechan sus productos y soluciones para crear aplicaciones
cada día más sofisticadas y fiables. AWS se posiciona como un servicio para cualquier caso de uso:
desde el almacenamiento de datos hasta las herramientas de implementación, y desde los
directorios hasta la entrega de contenido; AWS dispone de más de 50 servicios disponibles para
responder a múltiples requisitos empresariales a solo unos pocos clics de distancia.
Referencias
[Imagen sin título sobre almacenamiento ] (s.f.). Amazon AWS
https://images.app.goo.gl/ku6CJM5DTptyZLDN9.
[Imagen sin título sobre base de datos ] (s.f.). Amazon AWS.
https://aws.amazon.com/es/products/databases/.
[Imagen sin título sobre computac ión] (s. f.). Amazon AWS. https://aws.amazon.com/es/cloud-
migration/how-to-migrate/.
[Imagen sin título sobre centro de datos de Amazon  Web Services ] (s.f.). Creattiva.
https://www .creattiva.cl/hosting/Hosting-Amazon/
[Imagen sin título sobre cómo  se compone una región ] (2017). Cloud Academy .
https://cloudacademy .com/blog/aws-global-infrastructure/.
[Imagen sin título sobre logo de Alibaba Cloud ] (s.f.). Wixstatic.
https://static.wixstatic.com/media/78c337_1a2551ef54694101a49b9ed3f7f636b9~mv2.jpg/v1/fill/w
_600,h_424,al_c,q_90/78c337_1a2551ef54694101a49b9ed3f7f636b9~mv2.jpg 
[Imagen sin título sobre logo de Amazon Web Services ] (2017). Wikipedia. https
://es.wikipedia.org/wiki/Amazon_W eb_Services#/media/Archivo:Amazon_W eb_Services_Logo.svg
. 
[Imagen sin título sobre logo de Google Cloud ] (s.f.). Internet República.
https://internetrepublica.com/configurar-imagen-cloud-screaming/. 
[Imagen sin título sobre logo de IBM ]. (s. f.). Recuperado de https://1000marcas.net/ibm-logo/
[Imagen sin título sobre logo de Windows Azure ] (s.f.). All Vector .
http://allvectorlogo.com/windows-azure-logo/. 
[Imagen sin título sobre migración ] (s. f.). Amazon AWS. https://aws.amazon.com/es/cloud-
migration/how-to-migrate/
[Imagen sin título sobre redes y entrega de contenidos ] (s.f.). Amazon AWS.
https://images.app.goo.gl/1NYtPwTB9RNbpG1Z9.
[Imagen sin título sobre seguridad, identidad y conformidad ] (s.f.). Amazon AWS.
https://images.app.goo.gl/b7xGXoR Tt7oLAzdf6.
Amazon Web Services  (s.f.). Aspectos fundamentales de AWS. Amazon AWS.
https://aws.amazon.com/es/getting-started/fundamentals-core-concepts/.
Amazon Web Services , (s.f.). La importancia de contar con una infraestructura en la nube . AWS.
de https://aws.amazon.com/es/about-aws/global-infrastructure/.
Be Services . (s.f.). 7 razones por las que utilizar el Cloud Computing en tu empresa.  Be Services.
https://www .beservices.es/porque-utilizar-cloud-computing-n-5377-es. 
Citrix . (s.f.). ¿Qué es la seguridad Zero Trust? Citrix. https://www .citrix.com/es-mx/g lossary/what-
is-zero-trust-security .html. 
Flores, F. (22 de marzo de 2021). Cloud Computing:  Tipos de nubes , servicios y prove edores.
OpenW ebinars. https://openwebinars.net/blog/tipos-de-cloud-computing/. 
Gonzalez, J. M. (3 de abril de 2018). Infraestructura global de Amazon AWS. José María
González . https://www .josemariagonzalez.es/amazon-web-services-aws/infraestructura-global-de-
amazon-aws.html. 
Ionos . (21 de junio de 2019). Software on premises vs. cloud: ventajas y desventajas. Ionos .
https://www .ionos.mx/digitalguide/servidores/know-how/software-on-premises-vs-cloud/.
José María González  [usuario] (16 de mayo de 2018). ¿Qué es el cloud computing (compu tación
en la nube) con Amazon AWS?  [archivo de video ]. YouTube. https://www .youtube.com/watch?
v=4PkmhW ezYh4.
Nubersia (s.f.). Razones y ventajas de migrar a la nube . Nubersia.
https://www .nubersia.com/es/blog/ventajas-migrar-a-la-nube/.
Nubit Consulting  (2016). 5 compe tencias necesarias para trabajar en seguridad cloud . Nubit
Consulting. https://www .nubit.es/5-competencias-necesarias-para-trabajar-en-seguridad-cloud/. 
RedHat (s.f.). ¿Qué es el cloud computing?  RedHat. https://www .redhat.com/es/topics/cloud.
RedHat (s.f.). Tipos de cloud computing . RedHat. https: //www .redhat.com/es/topics/cloud-
computing/public-cloud-vs-private-cloud-and-hybrid-cloud. 
Social Geek , (2014). Los pioneros del cloud computing . Social Geek.
https://socialgeek.co/entretenimiento/pioneros-del-cloud-computing/.
Solop, N. (1 de marzo de 2014). Qué es el cloud computing y qué puede aportarnos . Wetcom SA.
https://www .wetcom.com/blog/blog-1/que-es-el-cloud-computing-y-que-puede-aportarnos-389. 
Tailhead (s.f.). Explorar la infraestructura global de AWS. Salesforce.
https://trailhead.salesforce.com/es-MX/content/learn/modules/aws-cloud/explore-the-aws-global-
infrastructure?trail_id=learn-the-aws-cloud-practitioner-essentials.
Tecnología para los negocios  (s.f.). Razones por las que el cloud es imprescindible para las
empresas . Tecnología para los negocios.
https://ticnegocios.camaravalencia.com/servicios/tendencias/razones-las-cloud-imprescindible-las-
empresas/.
Teckilla (2020). Informática en la nube: Conceptos básicos.  Teckilla.
https://teckilla.com/category/computacion-en-la-nube/.
Tres60 (s.f.). Capex u opex: ¿cuál es el más adecuado para las ti de su empresa? Tres60 .
http://tres60tics.com/capex-u-opex/. 
A continuación podrás descargar la lectura en formato PDF o MP3:


